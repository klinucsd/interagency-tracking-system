{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a6d9a14-e17b-4a32-8d05-bbbc28825d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6703453-a2ec-412d-9854-5a5fd0ed37bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "from multiprocessing import Manager\n",
    "from multiprocessing.managers import BaseManager\n",
    "\n",
    "\n",
    "from its_logging.logger_config import logger\n",
    "from utils.its_utils import clip_to_california, get_wfr_tf_template\n",
    "from utils.gdf_utils import repair_geometries, show_columns, verify_gdf_columns\n",
    "from utils.add_common_columns import add_common_columns\n",
    "from utils.enrich_polygons import enrich_polygons\n",
    "from utils.keep_fields import keep_fields\n",
    "from utils.assign_domains import assign_domains\n",
    "from utils.save_gdf_to_gdb import save_gdf_to_gdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a35dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_reference_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\Interagency Tracking System.gdb\"\n",
    "start_year, end_year = 1950, 2025\n",
    "\n",
    "process = psutil.Process(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46162e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrich.enrich_Timber_Industry import enrich_Timber_Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1882818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ti_input_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\Industry_spatial_FFSC_MOU_V2.0\\FFSC_MOU_v2_IndustryOnly.gdb\"\n",
    "ti_input_layer_name = \"FFSC_MOU_IndustryOnly_Pol\"\n",
    "\n",
    "output_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\Timber_Spatial_{}_{}.gdb\".format(start_year, end_year)\n",
    "output_layer_name = f\"Timber_Industry_Spatial_{datetime.today().strftime('%Y%m%d')}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92bd7b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 16:48:12,646 INFO  [enrich.Timber_Industry]  Load the Timeber Industry Spatial Layer into a GeoDataFrame\n",
      "2025-05-15 16:48:13,254 INFO  [enrich.Timber_Industry]     time for loading FFSC_MOU_IndustryOnly_Pol: 0.6079411506652832\n",
      "2025-05-15 16:48:13,255 INFO  [enrich.Timber_Industry]     all required columns are present.\n",
      "2025-05-15 16:48:13,333 INFO  [enrich.Timber_Industry]  Performing Standardization...\n",
      "2025-05-15 16:48:13,333 INFO  [enrich.Timber_Industry]     step 1/15 Clip Features to California...\n",
      "2025-05-15 16:48:56,574 INFO  [enrich.Timber_Industry]        time for loading California and clipping: 43.239997148513794\n",
      "2025-05-15 16:48:56,574 INFO  [enrich.Timber_Industry]     step 2/15 Repairing Geometry...\n",
      "2025-05-15 16:48:56,882 INFO  [enrich.Timber_Industry]     step 3/15 Adding Common Columns...\n",
      "2025-05-15 16:48:56,918 INFO  [enrich.Timber_Industry]     step 4/15 Transfering Values...\n",
      "2025-05-15 16:48:56,919 INFO  [enrich.Timber_Industry]     step 5/15 Calculating Start and End Date...\n",
      "2025-05-15 16:48:56,928 INFO  [enrich.Timber_Industry]     step 6/15 Calculating Status...\n",
      "2025-05-15 16:48:56,929 INFO  [enrich.Timber_Industry]     step 7/15 Activity Quantity...\n",
      "2025-05-15 16:48:56,930 INFO  [enrich.Timber_Industry]     step 8/15 Enter Column Values...\n",
      "2025-05-15 16:48:56,930 INFO  [enrich.Timber_Industry]     step 9/15 Adding Original Activity Description to Crosswalk Column...\n",
      "2025-05-15 16:48:56,931 INFO  [enrich.Timber_Industry]     step 10/15 Select by Years...\n",
      "2025-05-15 16:48:56,937 INFO  [enrich.Timber_Industry]     step 10/15 Create New GeoDataframe Using the Template...\n",
      "2025-05-15 16:48:56,977 INFO  [enrich.Timber_Industry]     step 10/15 Append to Template...\n",
      "2025-05-15 16:48:56,992 INFO  [enrich.Timber_Industry]     step 10/15 Calculate Treatment Geometry...\n",
      "2025-05-15 16:48:56,992 INFO  [enrich.Timber_Industry]     step 11/15 Remove Unnecessary Columns...\n",
      "2025-05-15 16:48:56,996 INFO  [enrich.Timber_Industry]     step 12/15 Enriching Polygons...\n",
      "2025-05-15 16:48:56,997 INFO  [utils.enrich_polygons ]        Executing Polygon Enrichments...\n",
      "2025-05-15 16:48:56,997 INFO  [utils.enrich_polygons ]           Calculating Broad Vegetation Type...\n",
      "2025-05-15 16:48:56,997 INFO  [utils.enrich_polygons ]              enrich step 1/32 summarize veg within polygons\n",
      "2025-05-15 16:49:02,080 INFO  [utils.enrich_polygons ]                 Loaded Broad_Vegetation_Types from cache\n",
      "2025-05-15 16:49:02,081 INFO  [utils.enrich_polygons ]                    time for loading Broad_Vegetation_Types: 5.083476543426514\n",
      "2025-05-15 16:49:02,088 INFO  [utils.enrich_polygons ]              create numerical intermediate columns before multiprocessing\n",
      "2025-05-15 16:49:02,090 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-05-15 16:49:02,525 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-05-15 16:49:02,526 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2340615 \n",
      "2025-05-15 16:49:02,526 INFO  [utils.enrich_polygons ]                 records for summary: 3168\n",
      "2025-05-15 16:49:02,526 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-05-15 16:49:02,526 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-05-15 16:49:06,568 INFO  [utils.enrich_polygons ]                 joined records: 16390\n",
      "2025-05-15 16:49:06,569 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-05-15 16:49:06,570 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-05-15 16:53:46,445 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-05-15 16:53:46,446 INFO  [utils.enrich_polygons ]                 time for summarizing veg types: 284.3647301197052\n",
      "2025-05-15 16:53:46,524 INFO  [utils.enrich_polygons ]              enrich step 7/32 select records where BROAD_VEGETATION_TYPE is not null\n",
      "2025-05-15 16:53:46,525 INFO  [utils.enrich_polygons ]              enrich step 8/32 set BVT_USERD of the selected records to YES\n",
      "2025-05-15 16:53:46,525 INFO  [utils.enrich_polygons ]              enrich step 9/32 select records where BROAD_VEGETATION_TYPE is null\n",
      "2025-05-15 16:53:46,526 INFO  [utils.enrich_polygons ]              enrich step 11/32 set BVT_USERD of the selected records to NO\n",
      "2025-05-15 16:53:46,529 INFO  [utils.enrich_polygons ]              enrich step 12/32 keeping only the necessary columns\n",
      "2025-05-15 16:53:47,186 INFO  [utils.enrich_polygons ]           Calculating WUI...\n",
      "2025-05-15 16:53:47,359 INFO  [utils.enrich_polygons ]              Loaded WUI from cache\n",
      "2025-05-15 16:53:47,360 INFO  [utils.enrich_polygons ]                 time for loading WUI: 0.1725914478302002\n",
      "2025-05-15 16:53:47,360 INFO  [utils.enrich_polygons ]              enrich step 13/32 select records with null WUI\n",
      "2025-05-15 16:53:47,366 INFO  [utils.enrich_polygons ]              enrich step 14/32 select by WUI location\n",
      "2025-05-15 16:53:56,638 INFO  [utils.enrich_polygons ]              enrich step 15/32 calculate WUI yes\n",
      "2025-05-15 16:53:56,639 INFO  [utils.enrich_polygons ]              enrich step 16/32 select remaining null records\n",
      "2025-05-15 16:53:56,645 INFO  [utils.enrich_polygons ]              enrich step 17/32 calculate WUI no\n",
      "2025-05-15 16:53:56,646 INFO  [utils.enrich_polygons ]              enrich step 18/32 feature to point\n",
      "2025-05-15 16:53:56,654 INFO  [utils.enrich_polygons ]              enrich step 19/32 setup ORIG_FID\n",
      "2025-05-15 16:53:56,655 INFO  [utils.enrich_polygons ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-05-15 16:53:57,089 INFO  [utils.enrich_polygons ]              Loaded CALFIRE_Ownership_Update from cache\n",
      "2025-05-15 16:53:57,089 INFO  [utils.enrich_polygons ]                 time for loading CALFIRE_Ownership_Update: 0.4337460994720459\n",
      "2025-05-15 16:53:57,105 INFO  [utils.enrich_polygons ]              Loaded WFRTF_Regions from cache\n",
      "2025-05-15 16:53:57,106 INFO  [utils.enrich_polygons ]                 time for loading WFRTF_Regions: 0.016269445419311523\n",
      "2025-05-15 16:53:57,106 INFO  [utils.enrich_polygons ]              enrich step 20/32 spatial join ownership\n",
      "2025-05-15 16:53:59,043 INFO  [utils.enrich_polygons ]              enrich step 21/32 spatial join with regions layer\n",
      "2025-05-15 16:53:59,495 INFO  [utils.enrich_polygons ]              enrich step 22/32 add ownership and region\n",
      "2025-05-15 16:53:59,500 INFO  [utils.enrich_polygons ]              enrich step 23/32 calculate ownership field\n",
      "2025-05-15 16:53:59,501 INFO  [utils.enrich_polygons ]              enrich step 24/32 calculate county field\n",
      "2025-05-15 16:53:59,501 INFO  [utils.enrich_polygons ]              enrich step 25/32 calculate region field\n",
      "2025-05-15 16:53:59,502 INFO  [utils.enrich_polygons ]              enrich step 26/32 set TRMT_GEOM\n",
      "2025-05-15 16:53:59,502 INFO  [utils.enrich_polygons ]              enrich step 27/32 calculating years...\n",
      "2025-05-15 16:53:59,512 INFO  [utils.enrich_polygons ]              enrich step 28/32 Initiating Crosswalk...\n",
      "2025-05-15 16:53:59,513 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-05-15 16:53:59,513 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-05-15 16:53:59,551 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-05-15 16:53:59,557 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-05-15 16:53:59,558 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-05-15 16:53:59,559 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-05-15 16:53:59,559 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "2025-05-15 16:53:59,562 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-05-15 16:53:59,583 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-05-15 16:53:59,671 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 16:53:59,671 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-05-15 16:53:59,672 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-05-15 16:53:59,672 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-05-15 16:53:59,675 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-05-15 16:53:59,675 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-05-15 16:53:59,675 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-05-15 16:53:59,676 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-05-15 16:53:59,676 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-05-15 16:53:59,678 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Org is 'USFS' and Status is 'Active'\n",
      "2025-05-15 16:53:59,683 INFO  [utils.enrich_polygons ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-05-15 16:53:59,683 INFO  [utils.enrich_polygons ]              enrich step 29/32 Calculating Latitude and Longitude...\n",
      "2025-05-15 16:53:59,696 INFO  [utils.enrich_polygons ]              enrich step 30/32 calculate treatment acres\n",
      "2025-05-15 16:53:59,699 INFO  [utils.enrich_polygons ]              enrich step 31/32 removing unnecessary fields\n",
      "2025-05-15 16:53:59,703 INFO  [utils.enrich_polygons ]              enrich step 32/32 delete if County is Null\n",
      "2025-05-15 16:53:59,898 INFO  [enrich.Timber_Industry]     step 13/15 Calculate Treatment ID...\n",
      "2025-05-15 16:53:59,899 INFO  [enrich.Timber_Industry]     step 14/15 Assign Domains...\n",
      "2025-05-15 16:54:00,270 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-05-15 16:54:00,276 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-05-15 16:54:00,282 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-05-15 16:54:00,288 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-05-15 16:54:00,294 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-05-15 16:54:00,300 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-05-15 16:54:00,305 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-05-15 16:54:00,312 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-05-15 16:54:00,319 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-05-15 16:54:00,324 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-05-15 16:54:00,330 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-05-15 16:54:00,335 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-05-15 16:54:00,341 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-05-15 16:54:00,346 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-05-15 16:54:00,353 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-05-15 16:54:00,358 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-05-15 16:54:00,358 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-05-15 16:54:00,364 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-05-15 16:54:00,369 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-05-15 16:54:00,375 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-05-15 16:54:00,375 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-05-15 16:54:00,382 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-05-15 16:54:00,390 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-05-15 16:54:00,403 INFO  [enrich.Timber_Industry]     step 15/15 Save Result...\n",
      "2025-05-15 16:54:00,403 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-05-15 16:54:00,404 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-05-15 16:54:00,428 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\Timber_Spatial_1950_2025.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 16:54:00,730 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\Timber_Spatial_1950_2025.gdb Timber_Industry_Spatial_20250515\n"
     ]
    }
   ],
   "source": [
    "enrich_Timber_Industry(ti_input_gdb_path,\n",
    "                       ti_input_layer_name,\n",
    "                       a_reference_gdb_path,\n",
    "                       start_year,\n",
    "                       end_year,\n",
    "                       output_gdb_path,\n",
    "                       output_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f099f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.managers import NamespaceProxy, BaseManager\n",
    "from pandas import DataFrame\n",
    "import inspect\n",
    "import os\n",
    "\n",
    "class MyDataFrame(DataFrame):\n",
    "    def __getstate__(self):\n",
    "        print(f'dataframe being pickled in pid {os.getpid()}')\n",
    "        return super().__getstate__()\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        print(f'dataframe being unpickled in pid {os.getpid()}')\n",
    "        print()\n",
    "        return super().__setstate__(state)\n",
    "\n",
    "\n",
    "class ObjProxy(NamespaceProxy):\n",
    "    \"\"\"Returns a proxy instance for any user defined data-type. The proxy instance will have the namespace and\n",
    "    functions of the data-type (except private/protected callables/attributes). Furthermore, the proxy will be\n",
    "    pickable and can its state can be shared among different processes. \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def populate_obj_attributes(cls, real_cls):\n",
    "        DISALLOWED = set(dir(cls))\n",
    "        ALLOWED = ['__sizeof__', '__eq__', '__ne__', '__le__', '__repr__', '__dict__', '__lt__',\n",
    "                   '__gt__']\n",
    "        DISALLOWED.add('__class__')\n",
    "        new_dict = {}\n",
    "        for (attr, value) in inspect.getmembers(real_cls, callable):\n",
    "            if attr not in DISALLOWED or attr in ALLOWED:\n",
    "                new_dict[attr] = proxy_wrap(attr)\n",
    "        return new_dict\n",
    "\n",
    "\n",
    "def proxy_wrap(attr):\n",
    "    \"\"\" This method creates function that calls the proxified object's method.\"\"\"\n",
    "    def f(self, *args, **kwargs):\n",
    "\n",
    "        # _callmethod is the method that proxies provided by multiprocessing use to call methods in the proxified object\n",
    "        return self._callmethod(attr, args, kwargs)\n",
    "\n",
    "    return f\n",
    "\n",
    "# Create a class during runtime\n",
    "new_dict = ObjProxy.populate_obj_attributes(MyDataFrame)\n",
    "DataFrameObjProxy = type(\"DataFrameObjProxy\", (ObjProxy,), new_dict)\n",
    "BaseManager.register('DataFrame', MyDataFrame, DataFrameObjProxy, exposed=tuple(dir(DataFrameObjProxy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff0115e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 05:25:31,057 INFO  [enrich.enrich_USFS    ]  Loading the USFS data into GeoDataFrames: Actv_CommonAttribute_PL_Region05.gdb : Actv_CommonAttribute_PL\n",
      "2025-06-04 05:25:31,058 INFO  [enrich.enrich_USFS    ]     Loading USFS data from cache\n",
      "2025-06-04 05:25:37,050 INFO  [enrich.enrich_USFS    ]        records: 748591\n",
      "2025-06-04 05:25:37,051 INFO  [enrich.enrich_USFS    ]        time for loading USFS: 5.9931745529174805\n",
      "2025-06-04 05:25:37,052 INFO  [enrich.enrich_USFS    ]     all required columns are present.\n",
      "2025-06-04 05:25:48,340 INFO  [enrich.enrich_USFS    ]  Performing Standardization...\n",
      "2025-06-04 05:25:48,394 INFO  [enrich.enrich_USFS    ]     found 55793 rows with empty geometry\n",
      "2025-06-04 05:25:48,394 INFO  [enrich.enrich_USFS    ]     drop 55793 rows with empty geometry\n",
      "2025-06-04 05:25:49,711 INFO  [enrich.enrich_USFS    ]     records in California: 683960\n",
      "2025-06-04 05:25:49,712 INFO  [enrich.enrich_USFS    ]     step 1/8 Selecting Features...\n",
      "2025-06-04 05:25:51,336 INFO  [enrich.enrich_USFS    ]        selected Activities have 403354 records\n",
      "2025-06-04 05:25:51,337 INFO  [enrich.enrich_USFS    ]     step 2/8 Repairing Geometry...\n",
      "2025-06-04 05:26:21,730 INFO  [enrich.enrich_USFS    ]     step 3/8 Adding Fields...\n",
      "2025-06-04 05:26:23,721 INFO  [enrich.enrich_USFS    ]     step 4/8 Transfering Attributes...\n",
      "2025-06-04 05:26:23,839 INFO  [enrich.enrich_USFS    ]     step 5/8 Calculating End Date...\n",
      "2025-06-04 05:26:23,848 INFO  [enrich.enrich_USFS    ]     step 6/8 Calculating Status...\n",
      "2025-06-04 05:26:26,923 INFO  [enrich.enrich_USFS    ]     step 7/8 Activity Quantity...\n",
      "2025-06-04 05:26:26,926 INFO  [enrich.enrich_USFS    ]     step 8/8 Enter Field Values...\n",
      "2025-06-04 05:26:27,021 INFO  [enrich.enrich_USFS    ]  Remove Unnecessary Columns...\n",
      "2025-06-04 05:26:27,429 INFO  [enrich.enrich_USFS    ]  Select records between 1950 and 2025...\n",
      "2025-06-04 05:26:27,863 INFO  [enrich.enrich_USFS    ]  Enriching Dataset...\n",
      "2025-06-04 05:26:27,864 INFO  [utils.enrich_polygons ]        Executing Polygon Enrichments...\n",
      "2025-06-04 05:26:27,864 INFO  [utils.enrich_polygons ]           Calculating Broad Vegetation Type...\n",
      "2025-06-04 05:26:27,865 INFO  [utils.enrich_polygons ]              enrich step 1/32 summarize veg within polygons\n",
      "2025-06-04 05:26:32,043 INFO  [utils.enrich_polygons ]                 Loaded Broad_Vegetation_Types from cache\n",
      "2025-06-04 05:26:32,044 INFO  [utils.enrich_polygons ]                    time for loading Broad_Vegetation_Types: 4.178954839706421\n",
      "2025-06-04 05:26:32,761 INFO  [utils.enrich_polygons ]              create numerical intermediate columns before multiprocessing\n",
      "2025-06-04 05:26:32,763 INFO  [utils.enrich_polygons ]                    Summarizing veg types with 401985 records may take up to 2411 minutes depending on the geometries.\n",
      "2025-06-04 05:26:33,031 INFO  [utils.enrich_polygons ]                 split into 41 chunks with 10000 records\n",
      "2025-06-04 05:26:33,031 INFO  [utils.enrich_polygons ]              ================ processing chunk 1 ================\n",
      "2025-06-04 05:26:33,832 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 05:26:34,407 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 05:26:34,407 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3347340 \n",
      "2025-06-04 05:26:34,408 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 05:26:34,408 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 05:26:34,409 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 05:26:46,738 INFO  [utils.enrich_polygons ]                 joined records: 75127\n",
      "2025-06-04 05:26:46,739 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 05:26:46,739 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 05:35:43,446 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 05:35:43,600 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 05:35:43,600 INFO  [utils.enrich_polygons ]              ================ processing chunk 2 ================\n",
      "2025-06-04 05:35:44,387 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 05:35:45,044 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 05:35:45,045 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3347304 \n",
      "2025-06-04 05:35:45,045 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 05:35:45,045 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 05:35:45,046 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 05:35:51,290 INFO  [utils.enrich_polygons ]                 joined records: 41627\n",
      "2025-06-04 05:35:51,291 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 05:35:51,292 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 05:48:33,485 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 05:48:33,622 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 05:48:33,622 INFO  [utils.enrich_polygons ]              ================ processing chunk 3 ================\n",
      "2025-06-04 05:48:34,368 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 05:48:35,007 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 05:48:35,007 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3390870 \n",
      "2025-06-04 05:48:35,008 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 05:48:35,008 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 05:48:35,008 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 05:48:56,857 INFO  [utils.enrich_polygons ]                 joined records: 34015\n",
      "2025-06-04 05:48:56,858 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 05:48:56,859 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 06:05:35,974 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 06:05:36,109 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 06:05:36,109 INFO  [utils.enrich_polygons ]              ================ processing chunk 4 ================\n",
      "2025-06-04 06:05:36,746 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 06:05:37,345 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 06:05:37,346 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3081621 \n",
      "2025-06-04 06:05:37,346 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 06:05:37,346 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 06:05:37,346 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 06:05:40,232 INFO  [utils.enrich_polygons ]                 joined records: 33365\n",
      "2025-06-04 06:05:40,233 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 06:05:40,234 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 06:20:36,299 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 06:20:36,416 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 06:20:36,416 INFO  [utils.enrich_polygons ]              ================ processing chunk 5 ================\n",
      "2025-06-04 06:20:37,091 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 06:20:37,681 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 06:20:37,682 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3087932 \n",
      "2025-06-04 06:20:37,682 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 06:20:37,682 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 06:20:37,683 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 06:20:41,358 INFO  [utils.enrich_polygons ]                 joined records: 36349\n",
      "2025-06-04 06:20:41,359 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 06:20:41,360 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 06:34:26,605 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 06:34:26,717 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 06:34:26,717 INFO  [utils.enrich_polygons ]              ================ processing chunk 6 ================\n",
      "2025-06-04 06:34:27,230 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 06:34:27,756 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 06:34:27,756 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2872471 \n",
      "2025-06-04 06:34:27,757 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 06:34:27,757 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 06:34:27,757 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 06:34:31,857 INFO  [utils.enrich_polygons ]                 joined records: 36590\n",
      "2025-06-04 06:34:31,858 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 06:34:31,858 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 06:49:39,512 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 06:49:39,811 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 06:49:39,811 INFO  [utils.enrich_polygons ]              ================ processing chunk 7 ================\n",
      "2025-06-04 06:49:40,359 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 06:49:40,848 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 06:49:40,848 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2623531 \n",
      "2025-06-04 06:49:40,849 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 06:49:40,849 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 06:49:40,849 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 06:49:44,862 INFO  [utils.enrich_polygons ]                 joined records: 26643\n",
      "2025-06-04 06:49:44,863 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 06:49:44,864 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 07:01:47,849 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 07:01:47,947 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 07:01:47,948 INFO  [utils.enrich_polygons ]              ================ processing chunk 8 ================\n",
      "2025-06-04 07:01:48,492 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 07:01:49,001 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 07:01:49,002 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2866712 \n",
      "2025-06-04 07:01:49,002 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 07:01:49,002 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 07:01:49,003 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 07:01:54,427 INFO  [utils.enrich_polygons ]                 joined records: 25465\n",
      "2025-06-04 07:01:54,429 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 07:01:54,429 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 07:13:18,894 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 07:13:18,991 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 07:13:18,992 INFO  [utils.enrich_polygons ]              ================ processing chunk 9 ================\n",
      "2025-06-04 07:13:19,651 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 07:13:20,196 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 07:13:20,196 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3297128 \n",
      "2025-06-04 07:13:20,197 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 07:13:20,197 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 07:13:20,197 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 07:13:24,490 INFO  [utils.enrich_polygons ]                 joined records: 31082\n",
      "2025-06-04 07:13:24,491 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 07:13:24,491 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 07:29:13,969 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 07:29:14,089 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 07:29:14,089 INFO  [utils.enrich_polygons ]              ================ processing chunk 10 ================\n",
      "2025-06-04 07:29:14,667 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 07:29:15,151 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 07:29:15,152 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2495618 \n",
      "2025-06-04 07:29:15,152 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 07:29:15,152 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 07:29:15,152 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 07:29:17,924 INFO  [utils.enrich_polygons ]                 joined records: 17908\n",
      "2025-06-04 07:29:17,925 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 07:29:17,925 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 07:42:16,282 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 07:42:16,393 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 07:42:16,393 INFO  [utils.enrich_polygons ]              ================ processing chunk 11 ================\n",
      "2025-06-04 07:42:16,987 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 07:42:17,440 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 07:42:17,441 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 1990299 \n",
      "2025-06-04 07:42:17,441 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 07:42:17,441 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 07:42:17,442 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 07:42:20,097 INFO  [utils.enrich_polygons ]                 joined records: 23832\n",
      "2025-06-04 07:42:20,098 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 07:42:20,098 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 07:54:44,561 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 07:54:44,664 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 07:54:44,664 INFO  [utils.enrich_polygons ]              ================ processing chunk 12 ================\n",
      "2025-06-04 07:54:45,434 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 07:54:45,992 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 07:54:45,993 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2665817 \n",
      "2025-06-04 07:54:45,993 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 07:54:45,994 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 07:54:45,994 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 07:56:10,002 INFO  [utils.enrich_polygons ]                 joined records: 33878\n",
      "2025-06-04 07:56:10,003 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 07:56:10,003 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 08:05:23,904 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 08:05:24,033 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 08:05:24,034 INFO  [utils.enrich_polygons ]              ================ processing chunk 13 ================\n",
      "2025-06-04 08:05:24,867 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 08:05:25,512 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 08:05:25,513 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3308140 \n",
      "2025-06-04 08:05:25,513 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 08:05:25,513 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 08:05:25,514 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 08:05:30,155 INFO  [utils.enrich_polygons ]                 joined records: 39108\n",
      "2025-06-04 08:05:30,156 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 08:05:30,156 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 08:13:49,744 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 08:13:49,887 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 08:13:49,888 INFO  [utils.enrich_polygons ]              ================ processing chunk 14 ================\n",
      "2025-06-04 08:13:50,533 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 08:13:50,826 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 08:13:50,827 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 949905 \n",
      "2025-06-04 08:13:50,827 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 08:13:50,827 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 08:13:50,827 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 08:13:52,684 INFO  [utils.enrich_polygons ]                 joined records: 19983\n",
      "2025-06-04 08:13:52,685 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 08:13:52,685 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 08:32:34,307 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 08:32:34,420 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 08:32:34,420 INFO  [utils.enrich_polygons ]              ================ processing chunk 15 ================\n",
      "2025-06-04 08:32:35,020 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 08:32:35,359 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 08:32:35,359 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 1224629 \n",
      "2025-06-04 08:32:35,360 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 08:32:35,360 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 08:32:35,360 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 08:32:37,254 INFO  [utils.enrich_polygons ]                 joined records: 18984\n",
      "2025-06-04 08:32:37,255 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 08:32:37,256 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 08:50:32,564 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 08:50:32,674 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 08:50:32,674 INFO  [utils.enrich_polygons ]              ================ processing chunk 16 ================\n",
      "2025-06-04 08:50:33,318 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 08:50:34,003 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 08:50:34,004 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3335731 \n",
      "2025-06-04 08:50:34,004 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 08:50:34,005 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 08:50:34,005 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 08:50:37,257 INFO  [utils.enrich_polygons ]                 joined records: 26866\n",
      "2025-06-04 08:50:37,258 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 08:50:37,258 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 09:06:36,881 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 09:06:36,996 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 09:06:36,997 INFO  [utils.enrich_polygons ]              ================ processing chunk 17 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 09:06:37,565 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 09:06:37,967 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 09:06:37,967 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2070119 \n",
      "2025-06-04 09:06:37,967 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 09:06:37,968 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 09:06:37,968 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 09:06:40,234 INFO  [utils.enrich_polygons ]                 joined records: 19140\n",
      "2025-06-04 09:06:40,235 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 09:06:40,235 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 09:22:02,799 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 09:22:02,900 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 09:22:02,900 INFO  [utils.enrich_polygons ]              ================ processing chunk 18 ================\n",
      "2025-06-04 09:22:03,474 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 09:22:03,977 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 09:22:03,977 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2596995 \n",
      "2025-06-04 09:22:03,977 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 09:22:03,978 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 09:22:03,978 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 09:22:10,851 INFO  [utils.enrich_polygons ]                 joined records: 22852\n",
      "2025-06-04 09:22:10,852 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 09:22:10,852 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 09:37:10,567 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 09:37:10,670 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 09:37:10,670 INFO  [utils.enrich_polygons ]              ================ processing chunk 19 ================\n",
      "2025-06-04 09:37:11,252 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 09:37:11,745 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 09:37:11,745 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2484898 \n",
      "2025-06-04 09:37:11,745 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 09:37:11,746 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 09:37:11,746 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 09:37:14,128 INFO  [utils.enrich_polygons ]                 joined records: 20135\n",
      "2025-06-04 09:37:14,129 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 09:37:14,129 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 09:52:50,116 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 09:52:50,221 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 09:52:50,222 INFO  [utils.enrich_polygons ]              ================ processing chunk 20 ================\n",
      "2025-06-04 09:52:51,022 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 09:52:51,577 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 09:52:51,578 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3169590 \n",
      "2025-06-04 09:52:51,578 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 09:52:51,578 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 09:52:51,579 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 09:52:55,800 INFO  [utils.enrich_polygons ]                 joined records: 28001\n",
      "2025-06-04 09:52:55,801 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 09:52:55,802 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 10:08:03,777 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 10:08:03,914 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 10:08:03,914 INFO  [utils.enrich_polygons ]              ================ processing chunk 21 ================\n",
      "2025-06-04 10:08:04,922 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 10:08:05,564 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 10:08:05,564 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3284578 \n",
      "2025-06-04 10:08:05,565 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 10:08:05,565 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 10:08:05,565 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 10:08:14,328 INFO  [utils.enrich_polygons ]                 joined records: 44529\n",
      "2025-06-04 10:08:14,330 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 10:08:14,330 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 10:21:10,516 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 10:21:10,707 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 10:21:10,707 INFO  [utils.enrich_polygons ]              ================ processing chunk 22 ================\n",
      "2025-06-04 10:21:11,750 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 10:21:12,389 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 10:21:12,390 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3262897 \n",
      "2025-06-04 10:21:12,390 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 10:21:12,390 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 10:21:12,390 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 10:21:21,456 INFO  [utils.enrich_polygons ]                 joined records: 43821\n",
      "2025-06-04 10:21:21,457 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 10:21:21,458 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 10:35:45,763 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 10:35:45,945 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 10:35:45,946 INFO  [utils.enrich_polygons ]              ================ processing chunk 23 ================\n",
      "2025-06-04 10:35:47,053 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 10:35:47,704 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 10:35:47,704 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3291688 \n",
      "2025-06-04 10:35:47,705 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 10:35:47,705 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 10:35:47,705 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 10:37:38,766 INFO  [utils.enrich_polygons ]                 joined records: 48167\n",
      "2025-06-04 10:37:38,767 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 10:37:38,767 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 10:52:37,975 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 10:52:38,166 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 10:52:38,167 INFO  [utils.enrich_polygons ]              ================ processing chunk 24 ================\n",
      "2025-06-04 10:52:39,137 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 10:52:39,823 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 10:52:39,823 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3381703 \n",
      "2025-06-04 10:52:39,824 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 10:52:39,824 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 10:52:39,825 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 10:52:53,821 INFO  [utils.enrich_polygons ]                 joined records: 41839\n",
      "2025-06-04 10:52:53,822 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 10:52:53,823 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 11:08:02,660 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 11:08:02,826 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 11:08:02,826 INFO  [utils.enrich_polygons ]              ================ processing chunk 25 ================\n",
      "2025-06-04 11:08:03,855 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 11:08:04,527 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 11:08:04,528 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3380434 \n",
      "2025-06-04 11:08:04,528 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 11:08:04,528 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 11:08:04,529 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 11:08:17,708 INFO  [utils.enrich_polygons ]                 joined records: 40983\n",
      "2025-06-04 11:08:17,710 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 11:08:17,710 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 11:23:15,882 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 11:23:16,058 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 11:23:16,058 INFO  [utils.enrich_polygons ]              ================ processing chunk 26 ================\n",
      "2025-06-04 11:23:17,080 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 11:23:17,730 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 11:23:17,730 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3261810 \n",
      "2025-06-04 11:23:17,731 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 11:23:17,731 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 11:23:17,731 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 11:23:29,532 INFO  [utils.enrich_polygons ]                 joined records: 40041\n",
      "2025-06-04 11:23:29,533 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 11:23:29,533 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 11:39:10,559 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 11:39:10,734 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 11:39:10,734 INFO  [utils.enrich_polygons ]              ================ processing chunk 27 ================\n",
      "2025-06-04 11:39:11,700 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 11:39:12,360 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 11:39:12,360 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3264958 \n",
      "2025-06-04 11:39:12,361 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 11:39:12,361 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 11:39:12,361 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 11:39:17,564 INFO  [utils.enrich_polygons ]                 joined records: 42783\n",
      "2025-06-04 11:39:17,566 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 11:39:17,566 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 11:55:28,535 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 11:55:28,698 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 11:55:28,699 INFO  [utils.enrich_polygons ]              ================ processing chunk 28 ================\n",
      "2025-06-04 11:55:29,668 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 11:55:30,299 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 11:55:30,299 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3258036 \n",
      "2025-06-04 11:55:30,300 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 11:55:30,300 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 11:55:30,300 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 11:55:37,544 INFO  [utils.enrich_polygons ]                 joined records: 44457\n",
      "2025-06-04 11:55:37,545 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 11:55:37,546 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 12:11:39,528 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 12:11:39,690 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 12:11:39,691 INFO  [utils.enrich_polygons ]              ================ processing chunk 29 ================\n",
      "2025-06-04 12:11:40,606 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 12:11:41,215 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 12:11:41,215 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3209633 \n",
      "2025-06-04 12:11:41,216 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 12:11:41,216 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 12:11:41,216 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 12:11:48,217 INFO  [utils.enrich_polygons ]                 joined records: 40910\n",
      "2025-06-04 12:11:48,218 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 12:11:48,218 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 12:25:59,700 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 12:25:59,849 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 12:25:59,849 INFO  [utils.enrich_polygons ]              ================ processing chunk 30 ================\n",
      "2025-06-04 12:26:00,801 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 12:26:01,312 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 12:26:01,312 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2897846 \n",
      "2025-06-04 12:26:01,313 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 12:26:01,313 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 12:26:01,313 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 12:27:02,935 INFO  [utils.enrich_polygons ]                 joined records: 49751\n",
      "2025-06-04 12:27:02,936 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 12:27:02,937 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 12:41:31,493 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 12:41:31,641 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 12:41:31,641 INFO  [utils.enrich_polygons ]              ================ processing chunk 31 ================\n",
      "2025-06-04 12:41:32,557 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 12:41:33,140 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 12:41:33,141 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3282832 \n",
      "2025-06-04 12:41:33,141 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 12:41:33,141 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 12:41:33,142 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 12:41:38,419 INFO  [utils.enrich_polygons ]                 joined records: 38574\n",
      "2025-06-04 12:41:38,420 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 12:41:38,421 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 12:55:16,156 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 12:55:16,310 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 12:55:16,310 INFO  [utils.enrich_polygons ]              ================ processing chunk 32 ================\n",
      "2025-06-04 12:55:17,153 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 12:55:17,724 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 12:55:17,725 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3168268 \n",
      "2025-06-04 12:55:17,725 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 12:55:17,725 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 12:55:17,726 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 12:55:23,911 INFO  [utils.enrich_polygons ]                 joined records: 37618\n",
      "2025-06-04 12:55:23,912 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 12:55:23,912 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 13:08:44,483 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 13:08:44,684 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 13:08:44,684 INFO  [utils.enrich_polygons ]              ================ processing chunk 33 ================\n",
      "2025-06-04 13:08:45,467 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 13:08:46,027 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 13:08:46,028 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3177839 \n",
      "2025-06-04 13:08:46,028 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 13:08:46,029 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 13:08:46,029 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 13:08:52,551 INFO  [utils.enrich_polygons ]                 joined records: 43436\n",
      "2025-06-04 13:08:52,553 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 13:08:52,553 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 13:20:37,345 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 13:20:37,477 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 13:20:37,477 INFO  [utils.enrich_polygons ]              ================ processing chunk 34 ================\n",
      "2025-06-04 13:20:38,243 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 13:20:38,817 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 13:20:38,817 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3176033 \n",
      "2025-06-04 13:20:38,818 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 13:20:38,818 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 13:20:38,818 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 13:20:45,481 INFO  [utils.enrich_polygons ]                 joined records: 40844\n",
      "2025-06-04 13:20:45,483 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 13:20:45,483 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 13:32:58,324 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 13:32:58,449 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 13:32:58,450 INFO  [utils.enrich_polygons ]              ================ processing chunk 35 ================\n",
      "2025-06-04 13:32:59,396 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 13:32:59,945 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 13:32:59,946 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3171531 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 13:32:59,946 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 13:32:59,946 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 13:32:59,947 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 13:33:05,327 INFO  [utils.enrich_polygons ]                 joined records: 28579\n",
      "2025-06-04 13:33:05,329 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 13:33:05,329 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 13:49:32,719 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 13:49:32,881 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 13:49:32,882 INFO  [utils.enrich_polygons ]              ================ processing chunk 36 ================\n",
      "2025-06-04 13:49:34,161 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 13:49:34,790 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 13:49:34,790 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3176350 \n",
      "2025-06-04 13:49:34,791 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 13:49:34,791 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 13:49:34,791 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 13:49:43,120 INFO  [utils.enrich_polygons ]                 joined records: 31914\n",
      "2025-06-04 13:49:43,121 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 13:49:43,121 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 14:05:57,085 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 14:05:57,299 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 14:05:57,300 INFO  [utils.enrich_polygons ]              ================ processing chunk 37 ================\n",
      "2025-06-04 14:05:58,622 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 14:05:59,279 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 14:05:59,279 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3286505 \n",
      "2025-06-04 14:05:59,280 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 14:05:59,280 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 14:05:59,280 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 14:06:08,618 INFO  [utils.enrich_polygons ]                 joined records: 51125\n",
      "2025-06-04 14:06:08,620 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 14:06:08,620 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 14:16:47,972 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 14:16:48,183 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 14:16:48,184 INFO  [utils.enrich_polygons ]              ================ processing chunk 38 ================\n",
      "2025-06-04 14:16:49,855 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 14:16:50,542 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 14:16:50,542 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3371246 \n",
      "2025-06-04 14:16:50,543 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 14:16:50,543 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 14:16:50,543 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 14:17:05,902 INFO  [utils.enrich_polygons ]                 joined records: 44136\n",
      "2025-06-04 14:17:05,904 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 14:17:05,904 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 14:33:06,247 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 14:33:06,505 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 14:33:06,505 INFO  [utils.enrich_polygons ]              ================ processing chunk 39 ================\n",
      "2025-06-04 14:33:07,739 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 14:33:08,403 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 14:33:08,403 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3352471 \n",
      "2025-06-04 14:33:08,404 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 14:33:08,404 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 14:33:08,404 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 14:33:23,046 INFO  [utils.enrich_polygons ]                 joined records: 34503\n",
      "2025-06-04 14:33:23,048 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 14:33:23,048 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 14:51:25,783 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 14:51:25,974 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 14:51:25,975 INFO  [utils.enrich_polygons ]              ================ processing chunk 40 ================\n",
      "2025-06-04 14:51:27,693 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 14:51:28,332 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 14:51:28,332 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3358447 \n",
      "2025-06-04 14:51:28,333 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 14:51:28,333 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 14:51:28,333 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 14:51:45,969 INFO  [utils.enrich_polygons ]                 joined records: 44919\n",
      "2025-06-04 14:51:45,970 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 14:51:45,971 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 15:09:21,890 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 15:09:22,182 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 15:09:22,183 INFO  [utils.enrich_polygons ]              ================ processing chunk 41 ================\n",
      "2025-06-04 15:09:23,162 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 15:09:23,808 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 15:09:23,808 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3223044 \n",
      "2025-06-04 15:09:23,809 INFO  [utils.enrich_polygons ]                 records for summary: 1985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:09:23,809 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 15:09:23,809 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 15:15:55,344 INFO  [utils.enrich_polygons ]                 joined records: 55433\n",
      "2025-06-04 15:15:55,345 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 15:15:55,345 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 15:20:49,107 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 15:20:49,287 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 15:20:50,681 INFO  [utils.enrich_polygons ]                 time for summarizing veg types: 35658.63615942001\n",
      "2025-06-04 15:20:51,617 INFO  [utils.enrich_polygons ]              enrich step 7/32 select records where BROAD_VEGETATION_TYPE is not null\n",
      "2025-06-04 15:20:51,625 INFO  [utils.enrich_polygons ]              enrich step 8/32 set BVT_USERD of the selected records to YES\n",
      "2025-06-04 15:20:51,627 INFO  [utils.enrich_polygons ]              enrich step 9/32 select records where BROAD_VEGETATION_TYPE is null\n",
      "2025-06-04 15:20:51,634 INFO  [utils.enrich_polygons ]              enrich step 11/32 set BVT_USERD of the selected records to NO\n",
      "2025-06-04 15:20:51,655 INFO  [utils.enrich_polygons ]              enrich step 12/32 keeping only the necessary columns\n",
      "2025-06-04 15:20:52,480 INFO  [utils.enrich_polygons ]           Calculating WUI...\n",
      "2025-06-04 15:20:52,675 INFO  [utils.enrich_polygons ]              Loaded WUI from cache\n",
      "2025-06-04 15:20:52,675 INFO  [utils.enrich_polygons ]                 time for loading WUI: 0.19417047500610352\n",
      "2025-06-04 15:20:52,676 INFO  [utils.enrich_polygons ]              enrich step 13/32 select records with null WUI\n",
      "2025-06-04 15:20:52,750 INFO  [utils.enrich_polygons ]              enrich step 14/32 select by WUI location\n",
      "2025-06-04 15:21:53,783 INFO  [utils.enrich_polygons ]              enrich step 15/32 calculate WUI yes\n",
      "2025-06-04 15:21:53,784 INFO  [utils.enrich_polygons ]              enrich step 16/32 select remaining null records\n",
      "2025-06-04 15:21:53,845 INFO  [utils.enrich_polygons ]              enrich step 17/32 calculate WUI no\n",
      "2025-06-04 15:21:53,846 INFO  [utils.enrich_polygons ]              enrich step 18/32 feature to point\n",
      "2025-06-04 15:21:55,401 INFO  [utils.enrich_polygons ]              enrich step 19/32 setup ORIG_FID\n",
      "2025-06-04 15:21:55,403 INFO  [utils.enrich_polygons ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-06-04 15:21:55,920 INFO  [utils.enrich_polygons ]              Loaded CALFIRE_Ownership_Update from cache\n",
      "2025-06-04 15:21:55,920 INFO  [utils.enrich_polygons ]                 time for loading CALFIRE_Ownership_Update: 0.516880989074707\n",
      "2025-06-04 15:21:55,937 INFO  [utils.enrich_polygons ]              Loaded WFRTF_Regions from cache\n",
      "2025-06-04 15:21:55,937 INFO  [utils.enrich_polygons ]                 time for loading WFRTF_Regions: 0.016559600830078125\n",
      "2025-06-04 15:21:55,938 INFO  [utils.enrich_polygons ]              enrich step 20/32 spatial join ownership\n",
      "2025-06-04 15:26:37,977 INFO  [utils.enrich_polygons ]              enrich step 21/32 spatial join with regions layer\n",
      "2025-06-04 15:27:36,448 INFO  [utils.enrich_polygons ]              enrich step 22/32 add ownership and region\n",
      "2025-06-04 15:27:37,933 INFO  [utils.enrich_polygons ]              enrich step 23/32 calculate ownership field\n",
      "2025-06-04 15:27:37,935 INFO  [utils.enrich_polygons ]              enrich step 24/32 calculate county field\n",
      "2025-06-04 15:27:37,936 INFO  [utils.enrich_polygons ]              enrich step 25/32 calculate region field\n",
      "2025-06-04 15:27:37,938 INFO  [utils.enrich_polygons ]              enrich step 26/32 set TRMT_GEOM\n",
      "2025-06-04 15:27:37,939 INFO  [utils.enrich_polygons ]              enrich step 27/32 calculating years...\n",
      "2025-06-04 15:27:38,908 INFO  [utils.enrich_polygons ]              enrich step 28/32 Initiating Crosswalk...\n",
      "2025-06-04 15:27:38,908 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-06-04 15:27:38,908 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-06-04 15:27:38,957 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-06-04 15:27:39,869 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-06-04 15:27:39,899 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-06-04 15:27:39,934 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-06-04 15:27:39,941 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "2025-06-04 15:27:40,290 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-06-04 15:27:43,247 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-06-04 15:27:52,938 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-06-04 15:27:52,938 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-06-04 15:27:52,939 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-06-04 15:27:52,940 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-06-04 15:27:52,953 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-06-04 15:27:52,967 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-06-04 15:27:52,974 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-06-04 15:27:52,986 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-06-04 15:27:52,996 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-06-04 15:27:53,115 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Org is 'USFS' and Status is 'Active'\n",
      "2025-06-04 15:27:53,498 INFO  [utils.enrich_polygons ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-06-04 15:27:53,498 INFO  [utils.enrich_polygons ]              enrich step 29/32 Calculating Latitude and Longitude...\n",
      "2025-06-04 15:27:54,454 INFO  [utils.enrich_polygons ]              enrich step 30/32 calculate treatment acres\n",
      "2025-06-04 15:27:54,621 INFO  [utils.enrich_polygons ]              enrich step 31/32 removing unnecessary fields\n",
      "2025-06-04 15:27:54,871 INFO  [utils.enrich_polygons ]              enrich step 32/32 delete if County is Null\n",
      "2025-06-04 15:27:56,073 INFO  [enrich.enrich_USFS    ]  Assign Domains...\n",
      "2025-06-04 15:27:56,293 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-06-04 15:27:56,299 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-06-04 15:27:56,307 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-06-04 15:27:56,312 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-06-04 15:27:56,320 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-06-04 15:27:56,325 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-06-04 15:27:56,332 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-06-04 15:27:56,338 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-06-04 15:27:56,344 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-06-04 15:27:56,350 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-06-04 15:27:56,356 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-06-04 15:27:56,362 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:27:56,368 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-06-04 15:27:56,374 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-06-04 15:27:56,380 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-06-04 15:27:56,386 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-06-04 15:27:56,387 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-06-04 15:27:56,393 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-06-04 15:27:56,399 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-06-04 15:27:56,405 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-06-04 15:27:56,405 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-06-04 15:27:56,635 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-06-04 15:27:56,938 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-06-04 15:27:57,370 INFO  [enrich.enrich_USFS    ]  Save Result...\n",
      "2025-06-04 15:27:57,371 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-06-04 15:27:57,371 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\USFS_1950_2025.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:28:00,692 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n",
      "2025-06-04 15:28:28,384 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\USFS_1950_2025.gdb USFS_Region05_enriched_20250604\n"
     ]
    }
   ],
   "source": [
    "output_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\USFS_{}_{}.gdb\".format(start_year, end_year)\n",
    "if __name__ == '__main__':\n",
    "    from enrich.enrich_USFS import enrich_USFS\n",
    "    #from utils.mp_df import MyDataFrame, ObjProxy\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    region_ids = [\"05\"]#[\"04\", \"05\", \"06\"]\n",
    "    for region_id in region_ids:    \n",
    "        usfs_input_gdb_path = r'D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\FACTS_V2.0\\Actv_CommonAttribute_PL_Region{}.gdb'.format(region_id)\n",
    "        usfs_input_layer_name = \"Actv_CommonAttribute_PL\"\n",
    "        output_layer_name = f\"USFS_Region{region_id}_enriched_{datetime.today().strftime('%Y%m%d')}\"\n",
    "        # init multiprocessing manager in main module for Windows fork\n",
    "\n",
    "        \n",
    "        enrich_USFS(usfs_input_gdb_path,\n",
    "                    usfs_input_layer_name,\n",
    "                    a_reference_gdb_path,\n",
    "                    start_year,\n",
    "                    end_year,\n",
    "                    output_gdb_path,\n",
    "                    output_layer_name,\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df008fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 16:03:50,899 INFO  [enrich.enrich_USFS    ]  Loading the USFS data into GeoDataFrames: Actv_CommonAttribute_PL_Region04.gdb : Actv_CommonAttribute_PL\n",
      "2025-06-04 16:03:50,900 INFO  [enrich.enrich_USFS    ]     Loading USFS data from source and cache the data\n",
      "2025-06-04 16:04:19,996 INFO  [enrich.enrich_USFS    ]        records: 337783\n",
      "2025-06-04 16:04:19,996 INFO  [enrich.enrich_USFS    ]        time for loading USFS: 29.09639286994934\n",
      "2025-06-04 16:04:19,997 INFO  [enrich.enrich_USFS    ]     all required columns are present.\n",
      "2025-06-04 16:04:25,004 INFO  [enrich.enrich_USFS    ]  Performing Standardization...\n",
      "2025-06-04 16:04:25,138 INFO  [enrich.enrich_USFS    ]     found 137057 rows with empty geometry\n",
      "2025-06-04 16:04:25,139 INFO  [enrich.enrich_USFS    ]     drop 137057 rows with empty geometry\n",
      "2025-06-04 16:04:26,229 INFO  [enrich.enrich_USFS    ]     records in California: 979\n",
      "2025-06-04 16:04:26,230 INFO  [enrich.enrich_USFS    ]     step 1/8 Selecting Features...\n",
      "2025-06-04 16:04:26,245 INFO  [enrich.enrich_USFS    ]        selected Activities have 760 records\n",
      "2025-06-04 16:04:26,245 INFO  [enrich.enrich_USFS    ]     step 2/8 Repairing Geometry...\n",
      "2025-06-04 16:04:26,337 INFO  [enrich.enrich_USFS    ]     step 3/8 Adding Fields...\n",
      "2025-06-04 16:04:26,367 INFO  [enrich.enrich_USFS    ]     step 4/8 Transfering Attributes...\n",
      "2025-06-04 16:04:26,369 INFO  [enrich.enrich_USFS    ]     step 5/8 Calculating End Date...\n",
      "2025-06-04 16:04:26,370 INFO  [enrich.enrich_USFS    ]     step 6/8 Calculating Status...\n",
      "2025-06-04 16:04:26,379 INFO  [enrich.enrich_USFS    ]     step 7/8 Activity Quantity...\n",
      "2025-06-04 16:04:26,379 INFO  [enrich.enrich_USFS    ]     step 8/8 Enter Field Values...\n",
      "2025-06-04 16:04:26,381 INFO  [enrich.enrich_USFS    ]  Remove Unnecessary Columns...\n",
      "2025-06-04 16:04:26,385 INFO  [enrich.enrich_USFS    ]  Select records between 1950 and 2025...\n",
      "2025-06-04 16:04:26,388 INFO  [enrich.enrich_USFS    ]  Enriching Dataset...\n",
      "2025-06-04 16:04:26,388 INFO  [utils.enrich_polygons ]        Executing Polygon Enrichments...\n",
      "2025-06-04 16:04:26,389 INFO  [utils.enrich_polygons ]           Calculating Broad Vegetation Type...\n",
      "2025-06-04 16:04:26,389 INFO  [utils.enrich_polygons ]              enrich step 1/32 summarize veg within polygons\n",
      "2025-06-04 16:04:32,149 INFO  [utils.enrich_polygons ]                 Loaded Broad_Vegetation_Types from cache\n",
      "2025-06-04 16:04:32,150 INFO  [utils.enrich_polygons ]                    time for loading Broad_Vegetation_Types: 5.759950876235962\n",
      "2025-06-04 16:04:32,155 INFO  [utils.enrich_polygons ]              create numerical intermediate columns before multiprocessing\n",
      "2025-06-04 16:04:32,158 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 16:04:32,354 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 16:04:32,355 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 135255 \n",
      "2025-06-04 16:04:32,355 INFO  [utils.enrich_polygons ]                 records for summary: 760\n",
      "2025-06-04 16:04:32,356 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 16:04:32,356 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 16:04:33,540 INFO  [utils.enrich_polygons ]                 joined records: 5425\n",
      "2025-06-04 16:04:33,541 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 16:04:33,541 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 16:05:27,280 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 16:05:27,281 INFO  [utils.enrich_polygons ]                 time for summarizing veg types: 55.13131666183472\n",
      "2025-06-04 16:05:27,288 INFO  [utils.enrich_polygons ]              enrich step 7/32 select records where BROAD_VEGETATION_TYPE is not null\n",
      "2025-06-04 16:05:27,288 INFO  [utils.enrich_polygons ]              enrich step 8/32 set BVT_USERD of the selected records to YES\n",
      "2025-06-04 16:05:27,289 INFO  [utils.enrich_polygons ]              enrich step 9/32 select records where BROAD_VEGETATION_TYPE is null\n",
      "2025-06-04 16:05:27,289 INFO  [utils.enrich_polygons ]              enrich step 11/32 set BVT_USERD of the selected records to NO\n",
      "2025-06-04 16:05:27,292 INFO  [utils.enrich_polygons ]              enrich step 12/32 keeping only the necessary columns\n",
      "2025-06-04 16:05:29,481 INFO  [utils.enrich_polygons ]           Calculating WUI...\n",
      "2025-06-04 16:05:29,676 INFO  [utils.enrich_polygons ]              Loaded WUI from cache\n",
      "2025-06-04 16:05:29,677 INFO  [utils.enrich_polygons ]                 time for loading WUI: 0.19523978233337402\n",
      "2025-06-04 16:05:29,677 INFO  [utils.enrich_polygons ]              enrich step 13/32 select records with null WUI\n",
      "2025-06-04 16:05:29,682 INFO  [utils.enrich_polygons ]              enrich step 14/32 select by WUI location\n",
      "2025-06-04 16:05:29,730 INFO  [utils.enrich_polygons ]              enrich step 15/32 calculate WUI yes\n",
      "2025-06-04 16:05:29,731 INFO  [utils.enrich_polygons ]              enrich step 16/32 select remaining null records\n",
      "2025-06-04 16:05:29,735 INFO  [utils.enrich_polygons ]              enrich step 17/32 calculate WUI no\n",
      "2025-06-04 16:05:29,736 INFO  [utils.enrich_polygons ]              enrich step 18/32 feature to point\n",
      "2025-06-04 16:05:29,740 INFO  [utils.enrich_polygons ]              enrich step 19/32 setup ORIG_FID\n",
      "2025-06-04 16:05:29,741 INFO  [utils.enrich_polygons ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-06-04 16:05:30,211 INFO  [utils.enrich_polygons ]              Loaded CALFIRE_Ownership_Update from cache\n",
      "2025-06-04 16:05:30,211 INFO  [utils.enrich_polygons ]                 time for loading CALFIRE_Ownership_Update: 0.47026753425598145\n",
      "2025-06-04 16:05:30,222 INFO  [utils.enrich_polygons ]              Loaded WFRTF_Regions from cache\n",
      "2025-06-04 16:05:30,223 INFO  [utils.enrich_polygons ]                 time for loading WFRTF_Regions: 0.011296987533569336\n",
      "2025-06-04 16:05:30,223 INFO  [utils.enrich_polygons ]              enrich step 20/32 spatial join ownership\n",
      "2025-06-04 16:05:30,504 INFO  [utils.enrich_polygons ]              enrich step 21/32 spatial join with regions layer\n",
      "2025-06-04 16:05:30,554 INFO  [utils.enrich_polygons ]              enrich step 22/32 add ownership and region\n",
      "2025-06-04 16:05:30,560 INFO  [utils.enrich_polygons ]              enrich step 23/32 calculate ownership field\n",
      "2025-06-04 16:05:30,560 INFO  [utils.enrich_polygons ]              enrich step 24/32 calculate county field\n",
      "2025-06-04 16:05:30,561 INFO  [utils.enrich_polygons ]              enrich step 25/32 calculate region field\n",
      "2025-06-04 16:05:30,561 INFO  [utils.enrich_polygons ]              enrich step 26/32 set TRMT_GEOM\n",
      "2025-06-04 16:05:30,561 INFO  [utils.enrich_polygons ]              enrich step 27/32 calculating years...\n",
      "2025-06-04 16:05:30,565 INFO  [utils.enrich_polygons ]              enrich step 28/32 Initiating Crosswalk...\n",
      "2025-06-04 16:05:30,565 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-06-04 16:05:30,565 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-06-04 16:05:30,597 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-06-04 16:05:30,601 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-06-04 16:05:30,602 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-06-04 16:05:30,603 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-06-04 16:05:30,603 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "2025-06-04 16:05:30,605 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-06-04 16:05:30,613 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-06-04 16:05:30,634 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 16:05:30,635 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-06-04 16:05:30,635 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-06-04 16:05:30,635 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-06-04 16:05:30,636 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-06-04 16:05:30,637 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-06-04 16:05:30,637 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-06-04 16:05:30,638 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-06-04 16:05:30,638 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-06-04 16:05:30,639 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Org is 'USFS' and Status is 'Active'\n",
      "2025-06-04 16:05:30,642 INFO  [utils.enrich_polygons ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-06-04 16:05:30,643 INFO  [utils.enrich_polygons ]              enrich step 29/32 Calculating Latitude and Longitude...\n",
      "2025-06-04 16:05:30,647 INFO  [utils.enrich_polygons ]              enrich step 30/32 calculate treatment acres\n",
      "2025-06-04 16:05:30,648 INFO  [utils.enrich_polygons ]              enrich step 31/32 removing unnecessary fields\n",
      "2025-06-04 16:05:30,658 INFO  [utils.enrich_polygons ]              enrich step 32/32 delete if County is Null\n",
      "2025-06-04 16:05:30,847 INFO  [enrich.enrich_USFS    ]  Assign Domains...\n",
      "2025-06-04 16:05:30,921 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-06-04 16:05:30,928 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-06-04 16:05:30,936 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-06-04 16:05:30,941 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-06-04 16:05:30,948 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-06-04 16:05:30,954 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-06-04 16:05:30,959 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-06-04 16:05:30,965 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-06-04 16:05:30,971 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-06-04 16:05:30,976 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-06-04 16:05:30,982 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-06-04 16:05:30,987 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-06-04 16:05:30,993 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-06-04 16:05:30,999 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-06-04 16:05:31,005 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-06-04 16:05:31,010 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-06-04 16:05:31,011 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-06-04 16:05:31,016 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-06-04 16:05:31,022 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-06-04 16:05:31,027 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-06-04 16:05:31,028 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-06-04 16:05:31,037 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-06-04 16:05:31,046 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-06-04 16:05:31,062 INFO  [enrich.enrich_USFS    ]  Save Result...\n",
      "2025-06-04 16:05:31,062 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-06-04 16:05:31,062 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-06-04 16:05:31,068 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n",
      "2025-06-04 16:05:31,164 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\USFS_1950_2025.gdb USFS_Region04_enriched_20250604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\USFS_1950_2025.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 16:05:31,401 INFO  [enrich.enrich_USFS    ]  Loading the USFS data into GeoDataFrames: Actv_CommonAttribute_PL_Region06.gdb : Actv_CommonAttribute_PL\n",
      "2025-06-04 16:05:31,402 INFO  [enrich.enrich_USFS    ]     Loading USFS data from source and cache the data\n",
      "2025-06-04 16:07:14,442 INFO  [enrich.enrich_USFS    ]        records: 1213138\n",
      "2025-06-04 16:07:14,442 INFO  [enrich.enrich_USFS    ]        time for loading USFS: 103.04078197479248\n",
      "2025-06-04 16:07:14,443 INFO  [enrich.enrich_USFS    ]     all required columns are present.\n",
      "2025-06-04 16:07:39,281 INFO  [enrich.enrich_USFS    ]  Performing Standardization...\n",
      "2025-06-04 16:07:39,523 INFO  [enrich.enrich_USFS    ]     found 181936 rows with empty geometry\n",
      "2025-06-04 16:07:39,524 INFO  [enrich.enrich_USFS    ]     drop 181936 rows with empty geometry\n",
      "2025-06-04 16:07:44,763 INFO  [enrich.enrich_USFS    ]     records in California: 1205\n",
      "2025-06-04 16:07:44,764 INFO  [enrich.enrich_USFS    ]     step 1/8 Selecting Features...\n",
      "2025-06-04 16:07:44,780 INFO  [enrich.enrich_USFS    ]        selected Activities have 681 records\n",
      "2025-06-04 16:07:44,781 INFO  [enrich.enrich_USFS    ]     step 2/8 Repairing Geometry...\n",
      "2025-06-04 16:07:45,210 INFO  [enrich.enrich_USFS    ]     step 3/8 Adding Fields...\n",
      "2025-06-04 16:07:45,238 INFO  [enrich.enrich_USFS    ]     step 4/8 Transfering Attributes...\n",
      "2025-06-04 16:07:45,240 INFO  [enrich.enrich_USFS    ]     step 5/8 Calculating End Date...\n",
      "2025-06-04 16:07:45,242 INFO  [enrich.enrich_USFS    ]     step 6/8 Calculating Status...\n",
      "2025-06-04 16:07:45,250 INFO  [enrich.enrich_USFS    ]     step 7/8 Activity Quantity...\n",
      "2025-06-04 16:07:45,251 INFO  [enrich.enrich_USFS    ]     step 8/8 Enter Field Values...\n",
      "2025-06-04 16:07:45,252 INFO  [enrich.enrich_USFS    ]  Remove Unnecessary Columns...\n",
      "2025-06-04 16:07:45,255 INFO  [enrich.enrich_USFS    ]  Select records between 1950 and 2025...\n",
      "2025-06-04 16:07:45,257 INFO  [enrich.enrich_USFS    ]  Enriching Dataset...\n",
      "2025-06-04 16:07:45,258 INFO  [utils.enrich_polygons ]        Executing Polygon Enrichments...\n",
      "2025-06-04 16:07:45,258 INFO  [utils.enrich_polygons ]           Calculating Broad Vegetation Type...\n",
      "2025-06-04 16:07:45,258 INFO  [utils.enrich_polygons ]              enrich step 1/32 summarize veg within polygons\n",
      "2025-06-04 16:07:50,613 INFO  [utils.enrich_polygons ]                 Loaded Broad_Vegetation_Types from cache\n",
      "2025-06-04 16:07:50,614 INFO  [utils.enrich_polygons ]                    time for loading Broad_Vegetation_Types: 5.355029821395874\n",
      "2025-06-04 16:07:50,618 INFO  [utils.enrich_polygons ]              create numerical intermediate columns before multiprocessing\n",
      "2025-06-04 16:07:50,621 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 16:07:50,799 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 16:07:50,800 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3656 \n",
      "2025-06-04 16:07:50,800 INFO  [utils.enrich_polygons ]                 records for summary: 681\n",
      "2025-06-04 16:07:50,801 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 16:07:50,801 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 16:07:53,941 INFO  [utils.enrich_polygons ]                 joined records: 3277\n",
      "2025-06-04 16:07:53,942 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 16:07:53,942 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 16:08:45,208 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 16:08:45,210 INFO  [utils.enrich_polygons ]                 time for summarizing veg types: 54.59548211097717\n",
      "2025-06-04 16:08:45,216 INFO  [utils.enrich_polygons ]              enrich step 7/32 select records where BROAD_VEGETATION_TYPE is not null\n",
      "2025-06-04 16:08:45,216 INFO  [utils.enrich_polygons ]              enrich step 8/32 set BVT_USERD of the selected records to YES\n",
      "2025-06-04 16:08:45,217 INFO  [utils.enrich_polygons ]              enrich step 9/32 select records where BROAD_VEGETATION_TYPE is null\n",
      "2025-06-04 16:08:45,218 INFO  [utils.enrich_polygons ]              enrich step 11/32 set BVT_USERD of the selected records to NO\n",
      "2025-06-04 16:08:45,220 INFO  [utils.enrich_polygons ]              enrich step 12/32 keeping only the necessary columns\n",
      "2025-06-04 16:08:47,984 INFO  [utils.enrich_polygons ]           Calculating WUI...\n",
      "2025-06-04 16:08:48,187 INFO  [utils.enrich_polygons ]              Loaded WUI from cache\n",
      "2025-06-04 16:08:48,188 INFO  [utils.enrich_polygons ]                 time for loading WUI: 0.20336318016052246\n",
      "2025-06-04 16:08:48,188 INFO  [utils.enrich_polygons ]              enrich step 13/32 select records with null WUI\n",
      "2025-06-04 16:08:48,192 INFO  [utils.enrich_polygons ]              enrich step 14/32 select by WUI location\n",
      "2025-06-04 16:08:48,230 INFO  [utils.enrich_polygons ]              enrich step 15/32 calculate WUI yes\n",
      "2025-06-04 16:08:48,230 INFO  [utils.enrich_polygons ]              enrich step 16/32 select remaining null records\n",
      "2025-06-04 16:08:48,234 INFO  [utils.enrich_polygons ]              enrich step 17/32 calculate WUI no\n",
      "2025-06-04 16:08:48,235 INFO  [utils.enrich_polygons ]              enrich step 18/32 feature to point\n",
      "2025-06-04 16:08:48,238 INFO  [utils.enrich_polygons ]              enrich step 19/32 setup ORIG_FID\n",
      "2025-06-04 16:08:48,239 INFO  [utils.enrich_polygons ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-06-04 16:08:48,746 INFO  [utils.enrich_polygons ]              Loaded CALFIRE_Ownership_Update from cache\n",
      "2025-06-04 16:08:48,746 INFO  [utils.enrich_polygons ]                 time for loading CALFIRE_Ownership_Update: 0.507314920425415\n",
      "2025-06-04 16:08:48,768 INFO  [utils.enrich_polygons ]              Loaded WFRTF_Regions from cache\n",
      "2025-06-04 16:08:48,768 INFO  [utils.enrich_polygons ]                 time for loading WFRTF_Regions: 0.02144765853881836\n",
      "2025-06-04 16:08:48,768 INFO  [utils.enrich_polygons ]              enrich step 20/32 spatial join ownership\n",
      "2025-06-04 16:08:49,170 INFO  [utils.enrich_polygons ]              enrich step 21/32 spatial join with regions layer\n",
      "2025-06-04 16:08:49,273 INFO  [utils.enrich_polygons ]              enrich step 22/32 add ownership and region\n",
      "2025-06-04 16:08:49,279 INFO  [utils.enrich_polygons ]              enrich step 23/32 calculate ownership field\n",
      "2025-06-04 16:08:49,279 INFO  [utils.enrich_polygons ]              enrich step 24/32 calculate county field\n",
      "2025-06-04 16:08:49,280 INFO  [utils.enrich_polygons ]              enrich step 25/32 calculate region field\n",
      "2025-06-04 16:08:49,280 INFO  [utils.enrich_polygons ]              enrich step 26/32 set TRMT_GEOM\n",
      "2025-06-04 16:08:49,280 INFO  [utils.enrich_polygons ]              enrich step 27/32 calculating years...\n",
      "2025-06-04 16:08:49,284 INFO  [utils.enrich_polygons ]              enrich step 28/32 Initiating Crosswalk...\n",
      "2025-06-04 16:08:49,284 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-06-04 16:08:49,284 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-06-04 16:08:49,326 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-06-04 16:08:49,330 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-06-04 16:08:49,331 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-06-04 16:08:49,332 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-06-04 16:08:49,332 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "2025-06-04 16:08:49,335 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-06-04 16:08:49,341 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-06-04 16:08:49,362 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 16:08:49,362 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-06-04 16:08:49,362 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-06-04 16:08:49,363 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-06-04 16:08:49,364 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-06-04 16:08:49,364 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-06-04 16:08:49,364 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-06-04 16:08:49,365 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-06-04 16:08:49,365 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-06-04 16:08:49,366 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Org is 'USFS' and Status is 'Active'\n",
      "2025-06-04 16:08:49,369 INFO  [utils.enrich_polygons ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-06-04 16:08:49,369 INFO  [utils.enrich_polygons ]              enrich step 29/32 Calculating Latitude and Longitude...\n",
      "2025-06-04 16:08:49,375 INFO  [utils.enrich_polygons ]              enrich step 30/32 calculate treatment acres\n",
      "2025-06-04 16:08:49,376 INFO  [utils.enrich_polygons ]              enrich step 31/32 removing unnecessary fields\n",
      "2025-06-04 16:08:49,378 INFO  [utils.enrich_polygons ]              enrich step 32/32 delete if County is Null\n",
      "2025-06-04 16:08:49,577 INFO  [enrich.enrich_USFS    ]  Assign Domains...\n",
      "2025-06-04 16:08:49,652 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-06-04 16:08:49,658 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-06-04 16:08:49,665 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-06-04 16:08:49,670 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-06-04 16:08:49,678 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-06-04 16:08:49,720 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-06-04 16:08:49,726 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-06-04 16:08:49,732 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-06-04 16:08:49,737 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-06-04 16:08:49,743 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-06-04 16:08:49,749 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-06-04 16:08:49,754 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-06-04 16:08:49,760 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-06-04 16:08:49,766 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-06-04 16:08:49,773 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-06-04 16:08:49,778 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-06-04 16:08:49,779 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-06-04 16:08:49,785 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-06-04 16:08:49,790 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-06-04 16:08:49,797 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-06-04 16:08:49,797 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-06-04 16:08:49,807 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-06-04 16:08:49,818 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-06-04 16:08:49,835 INFO  [enrich.enrich_USFS    ]  Save Result...\n",
      "2025-06-04 16:08:49,836 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-06-04 16:08:49,836 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-06-04 16:08:49,842 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n",
      "2025-06-04 16:08:49,946 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\USFS_1950_2025.gdb USFS_Region06_enriched_20250604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\USFS_1950_2025.gdb\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    region_ids = [\"04\", \"06\"]\n",
    "    for region_id in region_ids:    \n",
    "        usfs_input_gdb_path = r'D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\FACTS_V2.0\\Actv_CommonAttribute_PL_Region{}.gdb'.format(region_id)\n",
    "        usfs_input_layer_name = \"Actv_CommonAttribute_PL\"\n",
    "        output_layer_name = f\"USFS_Region{region_id}_enriched_{datetime.today().strftime('%Y%m%d')}\"\n",
    "        # init multiprocessing manager in main module for Windows fork\n",
    "\n",
    "        \n",
    "        enrich_USFS(usfs_input_gdb_path,\n",
    "                    usfs_input_layer_name,\n",
    "                    a_reference_gdb_path,\n",
    "                    start_year,\n",
    "                    end_year,\n",
    "                    output_gdb_path,\n",
    "                    output_layer_name,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cdea36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrich.enrich_Timber_Nonspatial import enrich_Timber_Nonspatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb45224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tn_input_excel_path = r'D:\\WORK\\wildfire\\Interagency-Tracking-System\\2023\\Industry_nonspatial_2023\\Timber_Industry_Acres_{}.xlsx'\n",
    "output_gdb_path =  r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\tmp\\Timber_Nonspatial_{}_{}.gdb\".format(start_year, end_year)\n",
    "output_layer_name = f\"Timber_Nonspatial_{datetime.today().strftime('%Y%m%d')}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2ce6895",
   "metadata": {},
   "source": [
    "# concat all timber nonspatial xlsx files\n",
    "tn21_df = pd.read_excel(tn_input_excel_path.format(2021))\n",
    "tn22_df = pd.read_excel(tn_input_excel_path.format(2022))\n",
    "tn23_df = pd.read_excel(tn_input_excel_path.format(2023))\n",
    "tn_df = pd.concat([tn21_df, tn22_df, tn23_df])\n",
    "tn_df.to_excel(tn_input_excel_path.format('concat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "510e50f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tn_input_excel_path = r'D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\Industry_nonspatial_V2.0\\timber2024concat.xlsx'\n",
    "output_gdb_path =  r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\Timber_Nonspatial_{}_{}.gdb\".format(start_year, end_year)\n",
    "output_layer_name = f\"Timber_Nonspatial_{datetime.today().strftime('%Y%m%d')}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33e7c393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 11:57:17,548 INFO  [enrich.Timber_NSpatial]  Load the Timeber Industry Nonspatial data into a DataFrame\n",
      "2025-05-23 11:57:17,657 INFO  [enrich.Timber_NSpatial]     time for loading D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\Industry_nonspatial_V2.0\\Timber Industry Acres 2024 for UCSD 13May2025.xlsx: 0.10840058326721191\n",
      "2025-05-23 11:57:17,657 INFO  [enrich.Timber_NSpatial]  Performing Standardization\n",
      "2025-05-23 11:57:17,657 INFO  [enrich.Timber_NSpatial]     step 1/10 convert Excel sheet to table\n",
      "2025-05-23 11:57:17,662 INFO  [enrich.Timber_NSpatial]     all required columns are present.\n",
      "2025-05-23 11:57:17,663 INFO  [enrich.Timber_NSpatial]     step 2/10 rename and add fields\n",
      "2025-05-23 11:57:17,663 INFO  [enrich.Timber_NSpatial]     step 3/10 adding common columns...\n",
      "2025-05-23 11:57:17,684 INFO  [enrich.Timber_NSpatial]     step 4/10 calculate fields\n",
      "2025-05-23 11:57:17,686 INFO  [enrich.Timber_NSpatial]     step 5/10 converting Table to Geodataframe\n",
      "2025-05-23 11:57:17,715 INFO  [enrich.Timber_NSpatial]     step 6/10 Remove Unnecessary Columns...\n",
      "2025-05-23 11:57:17,716 INFO  [enrich.Timber_NSpatial]     step 7/10 Enrich Points\n",
      "2025-05-23 11:57:17,717 INFO  [utils.enrich_points   ]        Executing Point Enrichments...\n",
      "2025-05-23 11:57:17,718 INFO  [utils.enrich_points   ]           Calculating WUI...\n",
      "2025-05-23 11:57:17,718 INFO  [utils.enrich_points   ]              enrich step 1/16 loading WUI from cache\n",
      "2025-05-23 11:57:17,914 INFO  [utils.enrich_points   ]                 time for loading WUI: 0.19631576538085938\n",
      "2025-05-23 11:57:17,915 INFO  [utils.enrich_points   ]              enrich step 2/16 select records with null WUI\n",
      "2025-05-23 11:57:17,916 INFO  [utils.enrich_points   ]              enrich step 3/16 select by WUI location\n",
      "2025-05-23 11:57:17,949 INFO  [utils.enrich_points   ]              enrich step 4/16 calculate WUI yes\n",
      "2025-05-23 11:57:17,949 INFO  [utils.enrich_points   ]              enrich step 5/16 select remaining null records\n",
      "2025-05-23 11:57:17,950 INFO  [utils.enrich_points   ]              enrich step 6/16 calculate WUI no\n",
      "2025-05-23 11:57:17,951 INFO  [utils.enrich_points   ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-05-23 11:57:17,951 INFO  [utils.enrich_points   ]              enrich step 7/16 loading CALFIRE_Ownership_Update from cache\n",
      "2025-05-23 11:57:18,371 INFO  [utils.enrich_points   ]                 time for loading CALFIRE_Ownership_Update: 0.419605016708374\n",
      "2025-05-23 11:57:18,371 INFO  [utils.enrich_points   ]              enrich step 8/16 spatial join ownership\n",
      "2025-05-23 11:57:18,489 INFO  [utils.enrich_points   ]              enrich step 9/16 loading WFRTF_Regions from cache\n",
      "2025-05-23 11:57:18,499 INFO  [utils.enrich_points   ]                 time for loading WFRTF_Regions: 0.010216474533081055\n",
      "2025-05-23 11:57:18,500 INFO  [utils.enrich_points   ]              enrich step 10/16 spatial join regions\n",
      "2025-05-23 11:57:18,526 INFO  [utils.enrich_points   ]              enrich step 11/16 loading Broad_Vegetation_Types from cache\n",
      "2025-05-23 11:57:22,518 INFO  [utils.enrich_points   ]                 time for loading Broad_Vegetation_Types: 4.02934718132019\n",
      "2025-05-23 11:57:22,519 INFO  [utils.enrich_points   ]              enrich step 12/16 spatial join veg and calculations\n",
      "2025-05-23 11:57:23,737 INFO  [utils.enrich_points   ]              enrich step 13/16 Initiating Crosswalk\n",
      "2025-05-23 11:57:23,737 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-05-23 11:57:23,737 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-05-23 11:57:23,773 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-05-23 11:57:23,776 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-05-23 11:57:23,776 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-05-23 11:57:23,777 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-05-23 11:57:23,778 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "2025-05-23 11:57:23,779 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-05-23 11:57:23,782 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-05-23 11:57:23,785 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-05-23 11:57:23,786 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-05-23 11:57:23,786 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-05-23 11:57:23,787 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-05-23 11:57:23,788 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-05-23 11:57:23,788 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-05-23 11:57:23,789 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-05-23 11:57:23,789 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-05-23 11:57:23,790 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-05-23 11:57:23,791 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Org is 'USFS' and Status is 'Active'\n",
      "2025-05-23 11:57:23,793 INFO  [utils.enrich_points   ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-05-23 11:57:23,793 INFO  [utils.enrich_points   ]              enrich step 14/16 calculating Years\n",
      "2025-05-23 11:57:23,795 INFO  [utils.enrich_points   ]              enrich step 15/16 calculating Latitude and Longitude\n",
      "2025-05-23 11:57:23,796 INFO  [utils.enrich_points   ]              enrich step 16/16 removing unnecessary fields\n",
      "2025-05-23 11:57:23,797 INFO  [utils.enrich_points   ]           Enrich Points Complete...\n",
      "2025-05-23 11:57:23,992 INFO  [enrich.Timber_NSpatial]     step 8/10 Fix board veg types and others\n",
      "2025-05-23 11:57:23,994 INFO  [enrich.Timber_NSpatial]     step 9/10 Assign Domains...\n",
      "2025-05-23 11:57:24,175 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-05-23 11:57:24,181 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-05-23 11:57:24,188 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-05-23 11:57:24,194 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-05-23 11:57:24,201 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-05-23 11:57:24,206 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-05-23 11:57:24,212 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-05-23 11:57:24,218 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-05-23 11:57:24,224 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-05-23 11:57:24,229 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-05-23 11:57:24,235 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-05-23 11:57:24,241 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-05-23 11:57:24,246 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-05-23 11:57:24,253 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-05-23 11:57:24,259 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-05-23 11:57:24,265 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-05-23 11:57:24,265 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-05-23 11:57:24,271 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 11:57:24,277 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-05-23 11:57:24,282 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-05-23 11:57:24,283 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-05-23 11:57:24,287 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-05-23 11:57:24,292 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-05-23 11:57:24,301 INFO  [enrich.Timber_NSpatial]     step 10/10 Save Result...\n",
      "2025-05-23 11:57:24,301 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-05-23 11:57:24,301 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-05-23 11:57:24,302 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n",
      "2025-05-23 11:57:24,376 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\Timber_Nonspatial_1950_2025.gdb Timber_Nonspatial_20250523\n",
      "2025-05-23 11:57:24,377 INFO  [its_logging.logger_config]  Memory usage: 4017.34 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\Timber_Nonspatial_1950_2025.gdb\n"
     ]
    }
   ],
   "source": [
    "enrich_Timber_Nonspatial(tn_input_excel_path.format('concat'),\n",
    "                         a_reference_gdb_path,\n",
    "                         start_year,\n",
    "                         end_year,\n",
    "                         output_gdb_path,\n",
    "                         output_layer_name)\n",
    "\n",
    "# Get memory usage in bytes, convert to MB\n",
    "memory_usage = process.memory_info().rss / 1024 / 1024\n",
    "logger.info(f\"Memory usage: {memory_usage:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0e711e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrich.enrich_NPS import enrich_NPS_from_gdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0aa83f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nps_gdb_path = r'D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\NPS_V2.0\\NPS_V2.0\\NPS_V2_0_20250331.shp'\n",
    "nps_layer_name = None\n",
    "output_gdb_path =  r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\NPS_{}_{}.gdb\".format(start_year, end_year)\n",
    "output_layer_name = f\"NPS_enriched_{datetime.today().strftime('%Y%m%d')}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d86e3a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 12:13:09,392 INFO  [enrich.enrich_NPS     ]  Load the NPS data into a GeoDataFrame\n",
      "2025-07-18 12:13:09,808 INFO  [enrich.enrich_NPS     ]     time for loading None: 0.4152565002441406\n",
      "2025-07-18 12:13:09,809 INFO  [enrich.enrich_NPS     ]     all required columns are present.\n",
      "2025-07-18 12:13:10,244 INFO  [enrich.enrich_NPS     ]  Performing Standardization...\n",
      "2025-07-18 12:13:10,244 INFO  [enrich.enrich_NPS     ]     step 1/11 select after 1995\n",
      "2025-07-18 12:13:10,261 INFO  [enrich.enrich_NPS     ]     step 2/11 repairing geometry\n",
      "2025-07-18 12:13:13,107 INFO  [enrich.enrich_NPS     ]     step 3/11 clip features by CA\n",
      "2025-07-18 12:13:23,198 INFO  [enrich.enrich_NPS     ]     step 4/11 dissolve to implement multipart polygons\n",
      "2025-07-18 12:13:23,723 INFO  [enrich.enrich_NPS     ]     step 5/11 rename and add fields\n",
      "2025-07-18 12:13:23,747 INFO  [enrich.enrich_NPS     ]     step 6/11 import attributes\n",
      "2025-07-18 12:13:23,767 INFO  [enrich.enrich_NPS     ]     step 7/11 Remove Unnecessary Columns...\n",
      "2025-07-18 12:13:23,769 INFO  [enrich.enrich_NPS     ]     step 8/11 Enriching Polygons...\n",
      "2025-07-18 12:13:23,769 INFO  [utils.enrich_polygons ]        Executing Polygon Enrichments...\n",
      "2025-07-18 12:13:23,770 INFO  [utils.enrich_polygons ]           Calculating Broad Vegetation Type...\n",
      "2025-07-18 12:13:23,770 INFO  [utils.enrich_polygons ]              enrich step 1/32 summarize veg within polygons\n",
      "2025-07-18 12:13:27,910 INFO  [utils.enrich_polygons ]                 Loaded Broad_Vegetation_Types from cache\n",
      "2025-07-18 12:13:27,910 INFO  [utils.enrich_polygons ]                    time for loading Broad_Vegetation_Types: 4.139890432357788\n",
      "2025-07-18 12:13:27,914 INFO  [utils.enrich_polygons ]              create numerical intermediate columns before multiprocessing\n",
      "2025-07-18 12:13:27,918 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-07-18 12:13:28,499 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-07-18 12:13:28,500 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3499647 \n",
      "2025-07-18 12:13:28,500 INFO  [utils.enrich_polygons ]                 records for summary: 831\n",
      "2025-07-18 12:13:28,501 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-07-18 12:13:28,501 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-07-18 12:13:50,798 INFO  [utils.enrich_polygons ]                 joined records: 20391\n",
      "2025-07-18 12:13:50,799 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-07-18 12:13:50,799 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-07-18 12:14:55,700 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-07-18 12:14:55,701 INFO  [utils.enrich_polygons ]                 time for summarizing veg types: 87.79056334495544\n",
      "2025-07-18 12:14:55,707 INFO  [utils.enrich_polygons ]              enrich step 7/32 select records where BROAD_VEGETATION_TYPE is not null\n",
      "2025-07-18 12:14:55,708 INFO  [utils.enrich_polygons ]              enrich step 8/32 set BVT_USERD of the selected records to YES\n",
      "2025-07-18 12:14:55,708 INFO  [utils.enrich_polygons ]              enrich step 9/32 select records where BROAD_VEGETATION_TYPE is null\n",
      "2025-07-18 12:14:55,708 INFO  [utils.enrich_polygons ]              enrich step 11/32 set BVT_USERD of the selected records to NO\n",
      "2025-07-18 12:14:55,711 INFO  [utils.enrich_polygons ]              enrich step 12/32 keeping only the necessary columns\n",
      "2025-07-18 12:14:55,840 INFO  [utils.enrich_polygons ]           Calculating WUI...\n",
      "2025-07-18 12:14:56,001 INFO  [utils.enrich_polygons ]              Loaded WUI from cache\n",
      "2025-07-18 12:14:56,001 INFO  [utils.enrich_polygons ]                 time for loading WUI: 0.16117453575134277\n",
      "2025-07-18 12:14:56,002 INFO  [utils.enrich_polygons ]              enrich step 13/32 select records with null WUI\n",
      "2025-07-18 12:14:56,006 INFO  [utils.enrich_polygons ]              enrich step 14/32 select by WUI location\n",
      "2025-07-18 12:14:57,911 INFO  [utils.enrich_polygons ]              enrich step 15/32 calculate WUI yes\n",
      "2025-07-18 12:14:57,911 INFO  [utils.enrich_polygons ]              enrich step 16/32 select remaining null records\n",
      "2025-07-18 12:14:57,915 INFO  [utils.enrich_polygons ]              enrich step 17/32 calculate WUI no\n",
      "2025-07-18 12:14:57,916 INFO  [utils.enrich_polygons ]              enrich step 18/32 feature to point\n",
      "2025-07-18 12:14:57,922 INFO  [utils.enrich_polygons ]              enrich step 19/32 setup ORIG_FID\n",
      "2025-07-18 12:14:57,922 INFO  [utils.enrich_polygons ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-07-18 12:14:58,363 INFO  [utils.enrich_polygons ]              Loaded CALFIRE_Ownership_Update from cache\n",
      "2025-07-18 12:14:58,364 INFO  [utils.enrich_polygons ]                 time for loading CALFIRE_Ownership_Update: 0.44112586975097656\n",
      "2025-07-18 12:14:58,382 INFO  [utils.enrich_polygons ]              Loaded WFRTF_Regions from cache\n",
      "2025-07-18 12:14:58,383 INFO  [utils.enrich_polygons ]                 time for loading WFRTF_Regions: 0.01890420913696289\n",
      "2025-07-18 12:14:58,383 INFO  [utils.enrich_polygons ]              enrich step 20/32 spatial join ownership\n",
      "2025-07-18 12:14:59,033 INFO  [utils.enrich_polygons ]              enrich step 21/32 spatial join with regions layer\n",
      "2025-07-18 12:14:59,174 INFO  [utils.enrich_polygons ]              enrich step 22/32 add ownership and region\n",
      "2025-07-18 12:14:59,180 INFO  [utils.enrich_polygons ]              enrich step 23/32 calculate ownership field\n",
      "2025-07-18 12:14:59,181 INFO  [utils.enrich_polygons ]              enrich step 24/32 calculate county field\n",
      "2025-07-18 12:14:59,181 INFO  [utils.enrich_polygons ]              enrich step 25/32 calculate region field\n",
      "2025-07-18 12:14:59,182 INFO  [utils.enrich_polygons ]              enrich step 26/32 set TRMT_GEOM\n",
      "2025-07-18 12:14:59,182 INFO  [utils.enrich_polygons ]              enrich step 27/32 calculating years...\n",
      "2025-07-18 12:14:59,186 INFO  [utils.enrich_polygons ]              enrich step 28/32 Initiating Crosswalk...\n",
      "2025-07-18 12:14:59,186 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-07-18 12:14:59,187 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-07-18 12:14:59,228 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-07-18 12:14:59,233 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-07-18 12:14:59,234 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-07-18 12:14:59,235 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-07-18 12:14:59,236 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "2025-07-18 12:14:59,241 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-07-18 12:14:59,249 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-07-18 12:14:59,273 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-07-18 12:14:59,274 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 12:14:59,274 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-07-18 12:14:59,274 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-07-18 12:14:59,275 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-07-18 12:14:59,276 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-07-18 12:14:59,277 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-07-18 12:14:59,277 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-07-18 12:14:59,278 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-07-18 12:14:59,279 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Org is 'USFS' and Status is 'Active'\n",
      "2025-07-18 12:14:59,282 INFO  [utils.enrich_polygons ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-07-18 12:14:59,282 INFO  [utils.enrich_polygons ]              enrich step 29/32 Calculating Latitude and Longitude...\n",
      "2025-07-18 12:14:59,291 INFO  [utils.enrich_polygons ]              enrich step 30/32 calculate treatment acres\n",
      "2025-07-18 12:14:59,294 INFO  [utils.enrich_polygons ]              enrich step 31/32 removing unnecessary fields\n",
      "2025-07-18 12:14:59,297 INFO  [utils.enrich_polygons ]              enrich step 32/32 delete if County is Null\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "NOT_DEFINED\n",
      "NOT_DEFINED\n",
      "NOT_DEFINED\n",
      "NOT_DEFINED\n",
      "NOT_DEFINED\n",
      "NOT_DEFINED\n",
      "NOT_DEFINED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 12:14:59,499 INFO  [enrich.enrich_NPS     ]     step 9/11 adding treatment ID\n",
      "2025-07-18 12:14:59,509 INFO  [enrich.enrich_NPS     ]     step 10/11 Assign Domains...\n",
      "2025-07-18 12:14:59,762 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-07-18 12:14:59,770 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-07-18 12:14:59,779 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-07-18 12:14:59,786 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-07-18 12:14:59,794 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-07-18 12:14:59,800 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-07-18 12:14:59,806 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-07-18 12:14:59,813 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-07-18 12:14:59,819 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-07-18 12:14:59,825 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-07-18 12:14:59,832 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-07-18 12:14:59,838 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-07-18 12:14:59,845 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-07-18 12:14:59,851 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-07-18 12:14:59,858 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-07-18 12:14:59,864 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-07-18 12:14:59,865 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-07-18 12:14:59,871 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-07-18 12:14:59,877 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-07-18 12:14:59,883 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-07-18 12:14:59,883 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-07-18 12:14:59,889 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-07-18 12:14:59,896 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-07-18 12:14:59,907 INFO  [enrich.enrich_NPS     ]     step 11/11 Save Result...\n",
      "2025-07-18 12:14:59,907 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-07-18 12:14:59,907 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-07-18 12:14:59,913 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n",
      "2025-07-18 12:15:00,072 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\NPS_1950_2025.gdb NPS_enriched_20250718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\NPS_1950_2025.gdb\n"
     ]
    }
   ],
   "source": [
    "enrich_NPS_from_gdb(nps_gdb_path,\n",
    "                    nps_layer_name,\n",
    "                    a_reference_gdb_path,\n",
    "                    start_year,\n",
    "                    end_year,\n",
    "                    output_gdb_path,\n",
    "                    output_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "230b4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nps_gdf = gpd.read_file(output_gdb_path, driver='OpenFileGDB', layer=output_layer_name)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "27b674a3",
   "metadata": {},
   "source": [
    "NPS_gpd = enrich_NPS_from_gdb(nps_gdb_path,\n",
    "                    nps_layer_name,\n",
    "                    a_reference_gdb_path,\n",
    "                    start_year,\n",
    "                    end_year,\n",
    "                    output_gdb_path,\n",
    "                    output_layer_name)\n",
    "\n",
    "# Get memory usage in bytes, convert to MB\n",
    "memory_usage = process.memory_info().rss / 1024 / 1024\n",
    "logger.info(f\"Memory usage: {memory_usage:.2f} MB\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bbe37fd4",
   "metadata": {},
   "source": [
    "NPS_reference = gpd.read_file(r'D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\Interagency Tracking System.gdb', driver='openFileGDB', layer='nps_flat_fuels_enriched2023_20240925')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38b9d376",
   "metadata": {},
   "source": [
    "NPS_reference[['ACTIVITY_QUANTITY', 'ADMINISTERING_ORG', 'COUNTS_TO_MAS', 'PRIMARY_OBJECTIVE', \"Year_txt\"]].groupby(['ADMINISTERING_ORG', 'COUNTS_TO_MAS', 'PRIMARY_OBJECTIVE', \"Year_txt\"]).sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "554ccf80",
   "metadata": {},
   "source": [
    "NPS_output = gpd.read_file(output_gdb_path, driver='openFileGDB', layer=output_layer_name)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea0e15cd",
   "metadata": {},
   "source": [
    "NPS_output[['ACTIVITY_QUANTITY', 'ADMINISTERING_ORG', 'COUNTS_TO_MAS', 'PRIMARY_OBJECTIVE', \"Year_txt\"]].groupby(['ADMINISTERING_ORG', 'COUNTS_TO_MAS', 'PRIMARY_OBJECTIVE', \"Year_txt\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d79da30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrich.enrich_BLM import enrich_BLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86909eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "blm_input_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\BLM_V2.0\\BLM_V2.0\\BLM_V2_0_20250331.shp\"\n",
    "blm_input_layer_name = None\n",
    "output_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\BLM_{}_{}.gdb\".format(start_year, end_year)\n",
    "output_layer_name = f\"BLM_enriched_20250710\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f169405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 11:56:25,055 INFO  [enrich.enrich_BLM     ]  Load the BLM data into a GeoDataFrame\n",
      "2025-07-14 11:56:25,146 INFO  [enrich.enrich_BLM     ]     time for loading None: 0.09030699729919434\n",
      "2025-07-14 11:56:25,146 INFO  [enrich.enrich_BLM     ]     all required columns are present.\n",
      "2025-07-14 11:56:25,147 INFO  [enrich.enrich_BLM     ]  Performing Standardization...\n",
      "2025-07-14 11:56:25,147 INFO  [enrich.enrich_BLM     ]     step 1/15 Clip Features to California...\n",
      "2025-07-14 11:56:38,718 INFO  [enrich.enrich_BLM     ]     step 2/15 Repairing Geometry...\n",
      "2025-07-14 11:56:39,138 INFO  [enrich.enrich_BLM     ]     step 3/15 Adding Common Columns...\n",
      "2025-07-14 11:56:39,164 INFO  [enrich.enrich_BLM     ]     step 4/15 Transfering Values...\n",
      "2025-07-14 11:56:39,165 INFO  [enrich.enrich_BLM     ]     step 5/15 Calculating Start and End Date...\n",
      "2025-07-14 11:56:39,177 INFO  [enrich.enrich_BLM     ]     step 6/15 Calculating Status...\n",
      "2025-07-14 11:56:39,178 INFO  [enrich.enrich_BLM     ]     step 7/15 Activity Quantity...\n",
      "2025-07-14 11:56:39,189 INFO  [enrich.enrich_BLM     ]     step 8/15 Enter Column Values...\n",
      "2025-07-14 11:56:39,191 INFO  [enrich.enrich_BLM     ]     step 9/15 Adding Original Activity Description to Crosswalk Column...\n",
      "2025-07-14 11:56:39,224 INFO  [enrich.enrich_BLM     ]     step 10/15 Select by Years...\n",
      "2025-07-14 11:56:39,228 INFO  [enrich.enrich_BLM     ]     step 10/15 Create New GeoDataframe Using the Template...\n",
      "2025-07-14 11:56:39,266 INFO  [enrich.enrich_BLM     ]     step 10/15 Append to Template...\n",
      "2025-07-14 11:56:39,275 INFO  [enrich.enrich_BLM     ]     step 10/15 Calculate Treatment Geometry...\n",
      "2025-07-14 11:56:39,276 INFO  [enrich.enrich_BLM     ]     step 11/15 Remove Unnecessary Columns...\n",
      "2025-07-14 11:56:39,278 INFO  [enrich.enrich_BLM     ]     step 12/15 Enriching Polygons...\n",
      "2025-07-14 11:56:39,279 INFO  [utils.enrich_polygons ]        Executing Polygon Enrichments...\n",
      "2025-07-14 11:56:39,279 INFO  [utils.enrich_polygons ]           Calculating Broad Vegetation Type...\n",
      "2025-07-14 11:56:39,279 INFO  [utils.enrich_polygons ]              enrich step 1/32 summarize veg within polygons\n",
      "2025-07-14 11:56:44,374 INFO  [utils.enrich_polygons ]                 Loaded Broad_Vegetation_Types from cache\n",
      "2025-07-14 11:56:44,375 INFO  [utils.enrich_polygons ]                    time for loading Broad_Vegetation_Types: 5.095671892166138\n",
      "2025-07-14 11:56:44,379 INFO  [utils.enrich_polygons ]              create numerical intermediate columns before multiprocessing\n",
      "2025-07-14 11:56:44,386 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-07-14 11:56:44,983 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-07-14 11:56:44,984 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3677656 \n",
      "2025-07-14 11:56:44,984 INFO  [utils.enrich_polygons ]                 records for summary: 1220\n",
      "2025-07-14 11:56:44,984 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-07-14 11:56:44,985 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-07-14 11:57:30,003 INFO  [utils.enrich_polygons ]                 joined records: 30068\n",
      "2025-07-14 11:57:30,005 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-07-14 11:57:30,005 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-07-14 11:59:17,862 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-07-14 11:59:17,863 INFO  [utils.enrich_polygons ]                 time for summarizing veg types: 153.48784732818604\n",
      "2025-07-14 11:59:17,896 INFO  [utils.enrich_polygons ]              enrich step 7/32 select records where BROAD_VEGETATION_TYPE is not null\n",
      "2025-07-14 11:59:17,897 INFO  [utils.enrich_polygons ]              enrich step 8/32 set BVT_USERD of the selected records to YES\n",
      "2025-07-14 11:59:17,897 INFO  [utils.enrich_polygons ]              enrich step 9/32 select records where BROAD_VEGETATION_TYPE is null\n",
      "2025-07-14 11:59:17,898 INFO  [utils.enrich_polygons ]              enrich step 11/32 set BVT_USERD of the selected records to NO\n",
      "2025-07-14 11:59:17,901 INFO  [utils.enrich_polygons ]              enrich step 12/32 keeping only the necessary columns\n",
      "2025-07-14 11:59:17,964 INFO  [utils.enrich_polygons ]           Calculating WUI...\n",
      "2025-07-14 11:59:18,113 INFO  [utils.enrich_polygons ]              Loaded WUI from cache\n",
      "2025-07-14 11:59:18,113 INFO  [utils.enrich_polygons ]                 time for loading WUI: 0.14856624603271484\n",
      "2025-07-14 11:59:18,114 INFO  [utils.enrich_polygons ]              enrich step 13/32 select records with null WUI\n",
      "2025-07-14 11:59:18,116 INFO  [utils.enrich_polygons ]              enrich step 14/32 select by WUI location\n",
      "2025-07-14 11:59:21,998 INFO  [utils.enrich_polygons ]              enrich step 15/32 calculate WUI yes\n",
      "2025-07-14 11:59:21,999 INFO  [utils.enrich_polygons ]              enrich step 16/32 select remaining null records\n",
      "2025-07-14 11:59:22,002 INFO  [utils.enrich_polygons ]              enrich step 17/32 calculate WUI no\n",
      "2025-07-14 11:59:22,003 INFO  [utils.enrich_polygons ]              enrich step 18/32 feature to point\n",
      "2025-07-14 11:59:22,009 INFO  [utils.enrich_polygons ]              enrich step 19/32 setup ORIG_FID\n",
      "2025-07-14 11:59:22,010 INFO  [utils.enrich_polygons ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-07-14 11:59:22,591 INFO  [utils.enrich_polygons ]              Loaded CALFIRE_Ownership_Update from cache\n",
      "2025-07-14 11:59:22,592 INFO  [utils.enrich_polygons ]                 time for loading CALFIRE_Ownership_Update: 0.5816965103149414\n",
      "2025-07-14 11:59:22,609 INFO  [utils.enrich_polygons ]              Loaded WFRTF_Regions from cache\n",
      "2025-07-14 11:59:22,609 INFO  [utils.enrich_polygons ]                 time for loading WFRTF_Regions: 0.016805648803710938\n",
      "2025-07-14 11:59:22,609 INFO  [utils.enrich_polygons ]              enrich step 20/32 spatial join ownership\n",
      "2025-07-14 11:59:23,324 INFO  [utils.enrich_polygons ]              enrich step 21/32 spatial join with regions layer\n",
      "2025-07-14 11:59:23,540 INFO  [utils.enrich_polygons ]              enrich step 22/32 add ownership and region\n",
      "2025-07-14 11:59:23,544 INFO  [utils.enrich_polygons ]              enrich step 23/32 calculate ownership field\n",
      "2025-07-14 11:59:23,545 INFO  [utils.enrich_polygons ]              enrich step 24/32 calculate county field\n",
      "2025-07-14 11:59:23,545 INFO  [utils.enrich_polygons ]              enrich step 25/32 calculate region field\n",
      "2025-07-14 11:59:23,546 INFO  [utils.enrich_polygons ]              enrich step 26/32 set TRMT_GEOM\n",
      "2025-07-14 11:59:23,546 INFO  [utils.enrich_polygons ]              enrich step 27/32 calculating years...\n",
      "2025-07-14 11:59:23,552 INFO  [utils.enrich_polygons ]              enrich step 28/32 Initiating Crosswalk...\n",
      "2025-07-14 11:59:23,553 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-07-14 11:59:23,553 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-07-14 11:59:23,591 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-07-14 11:59:23,595 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-07-14 11:59:23,596 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-07-14 11:59:23,597 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-07-14 11:59:23,597 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "2025-07-14 11:59:23,602 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 11:59:23,611 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-07-14 11:59:23,643 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-07-14 11:59:23,643 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-07-14 11:59:23,643 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-07-14 11:59:23,644 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-07-14 11:59:23,645 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-07-14 11:59:23,646 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-07-14 11:59:23,646 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-07-14 11:59:23,646 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-07-14 11:59:23,647 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-07-14 11:59:23,648 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Org is 'USFS' and Status is 'Active'\n",
      "2025-07-14 11:59:23,651 INFO  [utils.enrich_polygons ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-07-14 11:59:23,651 INFO  [utils.enrich_polygons ]              enrich step 29/32 Calculating Latitude and Longitude...\n",
      "2025-07-14 11:59:23,667 INFO  [utils.enrich_polygons ]              enrich step 30/32 calculate treatment acres\n",
      "2025-07-14 11:59:23,669 INFO  [utils.enrich_polygons ]              enrich step 31/32 removing unnecessary fields\n",
      "2025-07-14 11:59:23,671 INFO  [utils.enrich_polygons ]              enrich step 32/32 delete if County is Null\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBD\n",
      "TBD\n",
      "NOT_DEFINED\n",
      "NOT_DEFINED\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 11:59:23,865 INFO  [enrich.enrich_BLM     ]     step 13/15 Calculate Treatment ID...\n",
      "2025-07-14 11:59:23,868 INFO  [enrich.enrich_BLM     ]     step 14/15 Assign Domains...\n",
      "2025-07-14 11:59:24,153 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-07-14 11:59:24,159 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-07-14 11:59:24,166 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-07-14 11:59:24,171 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-07-14 11:59:24,178 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-07-14 11:59:24,183 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-07-14 11:59:24,189 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-07-14 11:59:24,194 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-07-14 11:59:24,200 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-07-14 11:59:24,205 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-07-14 11:59:24,211 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-07-14 11:59:24,216 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-07-14 11:59:24,222 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-07-14 11:59:24,227 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-07-14 11:59:24,233 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-07-14 11:59:24,238 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-07-14 11:59:24,238 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-07-14 11:59:24,244 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-07-14 11:59:24,249 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-07-14 11:59:24,254 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-07-14 11:59:24,254 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-07-14 11:59:24,260 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-07-14 11:59:24,267 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-07-14 11:59:24,280 INFO  [enrich.enrich_BLM     ]     step 15/15 Save Result...\n",
      "2025-07-14 11:59:24,280 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-07-14 11:59:24,281 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-07-14 11:59:24,289 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\BLM_1950_2025.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 11:59:24,516 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\BLM_1950_2025.gdb BLM_enriched_20250710\n",
      "2025-07-14 11:59:24,527 INFO  [its_logging.logger_config]  Memory usage: 3880.41 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "enrich_BLM(blm_input_gdb_path,\n",
    "               blm_input_layer_name,\n",
    "               a_reference_gdb_path,\n",
    "               start_year,\n",
    "               end_year,\n",
    "               output_gdb_path,\n",
    "               output_layer_name)\n",
    "\n",
    "# Get memory usage in bytes, convert to MB\n",
    "memory_usage = process.memory_info().rss / 1024 / 1024\n",
    "logger.info(f\"Memory usage: {memory_usage:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3002c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrich.enrich_CNRA import enrich_CNRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aa5794b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>geometry_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TREATMENT_POINT</td>\n",
       "      <td>Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TREATMENT_LINE</td>\n",
       "      <td>MultiLineString</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TREATMENT_POLY</td>\n",
       "      <td>MultiPolygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PROJECT_POLY</td>\n",
       "      <td>MultiPolygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACTIVITIES</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name    geometry_type\n",
       "0  TREATMENT_POINT            Point\n",
       "1   TREATMENT_LINE  MultiLineString\n",
       "2   TREATMENT_POLY     MultiPolygon\n",
       "3     PROJECT_POLY     MultiPolygon\n",
       "4       ACTIVITIES             None"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpd.list_layers(r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\CNRA_V2.0\\CNRA_TRMT_DATA_Pv6c_20250620.gdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0146dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnra_input_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\CNRA_V2.0\\CNRA_TRMT_DATA_Pv6c_20250620.gdb\"\n",
    "cnra_polygon_layer_name = \"TREATMENT_POLY\"\n",
    "cnra_line_layer_name = \"TREATMENT_LINE\"\n",
    "cnra_point_layer_name = \"TREATMENT_POINT\"\n",
    "cnra_project_polygon_layer_name = \"PROJECT_POLY\"\n",
    "cnra_activity_layer_name = \"ACTIVITIES\"\n",
    "output_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\CNRA_{}_{}.gdb\".format(start_year, end_year)\n",
    "output_layer_name = f\"CNRA_enriched_{datetime.today().strftime('%Y%m%d')}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "710825bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:54:47,950 INFO  [enrich.enrich_CNRA    ]  Load the CNRA polygon layer into a GeoDataFrame\n",
      "2025-06-26 22:54:48,552 INFO  [enrich.enrich_CNRA    ]     all required columns are present.\n",
      "2025-06-26 22:54:49,456 INFO  [enrich.enrich_CNRA    ]  Load the CNRA line layer into a GeoDataFrame\n",
      "2025-06-26 22:54:49,477 INFO  [enrich.enrich_CNRA    ]     all required columns are present.\n",
      "2025-06-26 22:54:49,481 INFO  [enrich.enrich_CNRA    ]  Load the CNRA point layer into a GeoDataFrame\n",
      "2025-06-26 22:54:49,507 INFO  [enrich.enrich_CNRA    ]     all required columns are present.\n",
      "2025-06-26 22:54:49,508 INFO  [enrich.enrich_CNRA    ]  Load the CNRA project polygon layer into a GeoDataFrame\n",
      "2025-06-26 22:54:49,778 INFO  [enrich.enrich_CNRA    ]     all required columns are present.\n",
      "2025-06-26 22:54:50,335 INFO  [enrich.enrich_CNRA    ]  Load the CNRA activity layer into a DataFrame\n",
      "2025-06-26 22:54:51,230 INFO  [enrich.enrich_CNRA    ]     all required columns are present.\n",
      "2025-06-26 22:54:51,268 INFO  [enrich.enrich_CNRA    ]  Enrich the CNRA polygons...\n",
      "2025-06-26 22:54:51,268 INFO  [enrich.enrich_CNRA    ]     Part 1 Prepare Features\n",
      "2025-06-26 22:54:51,275 INFO  [enrich.enrich_CNRA    ]     Part 2 Prepare Activity Table\n",
      "2025-06-26 22:54:51,555 INFO  [enrich.enrich_CNRA    ]        step 2/17 remove milliseconds from dates\n",
      "2025-06-26 22:54:51,573 INFO  [enrich.enrich_CNRA    ]        step 3/17 create standardized activity table\n",
      "2025-06-26 22:54:51,577 INFO  [enrich.enrich_CNRA    ]        step 4/17 import activities into standardized table\n",
      "2025-06-26 22:54:51,606 INFO  [enrich.enrich_CNRA    ]     Part 3 - Combine CNRA Features and Activity Table\n",
      "2025-06-26 22:54:51,607 INFO  [enrich.enrich_CNRA    ]        step 6/17 join polygon table and activity table\n",
      "2025-06-26 22:54:51,684 INFO  [enrich.enrich_CNRA    ]           calculate unique Treatment ID with postfix '-CNRA'\n",
      "2025-06-26 22:54:55,583 INFO  [enrich.enrich_CNRA    ]     Part 4 Prepare Project Table\n",
      "2025-06-26 22:54:55,584 INFO  [enrich.enrich_CNRA    ]        step 7/17 calculate unique Project ID if null\n",
      "2025-06-26 22:54:55,588 INFO  [enrich.enrich_CNRA    ]     Part 5 Join Project Table to Features/Activities\n",
      "2025-06-26 22:54:55,730 INFO  [enrich.enrich_CNRA    ]        step 8/17 copy features\n",
      "2025-06-26 22:54:55,782 INFO  [enrich.enrich_CNRA    ]        step 9/17 create Features\n",
      "2025-06-26 22:54:55,848 INFO  [enrich.enrich_CNRA    ]        step 10/17 append\n",
      "2025-06-26 22:54:55,867 INFO  [enrich.enrich_CNRA    ]        standardized has 34831 records\n",
      "2025-06-26 22:54:55,867 INFO  [enrich.enrich_CNRA    ]     Part 6 Standardize and Enrich\n",
      "2025-06-26 22:54:55,867 INFO  [enrich.enrich_CNRA    ]        step 11/17 calculate crosswalk\n",
      "2025-06-26 22:54:55,868 INFO  [enrich.enrich_CNRA    ]        step 12/17 calculate source\n",
      "2025-06-26 22:54:55,868 INFO  [enrich.enrich_CNRA    ]        step 13/17 calculate admin\n",
      "2025-06-26 22:54:55,876 INFO  [enrich.enrich_CNRA    ]        step 14/17 update status\n",
      "2025-06-26 22:54:55,881 INFO  [enrich.enrich_CNRA    ]        step 15/17 update activity end date\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!\n",
      "13092\n",
      "2702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:54:56,224 INFO  [enrich.enrich_CNRA    ]     Part 7 Calculate Board Vegetation Types, Ownership and Others ... \n",
      "2025-06-26 22:54:56,257 INFO  [utils.enrich_polygons ]        Executing Polygon Enrichments...\n",
      "2025-06-26 22:54:56,257 INFO  [utils.enrich_polygons ]           Calculating Broad Vegetation Type...\n",
      "2025-06-26 22:54:56,258 INFO  [utils.enrich_polygons ]              enrich step 1/32 summarize veg within polygons\n",
      "2025-06-26 22:55:00,694 INFO  [utils.enrich_polygons ]                 Loaded Broad_Vegetation_Types from cache\n",
      "2025-06-26 22:55:00,694 INFO  [utils.enrich_polygons ]                    time for loading Broad_Vegetation_Types: 4.436531066894531\n",
      "2025-06-26 22:55:00,737 INFO  [utils.enrich_polygons ]              create numerical intermediate columns before multiprocessing\n",
      "2025-06-26 22:55:00,739 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-26 22:55:01,328 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-26 22:55:01,328 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3409950 \n",
      "2025-06-26 22:55:01,328 INFO  [utils.enrich_polygons ]                 records for summary: 319\n",
      "2025-06-26 22:55:01,329 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-26 22:55:01,329 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-26 22:55:10,376 INFO  [utils.enrich_polygons ]                 joined records: 6504\n",
      "2025-06-26 22:55:10,377 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-26 22:55:10,377 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-26 22:55:34,422 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-26 22:55:34,423 INFO  [utils.enrich_polygons ]                 time for summarizing veg types: 33.72810173034668\n",
      "2025-06-26 22:55:34,501 INFO  [utils.enrich_polygons ]              enrich step 7/32 select records where BROAD_VEGETATION_TYPE is not null\n",
      "2025-06-26 22:55:34,505 INFO  [utils.enrich_polygons ]              enrich step 8/32 set BVT_USERD of the selected records to YES\n",
      "2025-06-26 22:55:34,506 INFO  [utils.enrich_polygons ]              enrich step 9/32 select records where BROAD_VEGETATION_TYPE is null\n",
      "2025-06-26 22:55:34,507 INFO  [utils.enrich_polygons ]              enrich step 11/32 set BVT_USERD of the selected records to NO\n",
      "2025-06-26 22:55:34,510 INFO  [utils.enrich_polygons ]              enrich step 12/32 keeping only the necessary columns\n",
      "2025-06-26 22:55:34,718 INFO  [utils.enrich_polygons ]           Calculating WUI...\n",
      "2025-06-26 22:55:34,879 INFO  [utils.enrich_polygons ]              Loaded WUI from cache\n",
      "2025-06-26 22:55:34,880 INFO  [utils.enrich_polygons ]                 time for loading WUI: 0.16179919242858887\n",
      "2025-06-26 22:55:34,880 INFO  [utils.enrich_polygons ]              enrich step 13/32 select records with null WUI\n",
      "2025-06-26 22:55:34,885 INFO  [utils.enrich_polygons ]              enrich step 14/32 select by WUI location\n",
      "2025-06-26 22:55:35,277 INFO  [utils.enrich_polygons ]              enrich step 15/32 calculate WUI yes\n",
      "2025-06-26 22:55:35,279 INFO  [utils.enrich_polygons ]              enrich step 16/32 select remaining null records\n",
      "2025-06-26 22:55:35,283 INFO  [utils.enrich_polygons ]              enrich step 17/32 calculate WUI no\n",
      "2025-06-26 22:55:35,284 INFO  [utils.enrich_polygons ]              enrich step 18/32 feature to point\n",
      "2025-06-26 22:55:35,513 INFO  [utils.enrich_polygons ]              enrich step 19/32 setup ORIG_FID\n",
      "2025-06-26 22:55:35,514 INFO  [utils.enrich_polygons ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-06-26 22:55:35,954 INFO  [utils.enrich_polygons ]              Loaded CALFIRE_Ownership_Update from cache\n",
      "2025-06-26 22:55:35,955 INFO  [utils.enrich_polygons ]                 time for loading CALFIRE_Ownership_Update: 0.4399678707122803\n",
      "2025-06-26 22:55:35,970 INFO  [utils.enrich_polygons ]              Loaded WFRTF_Regions from cache\n",
      "2025-06-26 22:55:35,970 INFO  [utils.enrich_polygons ]                 time for loading WFRTF_Regions: 0.015314340591430664\n",
      "2025-06-26 22:55:35,970 INFO  [utils.enrich_polygons ]              enrich step 20/32 spatial join ownership\n",
      "2025-06-26 22:55:56,992 INFO  [utils.enrich_polygons ]              enrich step 21/32 spatial join with regions layer\n",
      "2025-06-26 22:56:03,526 INFO  [utils.enrich_polygons ]              enrich step 22/32 add ownership and region\n",
      "2025-06-26 22:56:03,605 INFO  [utils.enrich_polygons ]              enrich step 23/32 calculate ownership field\n",
      "2025-06-26 22:56:03,606 INFO  [utils.enrich_polygons ]              enrich step 24/32 calculate county field\n",
      "2025-06-26 22:56:03,606 INFO  [utils.enrich_polygons ]              enrich step 25/32 calculate region field\n",
      "2025-06-26 22:56:03,607 INFO  [utils.enrich_polygons ]              enrich step 26/32 set TRMT_GEOM\n",
      "2025-06-26 22:56:03,607 INFO  [utils.enrich_polygons ]              enrich step 27/32 calculating years...\n",
      "2025-06-26 22:56:03,840 INFO  [utils.enrich_polygons ]              enrich step 28/32 Initiating Crosswalk...\n",
      "2025-06-26 22:56:03,840 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-06-26 22:56:03,841 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-06-26 22:56:03,879 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-06-26 22:56:03,946 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-06-26 22:56:03,950 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-06-26 22:56:03,952 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-06-26 22:56:03,955 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "2025-06-26 22:56:04,050 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "FIRE_PREVENTION\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "FIRE_PREVENTION\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "PRESCRB_FIRE\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "ROADWAY_CLEARANCE\n",
      "NOT_DEFINED\n",
      "INV_SPECIES_CNTRL\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "FUEL_BREAK\n",
      "NOT_DEFINED\n",
      "RIPARIAN_RESTOR\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:56:04,370 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "INV_SPECIES_CNTRL\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "HABITAT_RESTOR\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "ROADWAY_CLEARANCE\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "REFORESTATION\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "RIPARIAN_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "RIPARIAN_RESTOR\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "RIPARIAN_RESTOR\n",
      "TBD\n",
      "RIPARIAN_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "REFORESTATION\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "ROADWAY_CLEARANCE\n",
      "TBD\n",
      "FOREST_PEST_CNTRL\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "BURNED_AREA_RESTOR\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "BURNED_AREA_RESTOR\n",
      "TBD\n",
      "FOREST_STEWARDSHIP\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "INV_SPECIES_CNTRL\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "REFORESTATION\n",
      "TBD\n",
      "REFORESTATION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:56:05,230 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-06-26 22:56:05,231 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-06-26 22:56:05,231 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-06-26 22:56:05,231 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-06-26 22:56:05,236 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-06-26 22:56:05,238 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-06-26 22:56:05,241 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-06-26 22:56:05,244 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-06-26 22:56:05,246 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-06-26 22:56:05,257 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Org is 'USFS' and Status is 'Active'\n",
      "2025-06-26 22:56:05,317 INFO  [utils.enrich_polygons ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-06-26 22:56:05,318 INFO  [utils.enrich_polygons ]              enrich step 29/32 Calculating Latitude and Longitude...\n",
      "2025-06-26 22:56:05,738 INFO  [utils.enrich_polygons ]              enrich step 30/32 calculate treatment acres\n",
      "2025-06-26 22:56:05,787 INFO  [utils.enrich_polygons ]              enrich step 31/32 removing unnecessary fields\n",
      "2025-06-26 22:56:05,817 INFO  [utils.enrich_polygons ]              enrich step 32/32 delete if County is Null\n",
      "2025-06-26 22:56:06,144 INFO  [enrich.enrich_CNRA    ]     Part 8 Assign Domains...\n",
      "2025-06-26 22:56:06,387 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-06-26 22:56:06,392 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-06-26 22:56:06,399 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-06-26 22:56:06,405 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-06-26 22:56:06,412 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-06-26 22:56:06,418 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-06-26 22:56:06,424 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-06-26 22:56:06,430 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-06-26 22:56:06,436 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-06-26 22:56:06,441 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-06-26 22:56:06,447 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-06-26 22:56:06,452 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-06-26 22:56:06,458 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-06-26 22:56:06,463 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-06-26 22:56:06,470 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-06-26 22:56:06,475 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-06-26 22:56:06,475 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-06-26 22:56:06,481 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-06-26 22:56:06,487 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-06-26 22:56:06,492 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-06-26 22:56:06,493 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-06-26 22:56:06,525 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-06-26 22:56:06,568 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-06-26 22:56:06,630 INFO  [enrich.enrich_CNRA    ]     Part 9 Save Result...\n",
      "2025-06-26 22:56:06,630 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-06-26 22:56:06,630 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-06-26 22:56:06,633 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\CNRA_1950_2025.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:56:14,841 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\CNRA_1950_2025.gdb CNRA_enriched_20250626_polygon\n",
      "2025-06-26 22:56:14,888 INFO  [enrich.enrich_CNRA    ]  Enrich the CNRA lines...\n",
      "2025-06-26 22:56:14,888 INFO  [enrich.enrich_CNRA    ]     Part 1 Prepare Features\n",
      "2025-06-26 22:56:14,889 INFO  [enrich.enrich_CNRA    ]     Part 2 Prepare Activity Table\n",
      "2025-06-26 22:56:15,163 INFO  [enrich.enrich_CNRA    ]        step 2/17 remove milliseconds from dates\n",
      "2025-06-26 22:56:15,181 INFO  [enrich.enrich_CNRA    ]        step 3/17 create standardized activity table\n",
      "2025-06-26 22:56:15,185 INFO  [enrich.enrich_CNRA    ]        step 4/17 import activities into standardized table\n",
      "2025-06-26 22:56:15,215 INFO  [enrich.enrich_CNRA    ]     Part 3 - Combine CNRA Features and Activity Table\n",
      "2025-06-26 22:56:15,216 INFO  [enrich.enrich_CNRA    ]        step 6/17 join polygon table and activity table\n",
      "2025-06-26 22:56:15,222 INFO  [enrich.enrich_CNRA    ]           calculate unique Treatment ID with postfix '-CNRA'\n",
      "2025-06-26 22:56:15,232 INFO  [enrich.enrich_CNRA    ]     Part 4 Prepare Project Table\n",
      "2025-06-26 22:56:15,234 INFO  [enrich.enrich_CNRA    ]        step 7/17 calculate unique Project ID if null\n",
      "2025-06-26 22:56:15,237 INFO  [enrich.enrich_CNRA    ]     Part 5 Join Project Table to Features/Activities\n",
      "2025-06-26 22:56:15,242 INFO  [enrich.enrich_CNRA    ]        step 8/17 copy features\n",
      "2025-06-26 22:56:15,243 INFO  [enrich.enrich_CNRA    ]        step 9/17 create Features\n",
      "2025-06-26 22:56:15,276 INFO  [enrich.enrich_CNRA    ]        step 10/17 append\n",
      "2025-06-26 22:56:15,277 INFO  [enrich.enrich_CNRA    ]        standardized has 359 records\n",
      "2025-06-26 22:56:15,277 INFO  [enrich.enrich_CNRA    ]     Part 6 Standardize and Enrich\n",
      "2025-06-26 22:56:15,278 INFO  [enrich.enrich_CNRA    ]        step 11/17 calculate crosswalk\n",
      "2025-06-26 22:56:15,278 INFO  [enrich.enrich_CNRA    ]        step 12/17 calculate source\n",
      "2025-06-26 22:56:15,279 INFO  [enrich.enrich_CNRA    ]        step 13/17 calculate admin\n",
      "2025-06-26 22:56:15,280 INFO  [enrich.enrich_CNRA    ]        step 14/17 update status\n",
      "2025-06-26 22:56:15,280 INFO  [enrich.enrich_CNRA    ]        step 15/17 update activity end date\n",
      "2025-06-26 22:56:15,290 INFO  [enrich.enrich_CNRA    ]     Part 7 Calculate Board Vegetation Types, Ownership and Others ... \n",
      "2025-06-26 22:56:15,291 INFO  [utils.enrich_lines    ]        Executing Line Enrichments...\n",
      "2025-06-26 22:56:15,320 INFO  [utils.enrich_lines    ]           enrich line step 1/4 convert to points\n",
      "2025-06-26 22:56:15,322 INFO  [utils.enrich_lines    ]           enrich line step 2/4 execute enrich_points...\n",
      "2025-06-26 22:56:15,323 INFO  [utils.enrich_points   ]        Executing Point Enrichments...\n",
      "2025-06-26 22:56:15,324 INFO  [utils.enrich_points   ]           Calculating WUI...\n",
      "2025-06-26 22:56:15,324 INFO  [utils.enrich_points   ]              enrich step 1/16 loading WUI from cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!\n",
      "113\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:56:15,481 INFO  [utils.enrich_points   ]                 time for loading WUI: 0.156876802444458\n",
      "2025-06-26 22:56:15,482 INFO  [utils.enrich_points   ]              enrich step 2/16 select records with null WUI\n",
      "2025-06-26 22:56:15,483 INFO  [utils.enrich_points   ]              enrich step 3/16 select by WUI location\n",
      "2025-06-26 22:56:15,519 INFO  [utils.enrich_points   ]              enrich step 4/16 calculate WUI yes\n",
      "2025-06-26 22:56:15,520 INFO  [utils.enrich_points   ]              enrich step 5/16 select remaining null records\n",
      "2025-06-26 22:56:15,521 INFO  [utils.enrich_points   ]              enrich step 6/16 calculate WUI no\n",
      "2025-06-26 22:56:15,522 INFO  [utils.enrich_points   ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-06-26 22:56:15,522 INFO  [utils.enrich_points   ]              enrich step 7/16 loading CALFIRE_Ownership_Update from cache\n",
      "2025-06-26 22:56:15,928 INFO  [utils.enrich_points   ]                 time for loading CALFIRE_Ownership_Update: 0.40665555000305176\n",
      "2025-06-26 22:56:15,929 INFO  [utils.enrich_points   ]              enrich step 8/16 spatial join ownership\n",
      "2025-06-26 22:56:18,228 INFO  [utils.enrich_points   ]              enrich step 9/16 loading WFRTF_Regions from cache\n",
      "2025-06-26 22:56:18,237 INFO  [utils.enrich_points   ]                 time for loading WFRTF_Regions: 0.00909113883972168\n",
      "2025-06-26 22:56:18,238 INFO  [utils.enrich_points   ]              enrich step 10/16 spatial join regions\n",
      "2025-06-26 22:56:18,518 INFO  [utils.enrich_points   ]              enrich step 11/16 loading Broad_Vegetation_Types from cache\n",
      "2025-06-26 22:56:22,736 INFO  [utils.enrich_points   ]                 time for loading Broad_Vegetation_Types: 4.507441759109497\n",
      "2025-06-26 22:56:22,736 INFO  [utils.enrich_points   ]              enrich step 12/16 spatial join veg and calculations\n",
      "2025-06-26 22:56:25,327 INFO  [utils.enrich_points   ]              enrich step 13/16 Initiating Crosswalk\n",
      "2025-06-26 22:56:25,328 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-06-26 22:56:25,328 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-06-26 22:56:25,357 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-06-26 22:56:25,360 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-06-26 22:56:25,361 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-06-26 22:56:25,362 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-06-26 22:56:25,362 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "2025-06-26 22:56:25,365 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-06-26 22:56:25,370 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-06-26 22:56:25,382 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-06-26 22:56:25,382 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-06-26 22:56:25,382 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-06-26 22:56:25,382 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-06-26 22:56:25,383 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-06-26 22:56:25,383 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-06-26 22:56:25,384 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-06-26 22:56:25,384 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-06-26 22:56:25,385 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-06-26 22:56:25,385 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Org is 'USFS' and Status is 'Active'\n",
      "2025-06-26 22:56:25,388 INFO  [utils.enrich_points   ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-06-26 22:56:25,388 INFO  [utils.enrich_points   ]              enrich step 14/16 calculating Years\n",
      "2025-06-26 22:56:25,391 INFO  [utils.enrich_points   ]              enrich step 15/16 calculating Latitude and Longitude\n",
      "2025-06-26 22:56:25,392 INFO  [utils.enrich_points   ]              enrich step 16/16 removing unnecessary fields\n",
      "2025-06-26 22:56:25,393 INFO  [utils.enrich_points   ]           Enrich Points Complete...\n",
      "2025-06-26 22:56:25,566 INFO  [utils.enrich_lines    ]           enrich line step 3/4 importing attributes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "ROADWAY_CLEARANCE\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:56:25,595 INFO  [utils.enrich_lines    ]           enrich line step 4/4 align to template\n",
      "2025-06-26 22:56:25,599 INFO  [enrich.enrich_CNRA    ]     Part 8 Assign Domains...\n",
      "2025-06-26 22:56:25,911 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-06-26 22:56:25,917 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-06-26 22:56:25,923 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-06-26 22:56:25,929 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-06-26 22:56:25,937 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-06-26 22:56:25,943 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-06-26 22:56:25,948 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-06-26 22:56:25,954 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-06-26 22:56:25,959 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-06-26 22:56:25,965 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-06-26 22:56:25,970 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-06-26 22:56:25,976 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-06-26 22:56:25,981 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-06-26 22:56:25,987 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-06-26 22:56:25,993 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-06-26 22:56:25,998 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-06-26 22:56:25,999 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-06-26 22:56:26,004 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-06-26 22:56:26,010 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-06-26 22:56:26,016 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-06-26 22:56:26,016 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-06-26 22:56:26,021 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-06-26 22:56:26,027 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-06-26 22:56:26,037 INFO  [enrich.enrich_CNRA    ]     Part 9 Save Result...\n",
      "2025-06-26 22:56:26,037 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-06-26 22:56:26,038 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-06-26 22:56:26,038 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n",
      "2025-06-26 22:56:26,118 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\CNRA_1950_2025.gdb CNRA_enriched_20250626_line\n",
      "2025-06-26 22:56:26,143 INFO  [enrich.enrich_CNRA    ]  Enrich the CNRA points...\n",
      "2025-06-26 22:56:26,144 INFO  [enrich.enrich_CNRA    ]     Part 1 Prepare Features\n",
      "2025-06-26 22:56:26,145 INFO  [enrich.enrich_CNRA    ]     Part 2 Prepare Activity Table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\CNRA_1950_2025.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:56:26,429 INFO  [enrich.enrich_CNRA    ]        step 2/17 remove milliseconds from dates\n",
      "2025-06-26 22:56:26,447 INFO  [enrich.enrich_CNRA    ]        step 3/17 create standardized activity table\n",
      "2025-06-26 22:56:26,451 INFO  [enrich.enrich_CNRA    ]        step 4/17 import activities into standardized table\n",
      "2025-06-26 22:56:26,482 INFO  [enrich.enrich_CNRA    ]     Part 3 - Combine CNRA Features and Activity Table\n",
      "2025-06-26 22:56:26,483 INFO  [enrich.enrich_CNRA    ]        step 6/17 join polygon table and activity table\n",
      "2025-06-26 22:56:26,493 INFO  [enrich.enrich_CNRA    ]           calculate unique Treatment ID with postfix '-CNRA'\n",
      "2025-06-26 22:56:26,506 INFO  [enrich.enrich_CNRA    ]     Part 4 Prepare Project Table\n",
      "2025-06-26 22:56:26,508 INFO  [enrich.enrich_CNRA    ]        step 7/17 calculate unique Project ID if null\n",
      "2025-06-26 22:56:26,511 INFO  [enrich.enrich_CNRA    ]     Part 5 Join Project Table to Features/Activities\n",
      "2025-06-26 22:56:26,519 INFO  [enrich.enrich_CNRA    ]        step 8/17 copy features\n",
      "2025-06-26 22:56:26,521 INFO  [enrich.enrich_CNRA    ]        step 9/17 create Features\n",
      "2025-06-26 22:56:26,553 INFO  [enrich.enrich_CNRA    ]        step 10/17 append\n",
      "2025-06-26 22:56:26,556 INFO  [enrich.enrich_CNRA    ]        standardized has 2066 records\n",
      "2025-06-26 22:56:26,556 INFO  [enrich.enrich_CNRA    ]     Part 6 Standardize and Enrich\n",
      "2025-06-26 22:56:26,556 INFO  [enrich.enrich_CNRA    ]        step 11/17 calculate crosswalk\n",
      "2025-06-26 22:56:26,557 INFO  [enrich.enrich_CNRA    ]        step 12/17 calculate source\n",
      "2025-06-26 22:56:26,557 INFO  [enrich.enrich_CNRA    ]        step 13/17 calculate admin\n",
      "2025-06-26 22:56:26,559 INFO  [enrich.enrich_CNRA    ]        step 14/17 update status\n",
      "2025-06-26 22:56:26,560 INFO  [enrich.enrich_CNRA    ]        step 15/17 update activity end date\n",
      "2025-06-26 22:56:26,583 INFO  [enrich.enrich_CNRA    ]     Part 7 Calculate Board Vegetation Types, Ownership and Others ... \n",
      "2025-06-26 22:56:26,586 INFO  [utils.enrich_points   ]        Executing Point Enrichments...\n",
      "2025-06-26 22:56:26,588 INFO  [utils.enrich_points   ]           Calculating WUI...\n",
      "2025-06-26 22:56:26,588 INFO  [utils.enrich_points   ]              enrich step 1/16 loading WUI from cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!\n",
      "361\n",
      "225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:56:26,753 INFO  [utils.enrich_points   ]                 time for loading WUI: 0.1646888256072998\n",
      "2025-06-26 22:56:26,754 INFO  [utils.enrich_points   ]              enrich step 2/16 select records with null WUI\n",
      "2025-06-26 22:56:26,755 INFO  [utils.enrich_points   ]              enrich step 3/16 select by WUI location\n",
      "2025-06-26 22:56:26,791 INFO  [utils.enrich_points   ]              enrich step 4/16 calculate WUI yes\n",
      "2025-06-26 22:56:26,792 INFO  [utils.enrich_points   ]              enrich step 5/16 select remaining null records\n",
      "2025-06-26 22:56:26,793 INFO  [utils.enrich_points   ]              enrich step 6/16 calculate WUI no\n",
      "2025-06-26 22:56:26,794 INFO  [utils.enrich_points   ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-06-26 22:56:26,794 INFO  [utils.enrich_points   ]              enrich step 7/16 loading CALFIRE_Ownership_Update from cache\n",
      "2025-06-26 22:56:27,184 INFO  [utils.enrich_points   ]                 time for loading CALFIRE_Ownership_Update: 0.3902699947357178\n",
      "2025-06-26 22:56:27,185 INFO  [utils.enrich_points   ]              enrich step 8/16 spatial join ownership\n",
      "2025-06-26 22:56:43,509 INFO  [utils.enrich_points   ]              enrich step 9/16 loading WFRTF_Regions from cache\n",
      "2025-06-26 22:56:43,519 INFO  [utils.enrich_points   ]                 time for loading WFRTF_Regions: 0.009532690048217773\n",
      "2025-06-26 22:56:43,519 INFO  [utils.enrich_points   ]              enrich step 10/16 spatial join regions\n",
      "2025-06-26 22:56:45,119 INFO  [utils.enrich_points   ]              enrich step 11/16 loading Broad_Vegetation_Types from cache\n",
      "2025-06-26 22:56:51,004 INFO  [utils.enrich_points   ]                 time for loading Broad_Vegetation_Types: 7.494853258132935\n",
      "2025-06-26 22:56:51,005 INFO  [utils.enrich_points   ]              enrich step 12/16 spatial join veg and calculations\n",
      "2025-06-26 22:57:00,861 INFO  [utils.enrich_points   ]              enrich step 13/16 Initiating Crosswalk\n",
      "2025-06-26 22:57:00,861 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-06-26 22:57:00,862 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-06-26 22:57:00,895 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-06-26 22:57:00,901 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-06-26 22:57:00,903 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-06-26 22:57:00,904 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-06-26 22:57:00,904 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "2025-06-26 22:57:00,911 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-06-26 22:57:00,933 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-06-26 22:57:00,986 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-06-26 22:57:00,987 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-06-26 22:57:00,987 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-06-26 22:57:00,988 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-06-26 22:57:00,989 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-06-26 22:57:00,989 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-06-26 22:57:00,989 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-06-26 22:57:00,990 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-06-26 22:57:00,991 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-06-26 22:57:00,992 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Org is 'USFS' and Status is 'Active'\n",
      "2025-06-26 22:57:00,998 INFO  [utils.enrich_points   ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-06-26 22:57:00,998 INFO  [utils.enrich_points   ]              enrich step 14/16 calculating Years\n",
      "2025-06-26 22:57:01,006 INFO  [utils.enrich_points   ]              enrich step 15/16 calculating Latitude and Longitude\n",
      "2025-06-26 22:57:01,007 INFO  [utils.enrich_points   ]              enrich step 16/16 removing unnecessary fields\n",
      "2025-06-26 22:57:01,011 INFO  [utils.enrich_points   ]           Enrich Points Complete...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "NOT_DEFINED\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "FOREST_STEWARDSHIP\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:57:01,244 INFO  [enrich.enrich_CNRA    ]     Part 8 Assign Domains...\n",
      "2025-06-26 22:57:01,313 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-06-26 22:57:01,319 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-06-26 22:57:01,326 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-06-26 22:57:01,332 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-06-26 22:57:01,339 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-06-26 22:57:01,344 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-06-26 22:57:01,350 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-06-26 22:57:01,356 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-06-26 22:57:01,362 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-06-26 22:57:01,368 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-06-26 22:57:01,373 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-06-26 22:57:01,379 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-06-26 22:57:01,384 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-06-26 22:57:01,390 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-06-26 22:57:01,396 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-06-26 22:57:01,402 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-06-26 22:57:01,402 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-06-26 22:57:01,408 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-06-26 22:57:01,413 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-06-26 22:57:01,418 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-06-26 22:57:01,419 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-06-26 22:57:01,425 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-06-26 22:57:01,432 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-06-26 22:57:01,445 INFO  [enrich.enrich_CNRA    ]     Part 9 Save Result...\n",
      "2025-06-26 22:57:01,446 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-06-26 22:57:01,446 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-06-26 22:57:01,447 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n",
      "2025-06-26 22:57:01,619 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\CNRA_1950_2025.gdb CNRA_enriched_20250626_point\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\CNRA_1950_2025.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:57:01,801 INFO  [its_logging.logger_config]  Memory usage: 7864.69 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "enrich_CNRA(cnra_input_gdb_path,\n",
    "            cnra_polygon_layer_name,\n",
    "            cnra_line_layer_name,\n",
    "            cnra_point_layer_name,\n",
    "            cnra_project_polygon_layer_name,\n",
    "            cnra_activity_layer_name,\n",
    "            a_reference_gdb_path,\n",
    "            start_year,\n",
    "            end_year,\n",
    "            output_gdb_path,\n",
    "            output_layer_name)\n",
    "\n",
    "# Get memory usage in bytes, convert to MB\n",
    "memory_usage = process.memory_info().rss / 1024 / 1024\n",
    "logger.info(f\"Memory usage: {memory_usage:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d5ff40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrich.enrich_CalTrans import enrich_Caltrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb66681f-509c-403c-9379-b13e10b2113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp file path\n",
    "caltrans_input_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\2023\\CALTRANS_2023\\Caltrans_Vegetation_Management_20_23.gdb\"\n",
    "tree_activity_layer_name = \"Caltrans_Vegetation_Management_Trees_ActivitiesTable_20_23\"\n",
    "tree_treatment_layer_name = \"Caltrans_Vegetation_Management_Trees_Treatments_20_23\"\n",
    "road_activity_layer_name = \"Caltrans_Vegetation_Management_RoadsideLandscape_ActivitiesTable_20_23\"\n",
    "road_treatment_layer_name = \"Caltrans_Vegetation_Management_RoadsideLandscape_Treatments_20_23\"\n",
    "start_year = 1950\n",
    "end_year = 2025\n",
    "output_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\tmp\\CalTRANS_{}_{}.gdb\".format(start_year, end_year)\n",
    "output_layer_name = f\"CalTRANS_enriched_{datetime.today().strftime('%Y%m%d')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8dc4b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 13:23:51,657 INFO  [enrich.enrich_CalTrans]  Load Caltrans road activity layer into a DataFrame\n",
      "2025-05-12 13:23:54,068 INFO  [enrich.enrich_CalTrans]     all required columns are present.\n",
      "2025-05-12 13:23:54,069 INFO  [enrich.enrich_CalTrans]  Load Caltrans road treatment layer into a GeoDataFrame\n",
      "2025-05-12 13:23:54,190 INFO  [enrich.enrich_CalTrans]     all required columns are present.\n",
      "2025-05-12 13:23:54,496 INFO  [enrich.enrich_CalTrans]  Performing Standardization\n",
      "2025-05-12 13:23:54,496 INFO  [enrich.enrich_CalTrans]     step 1/10 merge treatments and activities\n",
      "2025-05-12 13:23:54,696 INFO  [enrich.enrich_CalTrans]        merged_data has 103426 records\n",
      "2025-05-12 13:23:54,697 INFO  [enrich.enrich_CalTrans]     step 2/10 repair geometries\n",
      "2025-05-12 13:23:55,102 INFO  [enrich.enrich_CalTrans]     step 3/10 add standard columns\n",
      "2025-05-12 13:23:55,559 INFO  [enrich.enrich_CalTrans]     step 4/10 calculate column values\n",
      "2025-05-12 13:23:57,432 INFO  [enrich.enrich_CalTrans]     step 5/10 keep standard columns only\n",
      "2025-05-12 13:23:57,555 INFO  [enrich.enrich_CalTrans]     step 6/10 calculate broad veg table, region and etc\n",
      "2025-05-12 13:23:57,555 INFO  [utils.enrich_lines    ]        Executing Line Enrichments...\n",
      "2025-05-12 13:23:57,722 INFO  [utils.enrich_lines    ]           enrich line step 1/4 convert to points\n",
      "2025-05-12 13:23:58,501 INFO  [utils.enrich_lines    ]           enrich line step 2/4 execute enrich_points...\n",
      "2025-05-12 13:23:58,501 INFO  [utils.enrich_points   ]        Executing Point Enrichments...\n",
      "2025-05-12 13:23:58,585 INFO  [utils.enrich_points   ]           Calculating WUI...\n",
      "2025-05-12 13:23:58,586 INFO  [utils.enrich_points   ]              enrich step 1/16 loading WUI from cache\n",
      "2025-05-12 13:23:59,085 INFO  [utils.enrich_points   ]                 time for loading WUI: 0.49938011169433594\n",
      "2025-05-12 13:23:59,086 INFO  [utils.enrich_points   ]              enrich step 2/16 select records with null WUI\n",
      "2025-05-12 13:23:59,264 INFO  [utils.enrich_points   ]              enrich step 3/16 select by WUI location\n",
      "2025-05-12 13:24:13,245 INFO  [utils.enrich_points   ]              enrich step 4/16 calculate WUI yes\n",
      "2025-05-12 13:24:13,250 INFO  [utils.enrich_points   ]              enrich step 5/16 select remaining null records\n",
      "2025-05-12 13:24:13,405 INFO  [utils.enrich_points   ]              enrich step 6/16 calculate WUI no\n",
      "2025-05-12 13:24:13,410 INFO  [utils.enrich_points   ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-05-12 13:24:13,411 INFO  [utils.enrich_points   ]              enrich step 7/16 loading CALFIRE_Ownership_Update from cache\n",
      "2025-05-12 13:24:13,862 INFO  [utils.enrich_points   ]                 time for loading CALFIRE_Ownership_Update: 0.4520583152770996\n",
      "2025-05-12 13:24:13,863 INFO  [utils.enrich_points   ]              enrich step 8/16 spatial join ownership\n",
      "2025-05-12 13:25:40,886 INFO  [utils.enrich_points   ]              enrich step 9/16 loading WFRTF_Regions from cache\n",
      "2025-05-12 13:25:40,905 INFO  [utils.enrich_points   ]                 time for loading WFRTF_Regions: 0.019242286682128906\n",
      "2025-05-12 13:25:40,905 INFO  [utils.enrich_points   ]              enrich step 10/16 spatial join regions\n",
      "2025-05-12 13:26:54,445 INFO  [utils.enrich_points   ]              enrich step 11/16 loading Broad_Vegetation_Types from cache\n",
      "2025-05-12 13:26:59,107 INFO  [utils.enrich_points   ]                 time for loading Broad_Vegetation_Types: 78.22151207923889\n",
      "2025-05-12 13:26:59,108 INFO  [utils.enrich_points   ]              enrich step 12/16 spatial join veg and calculations\n",
      "2025-05-12 13:29:20,403 INFO  [utils.enrich_points   ]              enrich step 13/16 Initiating Crosswalk\n",
      "2025-05-12 13:29:20,403 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-05-12 13:29:20,404 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-05-12 13:29:20,445 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-05-12 13:29:20,688 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-05-12 13:29:20,697 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-05-12 13:29:20,700 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-05-12 13:29:20,703 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "2025-05-12 13:29:20,797 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-05-12 13:29:21,542 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-05-12 13:29:23,878 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-05-12 13:29:23,878 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-05-12 13:29:23,879 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-05-12 13:29:23,879 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-05-12 13:29:23,887 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-05-12 13:29:23,891 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-05-12 13:29:23,894 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-05-12 13:29:23,895 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-05-12 13:29:23,898 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-05-12 13:29:23,930 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Org is 'USFS' and Status is 'Active'\n",
      "2025-05-12 13:29:24,035 INFO  [utils.enrich_points   ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-05-12 13:29:24,036 INFO  [utils.enrich_points   ]              enrich step 14/16 calculating Years\n",
      "2025-05-12 13:29:24,273 INFO  [utils.enrich_points   ]              enrich step 15/16 calculating Latitude and Longitude\n",
      "2025-05-12 13:29:24,295 INFO  [utils.enrich_points   ]              enrich step 16/16 removing unnecessary fields\n",
      "2025-05-12 13:29:24,369 INFO  [utils.enrich_points   ]           Enrich Points Complete...\n",
      "2025-05-12 13:29:24,642 INFO  [utils.enrich_lines    ]           enrich line step 3/4 importing attributes\n",
      "2025-05-12 13:29:27,746 INFO  [utils.enrich_lines    ]           enrich line step 4/4 align to template\n",
      "2025-05-12 13:29:27,984 INFO  [enrich.enrich_CalTrans]        enriched data has 103426 records\n",
      "2025-05-12 13:29:27,984 INFO  [enrich.enrich_CalTrans]     step 7/10 calculate PRIMARY_OWNERSHIP_GROUP and TRMTID_USER\n",
      "2025-05-12 13:29:28,812 INFO  [enrich.enrich_CalTrans]     step 8/10 Remove Unnecessary Columns...\n",
      "2025-05-12 13:29:28,902 INFO  [enrich.enrich_CalTrans]     step 9/10 Assign Domains...\n",
      "2025-05-12 13:29:29,158 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-05-12 13:29:29,164 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-05-12 13:29:29,171 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-05-12 13:29:29,177 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-05-12 13:29:29,185 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-05-12 13:29:29,192 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-05-12 13:29:29,198 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-05-12 13:29:29,204 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-05-12 13:29:29,210 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-05-12 13:29:29,217 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-05-12 13:29:29,222 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-05-12 13:29:29,228 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 13:29:29,234 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-05-12 13:29:29,239 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-05-12 13:29:29,246 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-05-12 13:29:29,252 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-05-12 13:29:29,252 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-05-12 13:29:29,258 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-05-12 13:29:29,263 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-05-12 13:29:29,269 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-05-12 13:29:29,269 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-05-12 13:29:29,333 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-05-12 13:29:29,412 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-05-12 13:29:29,538 INFO  [enrich.enrich_CalTrans]     step 10/10 Save Result...\n",
      "2025-05-12 13:29:29,539 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-05-12 13:29:29,539 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-05-12 13:29:29,544 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\tmp\\CalTRANS_1950_2025.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 13:29:47,765 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\tmp\\CalTRANS_1950_2025.gdb CalTRANS_enriched_20250512\n",
      "2025-05-12 13:29:47,873 INFO  [its_logging.logger_config]  Memory usage: 4067.48 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "enrich_Caltrans(caltrans_input_gdb_path,\n",
    "                tree_activity_layer_name,\n",
    "                tree_treatment_layer_name,\n",
    "                road_activity_layer_name,\n",
    "                road_treatment_layer_name,\n",
    "                a_reference_gdb_path,\n",
    "                start_year,\n",
    "                end_year,\n",
    "                output_gdb_path,\n",
    "                output_layer_name)\n",
    "\n",
    "# Get memory usage in bytes, convert to MB\n",
    "memory_usage = process.memory_info().rss / 1024 / 1024\n",
    "logger.info(f\"Memory usage: {memory_usage:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "781b49f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp file path\n",
    "caltrans_input_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\CALTRANS_V2.0\\Caltrans_Vegetation_Management_Treatments_2024.gdb\"\n",
    "tree_activity_layer_name = \"Caltrans_Vegetation_Management_Trees_ActivitiesTable_2024\"\n",
    "tree_treatment_layer_name = \"Caltrans_Vegetation_Management_Tree_Treatments_2024\"\n",
    "road_activity_layer_name = \"Caltrans_Vegetation_Management_RoadsideLandscape_ActivitiesTable_2024\"\n",
    "road_treatment_layer_name = \"Caltrans_Vegetation_Management_RoadsideLandscape_Treatments_2024\"\n",
    "start_year = 1950\n",
    "end_year = 2025\n",
    "output_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\CalTRANS_{}_{}.gdb\".format(start_year, end_year)\n",
    "output_layer_name = f\"CalTRANS_enriched_{datetime.today().strftime('%Y%m%d')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e49232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 14:50:48,757 INFO  [enrich.enrich_CalTrans]  Load Caltrans road activity layer into a DataFrame\n",
      "2025-05-12 14:50:49,409 INFO  [enrich.enrich_CalTrans]     all required columns are present.\n",
      "2025-05-12 14:50:49,410 INFO  [enrich.enrich_CalTrans]  Load Caltrans road treatment layer into a GeoDataFrame\n",
      "2025-05-12 14:50:49,441 INFO  [enrich.enrich_CalTrans]     all required columns are present.\n",
      "2025-05-12 14:50:49,516 INFO  [enrich.enrich_CalTrans]  Performing Standardization\n",
      "2025-05-12 14:50:49,516 INFO  [enrich.enrich_CalTrans]     step 1/10 merge treatments and activities\n",
      "2025-05-12 14:50:49,568 INFO  [enrich.enrich_CalTrans]        merged_data has 27843 records\n",
      "2025-05-12 14:50:49,569 INFO  [enrich.enrich_CalTrans]     step 2/10 repair geometries\n",
      "2025-05-12 14:50:49,677 INFO  [enrich.enrich_CalTrans]     step 3/10 add standard columns\n",
      "2025-05-12 14:50:49,820 INFO  [enrich.enrich_CalTrans]     step 4/10 calculate column values\n",
      "2025-05-12 14:50:50,739 INFO  [enrich.enrich_CalTrans]     step 5/10 keep standard columns only\n",
      "2025-05-12 14:50:50,774 INFO  [enrich.enrich_CalTrans]     step 6/10 calculate broad veg table, region and etc\n",
      "2025-05-12 14:50:50,775 INFO  [utils.enrich_lines    ]        Executing Line Enrichments...\n",
      "2025-05-12 14:50:50,836 INFO  [utils.enrich_lines    ]           enrich line step 1/4 convert to points\n",
      "2025-05-12 14:50:51,048 INFO  [utils.enrich_lines    ]           enrich line step 2/4 execute enrich_points...\n",
      "2025-05-12 14:50:51,048 INFO  [utils.enrich_points   ]        Executing Point Enrichments...\n",
      "2025-05-12 14:50:51,072 INFO  [utils.enrich_points   ]           Calculating WUI...\n",
      "2025-05-12 14:50:51,073 INFO  [utils.enrich_points   ]              enrich step 1/16 loading WUI from cache\n",
      "2025-05-12 14:50:51,271 INFO  [utils.enrich_points   ]                 time for loading WUI: 0.1990203857421875\n",
      "2025-05-12 14:50:51,272 INFO  [utils.enrich_points   ]              enrich step 2/16 select records with null WUI\n",
      "2025-05-12 14:50:51,321 INFO  [utils.enrich_points   ]              enrich step 3/16 select by WUI location\n",
      "2025-05-12 14:50:54,813 INFO  [utils.enrich_points   ]              enrich step 4/16 calculate WUI yes\n",
      "2025-05-12 14:50:54,816 INFO  [utils.enrich_points   ]              enrich step 5/16 select remaining null records\n",
      "2025-05-12 14:50:54,858 INFO  [utils.enrich_points   ]              enrich step 6/16 calculate WUI no\n",
      "2025-05-12 14:50:54,860 INFO  [utils.enrich_points   ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-05-12 14:50:54,860 INFO  [utils.enrich_points   ]              enrich step 7/16 loading CALFIRE_Ownership_Update from cache\n",
      "2025-05-12 14:50:55,265 INFO  [utils.enrich_points   ]                 time for loading CALFIRE_Ownership_Update: 0.40497636795043945\n",
      "2025-05-12 14:50:55,266 INFO  [utils.enrich_points   ]              enrich step 8/16 spatial join ownership\n",
      "2025-05-12 14:51:24,626 INFO  [utils.enrich_points   ]              enrich step 9/16 loading WFRTF_Regions from cache\n",
      "2025-05-12 14:51:24,636 INFO  [utils.enrich_points   ]                 time for loading WFRTF_Regions: 0.009638547897338867\n",
      "2025-05-12 14:51:24,636 INFO  [utils.enrich_points   ]              enrich step 10/16 spatial join regions\n",
      "2025-05-12 14:51:44,611 INFO  [utils.enrich_points   ]              enrich step 11/16 loading Broad_Vegetation_Types from cache\n",
      "2025-05-12 14:51:48,586 INFO  [utils.enrich_points   ]                 time for loading Broad_Vegetation_Types: 23.96005654335022\n",
      "2025-05-12 14:51:48,587 INFO  [utils.enrich_points   ]              enrich step 12/16 spatial join veg and calculations\n",
      "2025-05-12 14:53:03,747 INFO  [utils.enrich_points   ]              enrich step 13/16 Initiating Crosswalk\n",
      "2025-05-12 14:53:03,747 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-05-12 14:53:03,747 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-05-12 14:53:03,776 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-05-12 14:53:03,845 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-05-12 14:53:03,849 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-05-12 14:53:03,850 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-05-12 14:53:03,851 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "2025-05-12 14:53:03,880 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-05-12 14:53:04,084 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-05-12 14:53:04,725 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-05-12 14:53:04,726 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-05-12 14:53:04,726 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-05-12 14:53:04,727 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-05-12 14:53:04,731 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-05-12 14:53:04,732 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-05-12 14:53:04,733 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-05-12 14:53:04,735 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-05-12 14:53:04,736 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-05-12 14:53:04,745 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Org is 'USFS' and Status is 'Active'\n",
      "2025-05-12 14:53:04,775 INFO  [utils.enrich_points   ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-05-12 14:53:04,775 INFO  [utils.enrich_points   ]              enrich step 14/16 calculating Years\n",
      "2025-05-12 14:53:04,845 INFO  [utils.enrich_points   ]              enrich step 15/16 calculating Latitude and Longitude\n",
      "2025-05-12 14:53:04,851 INFO  [utils.enrich_points   ]              enrich step 16/16 removing unnecessary fields\n",
      "2025-05-12 14:53:04,873 INFO  [utils.enrich_points   ]           Enrich Points Complete...\n",
      "2025-05-12 14:53:05,086 INFO  [utils.enrich_lines    ]           enrich line step 3/4 importing attributes\n",
      "2025-05-12 14:53:05,942 INFO  [utils.enrich_lines    ]           enrich line step 4/4 align to template\n",
      "2025-05-12 14:53:06,015 INFO  [enrich.enrich_CalTrans]        enriched data has 27843 records\n",
      "2025-05-12 14:53:06,016 INFO  [enrich.enrich_CalTrans]     step 7/10 calculate PRIMARY_OWNERSHIP_GROUP and TRMTID_USER\n",
      "2025-05-12 14:53:06,246 INFO  [enrich.enrich_CalTrans]     step 8/10 Remove Unnecessary Columns...\n",
      "2025-05-12 14:53:06,273 INFO  [enrich.enrich_CalTrans]     step 9/10 Assign Domains...\n",
      "2025-05-12 14:53:06,455 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-05-12 14:53:06,460 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-05-12 14:53:06,468 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-05-12 14:53:06,473 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-05-12 14:53:06,481 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-05-12 14:53:06,487 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-05-12 14:53:06,493 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-05-12 14:53:06,498 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-05-12 14:53:06,504 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-05-12 14:53:06,510 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-05-12 14:53:06,516 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-05-12 14:53:06,521 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 14:53:06,527 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-05-12 14:53:06,533 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-05-12 14:53:06,539 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-05-12 14:53:06,545 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-05-12 14:53:06,545 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-05-12 14:53:06,551 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-05-12 14:53:06,556 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-05-12 14:53:06,562 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-05-12 14:53:06,562 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-05-12 14:53:06,585 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-05-12 14:53:06,612 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-05-12 14:53:06,654 INFO  [enrich.enrich_CalTrans]     step 10/10 Save Result...\n",
      "2025-05-12 14:53:06,655 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-05-12 14:53:06,655 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-05-12 14:53:06,658 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\CalTRANS_1950_2025.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 14:53:11,553 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\CalTRANS_1950_2025.gdb CalTRANS_enriched_20250512\n",
      "2025-05-12 14:53:11,582 INFO  [its_logging.logger_config]  Memory usage: 3912.47 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "enrich_Caltrans(caltrans_input_gdb_path,\n",
    "                tree_activity_layer_name,\n",
    "                tree_treatment_layer_name,\n",
    "                road_activity_layer_name,\n",
    "                road_treatment_layer_name,\n",
    "                a_reference_gdb_path,\n",
    "                start_year,\n",
    "                end_year,\n",
    "                output_gdb_path,\n",
    "                output_layer_name)\n",
    "\n",
    "# Get memory usage in bytes, convert to MB\n",
    "memory_usage = process.memory_info().rss / 1024 / 1024\n",
    "logger.info(f\"Memory usage: {memory_usage:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edf47f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\tmp\\CalTRANS_{}_{}.gdb\".format(start_year, end_year)\n",
    "output_layer_name = f\"CalTRANS_enriched_{datetime.today().strftime('%Y%m%d')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b8326b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "caltrans_2023 = gpd.read_file(r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\tmp\\CalTRANS_{}_{}.gdb\".format(start_year, end_year),\n",
    "                              driver='OpenFileGDB',\n",
    "                              layer='CalTRANS_enriched_20250512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c8afb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "caltrans_2024 = gpd.read_file(r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\CalTRANS_{}_{}.gdb\".format(start_year, end_year),\n",
    "                              driver='OpenFileGDB',\n",
    "                              layer='CalTRANS_enriched_20250512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b87d2e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "caltrans_out = pd.concat([caltrans_2023, caltrans_2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65b2315",
   "metadata": {},
   "outputs": [],
   "source": [
    "caltrans_out.to_file(r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\CalTRANS_{}_{}.gdb\".format(start_year, end_year),\n",
    "                      driver='OpenFileGDB',\n",
    "                      layer='CalTRANS_enriched_20250512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f117bbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1425304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\tmp\\reports.gdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad738bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>geometry_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>footprint2021</td>\n",
       "      <td>MultiPolygon Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>footprint2022</td>\n",
       "      <td>MultiPolygon Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>footprint2023</td>\n",
       "      <td>MultiPolygon Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name   geometry_type\n",
       "0  footprint2021  MultiPolygon Z\n",
       "1  footprint2022  MultiPolygon Z\n",
       "2  footprint2023  MultiPolygon Z"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpd.list_layers(report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51e647d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\pyogrio\\raw.py:198: RuntimeWarning: driver OpenFileGDB does not support open option DRIVER\n",
      "  return ogr_read(\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\pyogrio\\raw.py:198: RuntimeWarning: organizePolygons() received a polygon with more than 100 parts. The processing may be really slow.  You can skip the processing by setting METHOD=SKIP, or only make it analyze counter-clock wise parts by setting METHOD=ONLY_CCW if you can assume that the outline of holes is counter-clock wise defined\n",
      "  return ogr_read(\n"
     ]
    }
   ],
   "source": [
    "footprint2023 = gpd.read_file(report_path,driver='OpenFileGDB',layer='footprint2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8fcc8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_OWNERSHIP_GROUP\n",
       "FEDERAL                 260083.279806\n",
       "LOCAL                     4945.251612\n",
       "NGO                       2446.897781\n",
       "PRIVATE_INDUSTRY        224994.549016\n",
       "PRIVATE_NON-INDUSTRY     59268.893918\n",
       "STATE                   137141.116163\n",
       "TRIBAL                    3599.720000\n",
       "Name: ACTIVITY_QUANTITY, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "footprint2023.groupby(['PRIMARY_OWNERSHIP_GROUP']).ACTIVITY_QUANTITY.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af52b779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRMTID_USER</th>\n",
       "      <th>ACTIVITY_QUANTITY</th>\n",
       "      <th>AGENCY</th>\n",
       "      <th>PRIMARY_OWNERSHIP_GROUP</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>BROAD_VEGETATION_TYPE</th>\n",
       "      <th>REGION</th>\n",
       "      <th>WUI</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-DN-101-DN-NOR-NON</td>\n",
       "      <td>32.400000</td>\n",
       "      <td>CALSTA</td>\n",
       "      <td>STATE</td>\n",
       "      <td>DN</td>\n",
       "      <td>Forest</td>\n",
       "      <td>North Coast</td>\n",
       "      <td>Non-WUI</td>\n",
       "      <td>MULTIPOLYGON (((-342583.596 406960.852, -34258...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-DN-101-DN-NOR-WUI</td>\n",
       "      <td>32.400000</td>\n",
       "      <td>CALSTA</td>\n",
       "      <td>STATE</td>\n",
       "      <td>DN</td>\n",
       "      <td>Forest</td>\n",
       "      <td>North Coast</td>\n",
       "      <td>Non-WUI</td>\n",
       "      <td>MULTIPOLYGON (((-342583.596 406960.852, -34258...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-DN-169-DN-NOR-NON</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>CALSTA</td>\n",
       "      <td>STATE</td>\n",
       "      <td>DN</td>\n",
       "      <td>Urban</td>\n",
       "      <td>North Coast</td>\n",
       "      <td>WUI</td>\n",
       "      <td>MULTIPOLYGON (((-337005.425 396726.106, -33698...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-DN-169-DN-NOR-WUI</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>CALSTA</td>\n",
       "      <td>STATE</td>\n",
       "      <td>DN</td>\n",
       "      <td>Urban</td>\n",
       "      <td>North Coast</td>\n",
       "      <td>WUI</td>\n",
       "      <td>MULTIPOLYGON (((-337005.425 396726.106, -33698...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-DN-197-DN-NOR-WUI</td>\n",
       "      <td>5.860000</td>\n",
       "      <td>CALSTA</td>\n",
       "      <td>STATE</td>\n",
       "      <td>DN</td>\n",
       "      <td>Forest</td>\n",
       "      <td>North Coast</td>\n",
       "      <td>WUI</td>\n",
       "      <td>MULTIPOLYGON (((-339603.722 428203.383, -33960...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>TI-55</td>\n",
       "      <td>12200.547236</td>\n",
       "      <td>TIMBER</td>\n",
       "      <td>PRIVATE_INDUSTRY</td>\n",
       "      <td>None</td>\n",
       "      <td>FOREST</td>\n",
       "      <td>None</td>\n",
       "      <td>Non-WUI</td>\n",
       "      <td>MULTIPOLYGON (((-308845.263 -48952.018, -30886...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>TI-58</td>\n",
       "      <td>1525.818568</td>\n",
       "      <td>TIMBER</td>\n",
       "      <td>PRIVATE_INDUSTRY</td>\n",
       "      <td>None</td>\n",
       "      <td>FOREST</td>\n",
       "      <td>None</td>\n",
       "      <td>Non-WUI</td>\n",
       "      <td>MULTIPOLYGON (((-291682.027 -45293.631, -29168...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>TI-61</td>\n",
       "      <td>30646.452164</td>\n",
       "      <td>TIMBER</td>\n",
       "      <td>PRIVATE_INDUSTRY</td>\n",
       "      <td>None</td>\n",
       "      <td>FOREST</td>\n",
       "      <td>None</td>\n",
       "      <td>Non-WUI</td>\n",
       "      <td>MULTIPOLYGON (((-286089.472 -38332.964, -28611...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>TI-64</td>\n",
       "      <td>2298.548819</td>\n",
       "      <td>TIMBER</td>\n",
       "      <td>PRIVATE_INDUSTRY</td>\n",
       "      <td>None</td>\n",
       "      <td>FOREST</td>\n",
       "      <td>None</td>\n",
       "      <td>Non-WUI</td>\n",
       "      <td>MULTIPOLYGON (((-295831.21 -46396.505, -295839...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>TI-70</td>\n",
       "      <td>34337.536889</td>\n",
       "      <td>TIMBER</td>\n",
       "      <td>PRIVATE_INDUSTRY</td>\n",
       "      <td>None</td>\n",
       "      <td>FOREST</td>\n",
       "      <td>None</td>\n",
       "      <td>Non-WUI</td>\n",
       "      <td>MULTIPOLYGON (((-286502.251 -48482.165, -28653...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5110 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               TRMTID_USER  ACTIVITY_QUANTITY  AGENCY PRIMARY_OWNERSHIP_GROUP  \\\n",
       "0     01-DN-101-DN-NOR-NON          32.400000  CALSTA                   STATE   \n",
       "1     01-DN-101-DN-NOR-WUI          32.400000  CALSTA                   STATE   \n",
       "2     01-DN-169-DN-NOR-NON           8.500000  CALSTA                   STATE   \n",
       "3     01-DN-169-DN-NOR-WUI           8.500000  CALSTA                   STATE   \n",
       "4     01-DN-197-DN-NOR-WUI           5.860000  CALSTA                   STATE   \n",
       "...                    ...                ...     ...                     ...   \n",
       "5105                 TI-55       12200.547236  TIMBER        PRIVATE_INDUSTRY   \n",
       "5106                 TI-58        1525.818568  TIMBER        PRIVATE_INDUSTRY   \n",
       "5107                 TI-61       30646.452164  TIMBER        PRIVATE_INDUSTRY   \n",
       "5108                 TI-64        2298.548819  TIMBER        PRIVATE_INDUSTRY   \n",
       "5109                 TI-70       34337.536889  TIMBER        PRIVATE_INDUSTRY   \n",
       "\n",
       "     COUNTY BROAD_VEGETATION_TYPE       REGION      WUI  \\\n",
       "0        DN                Forest  North Coast  Non-WUI   \n",
       "1        DN                Forest  North Coast  Non-WUI   \n",
       "2        DN                 Urban  North Coast      WUI   \n",
       "3        DN                 Urban  North Coast      WUI   \n",
       "4        DN                Forest  North Coast      WUI   \n",
       "...     ...                   ...          ...      ...   \n",
       "5105   None                FOREST         None  Non-WUI   \n",
       "5106   None                FOREST         None  Non-WUI   \n",
       "5107   None                FOREST         None  Non-WUI   \n",
       "5108   None                FOREST         None  Non-WUI   \n",
       "5109   None                FOREST         None  Non-WUI   \n",
       "\n",
       "                                               geometry  \n",
       "0     MULTIPOLYGON (((-342583.596 406960.852, -34258...  \n",
       "1     MULTIPOLYGON (((-342583.596 406960.852, -34258...  \n",
       "2     MULTIPOLYGON (((-337005.425 396726.106, -33698...  \n",
       "3     MULTIPOLYGON (((-337005.425 396726.106, -33698...  \n",
       "4     MULTIPOLYGON (((-339603.722 428203.383, -33960...  \n",
       "...                                                 ...  \n",
       "5105  MULTIPOLYGON (((-308845.263 -48952.018, -30886...  \n",
       "5106  MULTIPOLYGON (((-291682.027 -45293.631, -29168...  \n",
       "5107  MULTIPOLYGON (((-286089.472 -38332.964, -28611...  \n",
       "5108  MULTIPOLYGON (((-295831.21 -46396.505, -295839...  \n",
       "5109  MULTIPOLYGON (((-286502.251 -48482.165, -28653...  \n",
       "\n",
       "[5110 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "footprint2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd55fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
