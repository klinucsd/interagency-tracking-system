{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a6d9a14-e17b-4a32-8d05-bbbc28825d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6703453-a2ec-412d-9854-5a5fd0ed37bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "from multiprocessing import Manager\n",
    "from multiprocessing.managers import BaseManager\n",
    "\n",
    "\n",
    "from its_logging.logger_config import logger\n",
    "from utils.its_utils import clip_to_california, get_wfr_tf_template\n",
    "from utils.gdf_utils import repair_geometries, show_columns, verify_gdf_columns\n",
    "from utils.add_common_columns import add_common_columns\n",
    "from utils.enrich_polygons import enrich_polygons\n",
    "from utils.keep_fields import keep_fields\n",
    "from utils.assign_domains import assign_domains\n",
    "from utils.save_gdf_to_gdb import save_gdf_to_gdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a35dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_reference_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\Interagency Tracking System.gdb\"\n",
    "start_year, end_year = 1950, 2025\n",
    "\n",
    "process = psutil.Process(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46162e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrich.enrich_Timber_Industry import enrich_Timber_Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1882818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ti_input_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\Industry_spatial_FFSC_MOU_V2.0\\FFSC_MOU_v2_IndustryOnly.gdb\"\n",
    "ti_input_layer_name = \"FFSC_MOU_IndustryOnly_Pol\"\n",
    "\n",
    "output_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\Timber_Spatial_{}_{}.gdb\".format(start_year, end_year)\n",
    "output_layer_name = f\"Timber_Industry_Spatial_{datetime.today().strftime('%Y%m%d')}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92bd7b68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 16:47:20,631 INFO  [enrich.Timber_Industry]  Load the Timeber Industry Spatial Layer into a GeoDataFrame\n",
      "2025-08-14 16:47:21,268 INFO  [enrich.Timber_Industry]     time for loading FFSC_MOU_IndustryOnly_Pol: 0.6366462707519531\n",
      "2025-08-14 16:47:21,269 INFO  [enrich.Timber_Industry]     all required columns are present.\n",
      "2025-08-14 16:47:21,319 INFO  [enrich.Timber_Industry]  Performing Standardization...\n",
      "2025-08-14 16:47:21,320 INFO  [enrich.Timber_Industry]     step 1/15 Clip Features to California...\n",
      "2025-08-14 16:48:05,079 INFO  [enrich.Timber_Industry]        time for loading California and clipping: 43.759321451187134\n",
      "2025-08-14 16:48:05,080 INFO  [enrich.Timber_Industry]     step 2/15 Repairing Geometry...\n",
      "2025-08-14 16:48:05,380 INFO  [enrich.Timber_Industry]     step 3/15 Adding Common Columns...\n",
      "2025-08-14 16:48:05,415 INFO  [enrich.Timber_Industry]     step 4/15 Transfering Values...\n",
      "2025-08-14 16:48:05,417 INFO  [enrich.Timber_Industry]     step 5/15 Calculating Start and End Date...\n",
      "2025-08-14 16:48:05,424 INFO  [enrich.Timber_Industry]     step 6/15 Calculating Status...\n",
      "2025-08-14 16:48:05,426 INFO  [enrich.Timber_Industry]     step 7/15 Activity Quantity...\n",
      "2025-08-14 16:48:05,426 INFO  [enrich.Timber_Industry]     step 8/15 Enter Column Values...\n",
      "2025-08-14 16:48:05,427 INFO  [enrich.Timber_Industry]     step 9/15 Adding Original Activity Description to Crosswalk Column...\n",
      "2025-08-14 16:48:05,427 INFO  [enrich.Timber_Industry]     step 10/15 Select by Years...\n",
      "2025-08-14 16:48:05,433 INFO  [enrich.Timber_Industry]     step 10/15 Create New GeoDataframe Using the Template...\n",
      "2025-08-14 16:48:05,462 INFO  [enrich.Timber_Industry]     step 10/15 Append to Template...\n",
      "2025-08-14 16:48:05,477 INFO  [enrich.Timber_Industry]     step 10/15 Calculate Treatment Geometry...\n",
      "2025-08-14 16:48:05,478 INFO  [enrich.Timber_Industry]     step 11/15 Remove Unnecessary Columns...\n",
      "2025-08-14 16:48:05,481 INFO  [enrich.Timber_Industry]     step 12/15 Enriching Polygons...\n",
      "2025-08-14 16:48:05,482 INFO  [utils.enrich_polygons ]        Executing Polygon Enrichments...\n",
      "2025-08-14 16:48:05,482 INFO  [utils.enrich_polygons ]           Calculating Broad Vegetation Type...\n",
      "2025-08-14 16:48:05,482 INFO  [utils.enrich_polygons ]              enrich step 1/32 summarize veg within polygons\n",
      "2025-08-14 16:48:10,088 INFO  [utils.enrich_polygons ]                 Loaded Broad_Vegetation_Types from cache\n",
      "2025-08-14 16:48:10,088 INFO  [utils.enrich_polygons ]                    time for loading Broad_Vegetation_Types: 4.605731010437012\n",
      "2025-08-14 16:48:10,095 INFO  [utils.enrich_polygons ]              create numerical intermediate columns before multiprocessing\n",
      "2025-08-14 16:48:10,098 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-08-14 16:48:10,528 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-08-14 16:48:10,528 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2340615 \n",
      "2025-08-14 16:48:10,528 INFO  [utils.enrich_polygons ]                 records for summary: 3168\n",
      "2025-08-14 16:48:10,529 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-08-14 16:48:10,529 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-08-14 16:48:14,416 INFO  [utils.enrich_polygons ]                 joined records: 16390\n",
      "2025-08-14 16:48:14,417 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-08-14 16:48:14,417 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-08-14 16:52:51,758 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-08-14 16:52:51,759 INFO  [utils.enrich_polygons ]                 time for summarizing veg types: 281.670645236969\n",
      "2025-08-14 16:52:51,838 INFO  [utils.enrich_polygons ]              enrich step 7/32 select records where BROAD_VEGETATION_TYPE is not null\n",
      "2025-08-14 16:52:51,839 INFO  [utils.enrich_polygons ]              enrich step 8/32 set BVT_USERD of the selected records to YES\n",
      "2025-08-14 16:52:51,839 INFO  [utils.enrich_polygons ]              enrich step 9/32 select records where BROAD_VEGETATION_TYPE is null\n",
      "2025-08-14 16:52:51,840 INFO  [utils.enrich_polygons ]              enrich step 11/32 set BVT_USERD of the selected records to NO\n",
      "2025-08-14 16:52:51,843 INFO  [utils.enrich_polygons ]              enrich step 12/32 keeping only the necessary columns\n",
      "2025-08-14 16:52:52,479 INFO  [utils.enrich_polygons ]           Calculating WUI...\n",
      "2025-08-14 16:52:52,629 INFO  [utils.enrich_polygons ]              Loaded WUI from cache\n",
      "2025-08-14 16:52:52,629 INFO  [utils.enrich_polygons ]                 time for loading WUI: 0.14994049072265625\n",
      "2025-08-14 16:52:52,630 INFO  [utils.enrich_polygons ]              enrich step 13/32 select records with null WUI\n",
      "2025-08-14 16:52:52,635 INFO  [utils.enrich_polygons ]              enrich step 14/32 select by WUI location\n",
      "2025-08-14 16:53:01,939 INFO  [utils.enrich_polygons ]              enrich step 15/32 calculate WUI yes\n",
      "2025-08-14 16:53:01,940 INFO  [utils.enrich_polygons ]              enrich step 16/32 select remaining null records\n",
      "2025-08-14 16:53:01,945 INFO  [utils.enrich_polygons ]              enrich step 17/32 calculate WUI no\n",
      "2025-08-14 16:53:01,946 INFO  [utils.enrich_polygons ]              enrich step 18/32 feature to point\n",
      "2025-08-14 16:53:01,955 INFO  [utils.enrich_polygons ]              enrich step 19/32 setup ORIG_FID\n",
      "2025-08-14 16:53:01,956 INFO  [utils.enrich_polygons ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-08-14 16:53:02,363 INFO  [utils.enrich_polygons ]              Loaded CALFIRE_Ownership_Update from cache\n",
      "2025-08-14 16:53:02,363 INFO  [utils.enrich_polygons ]                 time for loading CALFIRE_Ownership_Update: 0.4069478511810303\n",
      "2025-08-14 16:53:02,385 INFO  [utils.enrich_polygons ]              Loaded WFRTF_Regions from cache\n",
      "2025-08-14 16:53:02,385 INFO  [utils.enrich_polygons ]                 time for loading WFRTF_Regions: 0.021485567092895508\n",
      "2025-08-14 16:53:02,385 INFO  [utils.enrich_polygons ]              enrich step 20/32 spatial join ownership\n",
      "2025-08-14 16:53:04,598 INFO  [utils.enrich_polygons ]              enrich step 21/32 spatial join with regions layer\n",
      "2025-08-14 16:53:05,574 INFO  [utils.enrich_polygons ]              enrich step 22/32 add ownership and region\n",
      "2025-08-14 16:53:05,580 INFO  [utils.enrich_polygons ]              enrich step 23/32 calculate ownership field\n",
      "2025-08-14 16:53:05,580 INFO  [utils.enrich_polygons ]              enrich step 24/32 calculate county field\n",
      "2025-08-14 16:53:05,580 INFO  [utils.enrich_polygons ]              enrich step 25/32 calculate region field\n",
      "2025-08-14 16:53:05,581 INFO  [utils.enrich_polygons ]              enrich step 26/32 set TRMT_GEOM\n",
      "2025-08-14 16:53:05,582 INFO  [utils.enrich_polygons ]              enrich step 27/32 calculating years...\n",
      "2025-08-14 16:53:05,597 INFO  [utils.enrich_polygons ]              enrich step 28/32 Initiating Crosswalk...\n",
      "2025-08-14 16:53:05,597 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-08-14 16:53:05,598 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-08-14 16:53:05,628 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-08-14 16:53:05,633 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-08-14 16:53:05,634 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-08-14 16:53:05,635 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-08-14 16:53:05,635 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "2025-08-14 16:53:05,645 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 16:53:05,669 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-08-14 16:53:05,750 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-08-14 16:53:05,750 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-08-14 16:53:05,750 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-08-14 16:53:05,751 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-08-14 16:53:05,753 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-08-14 16:53:05,754 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-08-14 16:53:05,754 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-08-14 16:53:05,755 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-08-14 16:53:05,755 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-08-14 16:53:05,757 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Status is 'Active' unless Agency is 'CNRA' \n",
      "2025-08-14 16:53:05,762 INFO  [utils.enrich_polygons ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-08-14 16:53:05,762 INFO  [utils.enrich_polygons ]              enrich step 29/32 Calculating Latitude and Longitude...\n",
      "2025-08-14 16:53:05,775 INFO  [utils.enrich_polygons ]              enrich step 30/32 calculate treatment acres\n",
      "2025-08-14 16:53:05,778 INFO  [utils.enrich_polygons ]              enrich step 31/32 removing unnecessary fields\n",
      "2025-08-14 16:53:05,781 INFO  [utils.enrich_polygons ]              enrich step 32/32 delete if County is Null\n",
      "2025-08-14 16:53:05,968 INFO  [enrich.Timber_Industry]     step 13/15 Calculate Treatment ID...\n",
      "2025-08-14 16:53:05,969 INFO  [enrich.Timber_Industry]     step 14/15 Assign Domains...\n",
      "2025-08-14 16:53:06,038 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-08-14 16:53:06,044 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-08-14 16:53:06,051 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-08-14 16:53:06,057 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-08-14 16:53:06,065 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-08-14 16:53:06,071 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-08-14 16:53:06,077 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-08-14 16:53:06,084 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-08-14 16:53:06,092 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-08-14 16:53:06,098 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-08-14 16:53:06,104 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-08-14 16:53:06,110 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-08-14 16:53:06,117 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-08-14 16:53:06,124 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-08-14 16:53:06,131 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-08-14 16:53:06,137 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-08-14 16:53:06,137 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-08-14 16:53:06,143 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-08-14 16:53:06,149 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-08-14 16:53:06,155 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-08-14 16:53:06,155 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-08-14 16:53:06,162 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-08-14 16:53:06,170 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-08-14 16:53:06,184 INFO  [enrich.Timber_Industry]     step 15/15 Save Result...\n",
      "2025-08-14 16:53:06,184 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-08-14 16:53:06,185 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-08-14 16:53:06,209 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\Timber_Nonspatial_1950_2025.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 16:53:06,519 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\Timber_Nonspatial_1950_2025.gdb Timber_Nonspatial_20250814\n"
     ]
    }
   ],
   "source": [
    "enrich_Timber_Industry(ti_input_gdb_path,\n",
    "                       ti_input_layer_name,\n",
    "                       a_reference_gdb_path,\n",
    "                       start_year,\n",
    "                       end_year,\n",
    "                       output_gdb_path,\n",
    "                       output_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f099f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.managers import NamespaceProxy, BaseManager\n",
    "from pandas import DataFrame\n",
    "import inspect\n",
    "import os\n",
    "\n",
    "class MyDataFrame(DataFrame):\n",
    "    def __getstate__(self):\n",
    "        print(f'dataframe being pickled in pid {os.getpid()}')\n",
    "        return super().__getstate__()\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        print(f'dataframe being unpickled in pid {os.getpid()}')\n",
    "        print()\n",
    "        return super().__setstate__(state)\n",
    "\n",
    "\n",
    "class ObjProxy(NamespaceProxy):\n",
    "    \"\"\"Returns a proxy instance for any user defined data-type. The proxy instance will have the namespace and\n",
    "    functions of the data-type (except private/protected callables/attributes). Furthermore, the proxy will be\n",
    "    pickable and can its state can be shared among different processes. \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def populate_obj_attributes(cls, real_cls):\n",
    "        DISALLOWED = set(dir(cls))\n",
    "        ALLOWED = ['__sizeof__', '__eq__', '__ne__', '__le__', '__repr__', '__dict__', '__lt__',\n",
    "                   '__gt__']\n",
    "        DISALLOWED.add('__class__')\n",
    "        new_dict = {}\n",
    "        for (attr, value) in inspect.getmembers(real_cls, callable):\n",
    "            if attr not in DISALLOWED or attr in ALLOWED:\n",
    "                new_dict[attr] = proxy_wrap(attr)\n",
    "        return new_dict\n",
    "\n",
    "\n",
    "def proxy_wrap(attr):\n",
    "    \"\"\" This method creates function that calls the proxified object's method.\"\"\"\n",
    "    def f(self, *args, **kwargs):\n",
    "\n",
    "        # _callmethod is the method that proxies provided by multiprocessing use to call methods in the proxified object\n",
    "        return self._callmethod(attr, args, kwargs)\n",
    "\n",
    "    return f\n",
    "\n",
    "# Create a class during runtime\n",
    "new_dict = ObjProxy.populate_obj_attributes(MyDataFrame)\n",
    "DataFrameObjProxy = type(\"DataFrameObjProxy\", (ObjProxy,), new_dict)\n",
    "BaseManager.register('DataFrame', MyDataFrame, DataFrameObjProxy, exposed=tuple(dir(DataFrameObjProxy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff0115e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 05:25:31,057 INFO  [enrich.enrich_USFS    ]  Loading the USFS data into GeoDataFrames: Actv_CommonAttribute_PL_Region05.gdb : Actv_CommonAttribute_PL\n",
      "2025-06-04 05:25:31,058 INFO  [enrich.enrich_USFS    ]     Loading USFS data from cache\n",
      "2025-06-04 05:25:37,050 INFO  [enrich.enrich_USFS    ]        records: 748591\n",
      "2025-06-04 05:25:37,051 INFO  [enrich.enrich_USFS    ]        time for loading USFS: 5.9931745529174805\n",
      "2025-06-04 05:25:37,052 INFO  [enrich.enrich_USFS    ]     all required columns are present.\n",
      "2025-06-04 05:25:48,340 INFO  [enrich.enrich_USFS    ]  Performing Standardization...\n",
      "2025-06-04 05:25:48,394 INFO  [enrich.enrich_USFS    ]     found 55793 rows with empty geometry\n",
      "2025-06-04 05:25:48,394 INFO  [enrich.enrich_USFS    ]     drop 55793 rows with empty geometry\n",
      "2025-06-04 05:25:49,711 INFO  [enrich.enrich_USFS    ]     records in California: 683960\n",
      "2025-06-04 05:25:49,712 INFO  [enrich.enrich_USFS    ]     step 1/8 Selecting Features...\n",
      "2025-06-04 05:25:51,336 INFO  [enrich.enrich_USFS    ]        selected Activities have 403354 records\n",
      "2025-06-04 05:25:51,337 INFO  [enrich.enrich_USFS    ]     step 2/8 Repairing Geometry...\n",
      "2025-06-04 05:26:21,730 INFO  [enrich.enrich_USFS    ]     step 3/8 Adding Fields...\n",
      "2025-06-04 05:26:23,721 INFO  [enrich.enrich_USFS    ]     step 4/8 Transfering Attributes...\n",
      "2025-06-04 05:26:23,839 INFO  [enrich.enrich_USFS    ]     step 5/8 Calculating End Date...\n",
      "2025-06-04 05:26:23,848 INFO  [enrich.enrich_USFS    ]     step 6/8 Calculating Status...\n",
      "2025-06-04 05:26:26,923 INFO  [enrich.enrich_USFS    ]     step 7/8 Activity Quantity...\n",
      "2025-06-04 05:26:26,926 INFO  [enrich.enrich_USFS    ]     step 8/8 Enter Field Values...\n",
      "2025-06-04 05:26:27,021 INFO  [enrich.enrich_USFS    ]  Remove Unnecessary Columns...\n",
      "2025-06-04 05:26:27,429 INFO  [enrich.enrich_USFS    ]  Select records between 1950 and 2025...\n",
      "2025-06-04 05:26:27,863 INFO  [enrich.enrich_USFS    ]  Enriching Dataset...\n",
      "2025-06-04 05:26:27,864 INFO  [utils.enrich_polygons ]        Executing Polygon Enrichments...\n",
      "2025-06-04 05:26:27,864 INFO  [utils.enrich_polygons ]           Calculating Broad Vegetation Type...\n",
      "2025-06-04 05:26:27,865 INFO  [utils.enrich_polygons ]              enrich step 1/32 summarize veg within polygons\n",
      "2025-06-04 05:26:32,043 INFO  [utils.enrich_polygons ]                 Loaded Broad_Vegetation_Types from cache\n",
      "2025-06-04 05:26:32,044 INFO  [utils.enrich_polygons ]                    time for loading Broad_Vegetation_Types: 4.178954839706421\n",
      "2025-06-04 05:26:32,761 INFO  [utils.enrich_polygons ]              create numerical intermediate columns before multiprocessing\n",
      "2025-06-04 05:26:32,763 INFO  [utils.enrich_polygons ]                    Summarizing veg types with 401985 records may take up to 2411 minutes depending on the geometries.\n",
      "2025-06-04 05:26:33,031 INFO  [utils.enrich_polygons ]                 split into 41 chunks with 10000 records\n",
      "2025-06-04 05:26:33,031 INFO  [utils.enrich_polygons ]              ================ processing chunk 1 ================\n",
      "2025-06-04 05:26:33,832 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 05:26:34,407 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 05:26:34,407 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3347340 \n",
      "2025-06-04 05:26:34,408 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 05:26:34,408 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 05:26:34,409 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 05:26:46,738 INFO  [utils.enrich_polygons ]                 joined records: 75127\n",
      "2025-06-04 05:26:46,739 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 05:26:46,739 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 05:35:43,446 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 05:35:43,600 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 05:35:43,600 INFO  [utils.enrich_polygons ]              ================ processing chunk 2 ================\n",
      "2025-06-04 05:35:44,387 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 05:35:45,044 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 05:35:45,045 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3347304 \n",
      "2025-06-04 05:35:45,045 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 05:35:45,045 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 05:35:45,046 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 05:35:51,290 INFO  [utils.enrich_polygons ]                 joined records: 41627\n",
      "2025-06-04 05:35:51,291 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 05:35:51,292 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 05:48:33,485 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 05:48:33,622 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 05:48:33,622 INFO  [utils.enrich_polygons ]              ================ processing chunk 3 ================\n",
      "2025-06-04 05:48:34,368 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 05:48:35,007 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 05:48:35,007 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3390870 \n",
      "2025-06-04 05:48:35,008 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 05:48:35,008 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 05:48:35,008 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 05:48:56,857 INFO  [utils.enrich_polygons ]                 joined records: 34015\n",
      "2025-06-04 05:48:56,858 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 05:48:56,859 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 06:05:35,974 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 06:05:36,109 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 06:05:36,109 INFO  [utils.enrich_polygons ]              ================ processing chunk 4 ================\n",
      "2025-06-04 06:05:36,746 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 06:05:37,345 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 06:05:37,346 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3081621 \n",
      "2025-06-04 06:05:37,346 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 06:05:37,346 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 06:05:37,346 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 06:05:40,232 INFO  [utils.enrich_polygons ]                 joined records: 33365\n",
      "2025-06-04 06:05:40,233 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 06:05:40,234 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 06:20:36,299 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 06:20:36,416 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 06:20:36,416 INFO  [utils.enrich_polygons ]              ================ processing chunk 5 ================\n",
      "2025-06-04 06:20:37,091 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 06:20:37,681 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 06:20:37,682 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3087932 \n",
      "2025-06-04 06:20:37,682 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 06:20:37,682 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 06:20:37,683 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 06:20:41,358 INFO  [utils.enrich_polygons ]                 joined records: 36349\n",
      "2025-06-04 06:20:41,359 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 06:20:41,360 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 06:34:26,605 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 06:34:26,717 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 06:34:26,717 INFO  [utils.enrich_polygons ]              ================ processing chunk 6 ================\n",
      "2025-06-04 06:34:27,230 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 06:34:27,756 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 06:34:27,756 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2872471 \n",
      "2025-06-04 06:34:27,757 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 06:34:27,757 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 06:34:27,757 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 06:34:31,857 INFO  [utils.enrich_polygons ]                 joined records: 36590\n",
      "2025-06-04 06:34:31,858 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 06:34:31,858 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 06:49:39,512 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 06:49:39,811 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 06:49:39,811 INFO  [utils.enrich_polygons ]              ================ processing chunk 7 ================\n",
      "2025-06-04 06:49:40,359 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 06:49:40,848 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 06:49:40,848 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2623531 \n",
      "2025-06-04 06:49:40,849 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 06:49:40,849 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 06:49:40,849 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 06:49:44,862 INFO  [utils.enrich_polygons ]                 joined records: 26643\n",
      "2025-06-04 06:49:44,863 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 06:49:44,864 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 07:01:47,849 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 07:01:47,947 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 07:01:47,948 INFO  [utils.enrich_polygons ]              ================ processing chunk 8 ================\n",
      "2025-06-04 07:01:48,492 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 07:01:49,001 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 07:01:49,002 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2866712 \n",
      "2025-06-04 07:01:49,002 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 07:01:49,002 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 07:01:49,003 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 07:01:54,427 INFO  [utils.enrich_polygons ]                 joined records: 25465\n",
      "2025-06-04 07:01:54,429 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 07:01:54,429 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 07:13:18,894 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 07:13:18,991 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 07:13:18,992 INFO  [utils.enrich_polygons ]              ================ processing chunk 9 ================\n",
      "2025-06-04 07:13:19,651 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 07:13:20,196 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 07:13:20,196 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3297128 \n",
      "2025-06-04 07:13:20,197 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 07:13:20,197 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 07:13:20,197 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 07:13:24,490 INFO  [utils.enrich_polygons ]                 joined records: 31082\n",
      "2025-06-04 07:13:24,491 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 07:13:24,491 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 07:29:13,969 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 07:29:14,089 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 07:29:14,089 INFO  [utils.enrich_polygons ]              ================ processing chunk 10 ================\n",
      "2025-06-04 07:29:14,667 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 07:29:15,151 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 07:29:15,152 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2495618 \n",
      "2025-06-04 07:29:15,152 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 07:29:15,152 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 07:29:15,152 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 07:29:17,924 INFO  [utils.enrich_polygons ]                 joined records: 17908\n",
      "2025-06-04 07:29:17,925 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 07:29:17,925 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 07:42:16,282 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 07:42:16,393 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 07:42:16,393 INFO  [utils.enrich_polygons ]              ================ processing chunk 11 ================\n",
      "2025-06-04 07:42:16,987 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 07:42:17,440 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 07:42:17,441 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 1990299 \n",
      "2025-06-04 07:42:17,441 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 07:42:17,441 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 07:42:17,442 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 07:42:20,097 INFO  [utils.enrich_polygons ]                 joined records: 23832\n",
      "2025-06-04 07:42:20,098 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 07:42:20,098 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 07:54:44,561 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 07:54:44,664 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 07:54:44,664 INFO  [utils.enrich_polygons ]              ================ processing chunk 12 ================\n",
      "2025-06-04 07:54:45,434 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 07:54:45,992 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 07:54:45,993 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2665817 \n",
      "2025-06-04 07:54:45,993 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 07:54:45,994 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 07:54:45,994 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 07:56:10,002 INFO  [utils.enrich_polygons ]                 joined records: 33878\n",
      "2025-06-04 07:56:10,003 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 07:56:10,003 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 08:05:23,904 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 08:05:24,033 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 08:05:24,034 INFO  [utils.enrich_polygons ]              ================ processing chunk 13 ================\n",
      "2025-06-04 08:05:24,867 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 08:05:25,512 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 08:05:25,513 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3308140 \n",
      "2025-06-04 08:05:25,513 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 08:05:25,513 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 08:05:25,514 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 08:05:30,155 INFO  [utils.enrich_polygons ]                 joined records: 39108\n",
      "2025-06-04 08:05:30,156 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 08:05:30,156 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 08:13:49,744 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 08:13:49,887 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 08:13:49,888 INFO  [utils.enrich_polygons ]              ================ processing chunk 14 ================\n",
      "2025-06-04 08:13:50,533 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 08:13:50,826 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 08:13:50,827 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 949905 \n",
      "2025-06-04 08:13:50,827 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 08:13:50,827 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 08:13:50,827 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 08:13:52,684 INFO  [utils.enrich_polygons ]                 joined records: 19983\n",
      "2025-06-04 08:13:52,685 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 08:13:52,685 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 08:32:34,307 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 08:32:34,420 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 08:32:34,420 INFO  [utils.enrich_polygons ]              ================ processing chunk 15 ================\n",
      "2025-06-04 08:32:35,020 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 08:32:35,359 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 08:32:35,359 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 1224629 \n",
      "2025-06-04 08:32:35,360 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 08:32:35,360 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 08:32:35,360 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 08:32:37,254 INFO  [utils.enrich_polygons ]                 joined records: 18984\n",
      "2025-06-04 08:32:37,255 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 08:32:37,256 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 08:50:32,564 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 08:50:32,674 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 08:50:32,674 INFO  [utils.enrich_polygons ]              ================ processing chunk 16 ================\n",
      "2025-06-04 08:50:33,318 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 08:50:34,003 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 08:50:34,004 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3335731 \n",
      "2025-06-04 08:50:34,004 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 08:50:34,005 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 08:50:34,005 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 08:50:37,257 INFO  [utils.enrich_polygons ]                 joined records: 26866\n",
      "2025-06-04 08:50:37,258 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 08:50:37,258 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 09:06:36,881 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 09:06:36,996 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 09:06:36,997 INFO  [utils.enrich_polygons ]              ================ processing chunk 17 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 09:06:37,565 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 09:06:37,967 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 09:06:37,967 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2070119 \n",
      "2025-06-04 09:06:37,967 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 09:06:37,968 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 09:06:37,968 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 09:06:40,234 INFO  [utils.enrich_polygons ]                 joined records: 19140\n",
      "2025-06-04 09:06:40,235 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 09:06:40,235 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 09:22:02,799 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 09:22:02,900 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 09:22:02,900 INFO  [utils.enrich_polygons ]              ================ processing chunk 18 ================\n",
      "2025-06-04 09:22:03,474 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 09:22:03,977 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 09:22:03,977 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2596995 \n",
      "2025-06-04 09:22:03,977 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 09:22:03,978 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 09:22:03,978 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 09:22:10,851 INFO  [utils.enrich_polygons ]                 joined records: 22852\n",
      "2025-06-04 09:22:10,852 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 09:22:10,852 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 09:37:10,567 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 09:37:10,670 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 09:37:10,670 INFO  [utils.enrich_polygons ]              ================ processing chunk 19 ================\n",
      "2025-06-04 09:37:11,252 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 09:37:11,745 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 09:37:11,745 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2484898 \n",
      "2025-06-04 09:37:11,745 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 09:37:11,746 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 09:37:11,746 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 09:37:14,128 INFO  [utils.enrich_polygons ]                 joined records: 20135\n",
      "2025-06-04 09:37:14,129 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 09:37:14,129 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 09:52:50,116 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 09:52:50,221 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 09:52:50,222 INFO  [utils.enrich_polygons ]              ================ processing chunk 20 ================\n",
      "2025-06-04 09:52:51,022 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 09:52:51,577 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 09:52:51,578 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3169590 \n",
      "2025-06-04 09:52:51,578 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 09:52:51,578 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 09:52:51,579 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 09:52:55,800 INFO  [utils.enrich_polygons ]                 joined records: 28001\n",
      "2025-06-04 09:52:55,801 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 09:52:55,802 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 10:08:03,777 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 10:08:03,914 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 10:08:03,914 INFO  [utils.enrich_polygons ]              ================ processing chunk 21 ================\n",
      "2025-06-04 10:08:04,922 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 10:08:05,564 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 10:08:05,564 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3284578 \n",
      "2025-06-04 10:08:05,565 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 10:08:05,565 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 10:08:05,565 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 10:08:14,328 INFO  [utils.enrich_polygons ]                 joined records: 44529\n",
      "2025-06-04 10:08:14,330 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 10:08:14,330 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 10:21:10,516 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 10:21:10,707 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 10:21:10,707 INFO  [utils.enrich_polygons ]              ================ processing chunk 22 ================\n",
      "2025-06-04 10:21:11,750 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 10:21:12,389 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 10:21:12,390 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3262897 \n",
      "2025-06-04 10:21:12,390 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 10:21:12,390 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 10:21:12,390 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 10:21:21,456 INFO  [utils.enrich_polygons ]                 joined records: 43821\n",
      "2025-06-04 10:21:21,457 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 10:21:21,458 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 10:35:45,763 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 10:35:45,945 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 10:35:45,946 INFO  [utils.enrich_polygons ]              ================ processing chunk 23 ================\n",
      "2025-06-04 10:35:47,053 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 10:35:47,704 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 10:35:47,704 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3291688 \n",
      "2025-06-04 10:35:47,705 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 10:35:47,705 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 10:35:47,705 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 10:37:38,766 INFO  [utils.enrich_polygons ]                 joined records: 48167\n",
      "2025-06-04 10:37:38,767 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 10:37:38,767 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 10:52:37,975 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 10:52:38,166 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 10:52:38,167 INFO  [utils.enrich_polygons ]              ================ processing chunk 24 ================\n",
      "2025-06-04 10:52:39,137 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 10:52:39,823 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 10:52:39,823 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3381703 \n",
      "2025-06-04 10:52:39,824 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 10:52:39,824 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 10:52:39,825 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 10:52:53,821 INFO  [utils.enrich_polygons ]                 joined records: 41839\n",
      "2025-06-04 10:52:53,822 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 10:52:53,823 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 11:08:02,660 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 11:08:02,826 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 11:08:02,826 INFO  [utils.enrich_polygons ]              ================ processing chunk 25 ================\n",
      "2025-06-04 11:08:03,855 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 11:08:04,527 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 11:08:04,528 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3380434 \n",
      "2025-06-04 11:08:04,528 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 11:08:04,528 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 11:08:04,529 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 11:08:17,708 INFO  [utils.enrich_polygons ]                 joined records: 40983\n",
      "2025-06-04 11:08:17,710 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 11:08:17,710 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 11:23:15,882 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 11:23:16,058 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 11:23:16,058 INFO  [utils.enrich_polygons ]              ================ processing chunk 26 ================\n",
      "2025-06-04 11:23:17,080 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 11:23:17,730 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 11:23:17,730 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3261810 \n",
      "2025-06-04 11:23:17,731 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 11:23:17,731 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 11:23:17,731 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 11:23:29,532 INFO  [utils.enrich_polygons ]                 joined records: 40041\n",
      "2025-06-04 11:23:29,533 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 11:23:29,533 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 11:39:10,559 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 11:39:10,734 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 11:39:10,734 INFO  [utils.enrich_polygons ]              ================ processing chunk 27 ================\n",
      "2025-06-04 11:39:11,700 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 11:39:12,360 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 11:39:12,360 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3264958 \n",
      "2025-06-04 11:39:12,361 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 11:39:12,361 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 11:39:12,361 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 11:39:17,564 INFO  [utils.enrich_polygons ]                 joined records: 42783\n",
      "2025-06-04 11:39:17,566 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 11:39:17,566 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 11:55:28,535 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 11:55:28,698 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 11:55:28,699 INFO  [utils.enrich_polygons ]              ================ processing chunk 28 ================\n",
      "2025-06-04 11:55:29,668 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 11:55:30,299 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 11:55:30,299 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3258036 \n",
      "2025-06-04 11:55:30,300 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 11:55:30,300 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 11:55:30,300 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 11:55:37,544 INFO  [utils.enrich_polygons ]                 joined records: 44457\n",
      "2025-06-04 11:55:37,545 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 11:55:37,546 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 12:11:39,528 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 12:11:39,690 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 12:11:39,691 INFO  [utils.enrich_polygons ]              ================ processing chunk 29 ================\n",
      "2025-06-04 12:11:40,606 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 12:11:41,215 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 12:11:41,215 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3209633 \n",
      "2025-06-04 12:11:41,216 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 12:11:41,216 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 12:11:41,216 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 12:11:48,217 INFO  [utils.enrich_polygons ]                 joined records: 40910\n",
      "2025-06-04 12:11:48,218 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 12:11:48,218 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 12:25:59,700 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 12:25:59,849 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 12:25:59,849 INFO  [utils.enrich_polygons ]              ================ processing chunk 30 ================\n",
      "2025-06-04 12:26:00,801 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 12:26:01,312 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 12:26:01,312 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 2897846 \n",
      "2025-06-04 12:26:01,313 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 12:26:01,313 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 12:26:01,313 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 12:27:02,935 INFO  [utils.enrich_polygons ]                 joined records: 49751\n",
      "2025-06-04 12:27:02,936 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 12:27:02,937 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 12:41:31,493 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 12:41:31,641 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 12:41:31,641 INFO  [utils.enrich_polygons ]              ================ processing chunk 31 ================\n",
      "2025-06-04 12:41:32,557 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 12:41:33,140 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 12:41:33,141 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3282832 \n",
      "2025-06-04 12:41:33,141 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 12:41:33,141 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 12:41:33,142 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 12:41:38,419 INFO  [utils.enrich_polygons ]                 joined records: 38574\n",
      "2025-06-04 12:41:38,420 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 12:41:38,421 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 12:55:16,156 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 12:55:16,310 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 12:55:16,310 INFO  [utils.enrich_polygons ]              ================ processing chunk 32 ================\n",
      "2025-06-04 12:55:17,153 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 12:55:17,724 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 12:55:17,725 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3168268 \n",
      "2025-06-04 12:55:17,725 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 12:55:17,725 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 12:55:17,726 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 12:55:23,911 INFO  [utils.enrich_polygons ]                 joined records: 37618\n",
      "2025-06-04 12:55:23,912 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 12:55:23,912 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 13:08:44,483 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 13:08:44,684 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 13:08:44,684 INFO  [utils.enrich_polygons ]              ================ processing chunk 33 ================\n",
      "2025-06-04 13:08:45,467 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 13:08:46,027 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 13:08:46,028 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3177839 \n",
      "2025-06-04 13:08:46,028 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 13:08:46,029 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 13:08:46,029 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 13:08:52,551 INFO  [utils.enrich_polygons ]                 joined records: 43436\n",
      "2025-06-04 13:08:52,553 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 13:08:52,553 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 13:20:37,345 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 13:20:37,477 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 13:20:37,477 INFO  [utils.enrich_polygons ]              ================ processing chunk 34 ================\n",
      "2025-06-04 13:20:38,243 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 13:20:38,817 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 13:20:38,817 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3176033 \n",
      "2025-06-04 13:20:38,818 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 13:20:38,818 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 13:20:38,818 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 13:20:45,481 INFO  [utils.enrich_polygons ]                 joined records: 40844\n",
      "2025-06-04 13:20:45,483 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 13:20:45,483 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 13:32:58,324 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 13:32:58,449 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 13:32:58,450 INFO  [utils.enrich_polygons ]              ================ processing chunk 35 ================\n",
      "2025-06-04 13:32:59,396 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 13:32:59,945 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 13:32:59,946 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3171531 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 13:32:59,946 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 13:32:59,946 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 13:32:59,947 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 13:33:05,327 INFO  [utils.enrich_polygons ]                 joined records: 28579\n",
      "2025-06-04 13:33:05,329 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 13:33:05,329 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 13:49:32,719 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 13:49:32,881 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 13:49:32,882 INFO  [utils.enrich_polygons ]              ================ processing chunk 36 ================\n",
      "2025-06-04 13:49:34,161 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 13:49:34,790 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 13:49:34,790 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3176350 \n",
      "2025-06-04 13:49:34,791 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 13:49:34,791 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 13:49:34,791 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 13:49:43,120 INFO  [utils.enrich_polygons ]                 joined records: 31914\n",
      "2025-06-04 13:49:43,121 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 13:49:43,121 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 14:05:57,085 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 14:05:57,299 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 14:05:57,300 INFO  [utils.enrich_polygons ]              ================ processing chunk 37 ================\n",
      "2025-06-04 14:05:58,622 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 14:05:59,279 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 14:05:59,279 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3286505 \n",
      "2025-06-04 14:05:59,280 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 14:05:59,280 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 14:05:59,280 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 14:06:08,618 INFO  [utils.enrich_polygons ]                 joined records: 51125\n",
      "2025-06-04 14:06:08,620 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 14:06:08,620 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 14:16:47,972 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 14:16:48,183 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 14:16:48,184 INFO  [utils.enrich_polygons ]              ================ processing chunk 38 ================\n",
      "2025-06-04 14:16:49,855 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 14:16:50,542 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 14:16:50,542 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3371246 \n",
      "2025-06-04 14:16:50,543 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 14:16:50,543 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 14:16:50,543 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 14:17:05,902 INFO  [utils.enrich_polygons ]                 joined records: 44136\n",
      "2025-06-04 14:17:05,904 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 14:17:05,904 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 14:33:06,247 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 14:33:06,505 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 14:33:06,505 INFO  [utils.enrich_polygons ]              ================ processing chunk 39 ================\n",
      "2025-06-04 14:33:07,739 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 14:33:08,403 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 14:33:08,403 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3352471 \n",
      "2025-06-04 14:33:08,404 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 14:33:08,404 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 14:33:08,404 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 14:33:23,046 INFO  [utils.enrich_polygons ]                 joined records: 34503\n",
      "2025-06-04 14:33:23,048 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 14:33:23,048 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 14:51:25,783 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 14:51:25,974 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 14:51:25,975 INFO  [utils.enrich_polygons ]              ================ processing chunk 40 ================\n",
      "2025-06-04 14:51:27,693 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 14:51:28,332 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 14:51:28,332 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3358447 \n",
      "2025-06-04 14:51:28,333 INFO  [utils.enrich_polygons ]                 records for summary: 10000\n",
      "2025-06-04 14:51:28,333 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 14:51:28,333 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 14:51:45,969 INFO  [utils.enrich_polygons ]                 joined records: 44919\n",
      "2025-06-04 14:51:45,970 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 14:51:45,971 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 15:09:21,890 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 15:09:22,182 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 15:09:22,183 INFO  [utils.enrich_polygons ]              ================ processing chunk 41 ================\n",
      "2025-06-04 15:09:23,162 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 15:09:23,808 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 15:09:23,808 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3223044 \n",
      "2025-06-04 15:09:23,809 INFO  [utils.enrich_polygons ]                 records for summary: 1985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:09:23,809 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 15:09:23,809 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 15:15:55,344 INFO  [utils.enrich_polygons ]                 joined records: 55433\n",
      "2025-06-04 15:15:55,345 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 15:15:55,345 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 15:20:49,107 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 15:20:49,287 INFO  [utils.enrich_polygons ]                 saved enriched chunks into the cache\n",
      "2025-06-04 15:20:50,681 INFO  [utils.enrich_polygons ]                 time for summarizing veg types: 35658.63615942001\n",
      "2025-06-04 15:20:51,617 INFO  [utils.enrich_polygons ]              enrich step 7/32 select records where BROAD_VEGETATION_TYPE is not null\n",
      "2025-06-04 15:20:51,625 INFO  [utils.enrich_polygons ]              enrich step 8/32 set BVT_USERD of the selected records to YES\n",
      "2025-06-04 15:20:51,627 INFO  [utils.enrich_polygons ]              enrich step 9/32 select records where BROAD_VEGETATION_TYPE is null\n",
      "2025-06-04 15:20:51,634 INFO  [utils.enrich_polygons ]              enrich step 11/32 set BVT_USERD of the selected records to NO\n",
      "2025-06-04 15:20:51,655 INFO  [utils.enrich_polygons ]              enrich step 12/32 keeping only the necessary columns\n",
      "2025-06-04 15:20:52,480 INFO  [utils.enrich_polygons ]           Calculating WUI...\n",
      "2025-06-04 15:20:52,675 INFO  [utils.enrich_polygons ]              Loaded WUI from cache\n",
      "2025-06-04 15:20:52,675 INFO  [utils.enrich_polygons ]                 time for loading WUI: 0.19417047500610352\n",
      "2025-06-04 15:20:52,676 INFO  [utils.enrich_polygons ]              enrich step 13/32 select records with null WUI\n",
      "2025-06-04 15:20:52,750 INFO  [utils.enrich_polygons ]              enrich step 14/32 select by WUI location\n",
      "2025-06-04 15:21:53,783 INFO  [utils.enrich_polygons ]              enrich step 15/32 calculate WUI yes\n",
      "2025-06-04 15:21:53,784 INFO  [utils.enrich_polygons ]              enrich step 16/32 select remaining null records\n",
      "2025-06-04 15:21:53,845 INFO  [utils.enrich_polygons ]              enrich step 17/32 calculate WUI no\n",
      "2025-06-04 15:21:53,846 INFO  [utils.enrich_polygons ]              enrich step 18/32 feature to point\n",
      "2025-06-04 15:21:55,401 INFO  [utils.enrich_polygons ]              enrich step 19/32 setup ORIG_FID\n",
      "2025-06-04 15:21:55,403 INFO  [utils.enrich_polygons ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-06-04 15:21:55,920 INFO  [utils.enrich_polygons ]              Loaded CALFIRE_Ownership_Update from cache\n",
      "2025-06-04 15:21:55,920 INFO  [utils.enrich_polygons ]                 time for loading CALFIRE_Ownership_Update: 0.516880989074707\n",
      "2025-06-04 15:21:55,937 INFO  [utils.enrich_polygons ]              Loaded WFRTF_Regions from cache\n",
      "2025-06-04 15:21:55,937 INFO  [utils.enrich_polygons ]                 time for loading WFRTF_Regions: 0.016559600830078125\n",
      "2025-06-04 15:21:55,938 INFO  [utils.enrich_polygons ]              enrich step 20/32 spatial join ownership\n",
      "2025-06-04 15:26:37,977 INFO  [utils.enrich_polygons ]              enrich step 21/32 spatial join with regions layer\n",
      "2025-06-04 15:27:36,448 INFO  [utils.enrich_polygons ]              enrich step 22/32 add ownership and region\n",
      "2025-06-04 15:27:37,933 INFO  [utils.enrich_polygons ]              enrich step 23/32 calculate ownership field\n",
      "2025-06-04 15:27:37,935 INFO  [utils.enrich_polygons ]              enrich step 24/32 calculate county field\n",
      "2025-06-04 15:27:37,936 INFO  [utils.enrich_polygons ]              enrich step 25/32 calculate region field\n",
      "2025-06-04 15:27:37,938 INFO  [utils.enrich_polygons ]              enrich step 26/32 set TRMT_GEOM\n",
      "2025-06-04 15:27:37,939 INFO  [utils.enrich_polygons ]              enrich step 27/32 calculating years...\n",
      "2025-06-04 15:27:38,908 INFO  [utils.enrich_polygons ]              enrich step 28/32 Initiating Crosswalk...\n",
      "2025-06-04 15:27:38,908 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-06-04 15:27:38,908 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-06-04 15:27:38,957 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-06-04 15:27:39,869 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-06-04 15:27:39,899 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-06-04 15:27:39,934 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-06-04 15:27:39,941 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "2025-06-04 15:27:40,290 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-06-04 15:27:43,247 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-06-04 15:27:52,938 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-06-04 15:27:52,938 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-06-04 15:27:52,939 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-06-04 15:27:52,940 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-06-04 15:27:52,953 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-06-04 15:27:52,967 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-06-04 15:27:52,974 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-06-04 15:27:52,986 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-06-04 15:27:52,996 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-06-04 15:27:53,115 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Org is 'USFS' and Status is 'Active'\n",
      "2025-06-04 15:27:53,498 INFO  [utils.enrich_polygons ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-06-04 15:27:53,498 INFO  [utils.enrich_polygons ]              enrich step 29/32 Calculating Latitude and Longitude...\n",
      "2025-06-04 15:27:54,454 INFO  [utils.enrich_polygons ]              enrich step 30/32 calculate treatment acres\n",
      "2025-06-04 15:27:54,621 INFO  [utils.enrich_polygons ]              enrich step 31/32 removing unnecessary fields\n",
      "2025-06-04 15:27:54,871 INFO  [utils.enrich_polygons ]              enrich step 32/32 delete if County is Null\n",
      "2025-06-04 15:27:56,073 INFO  [enrich.enrich_USFS    ]  Assign Domains...\n",
      "2025-06-04 15:27:56,293 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-06-04 15:27:56,299 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-06-04 15:27:56,307 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-06-04 15:27:56,312 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-06-04 15:27:56,320 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-06-04 15:27:56,325 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-06-04 15:27:56,332 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-06-04 15:27:56,338 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-06-04 15:27:56,344 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-06-04 15:27:56,350 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-06-04 15:27:56,356 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-06-04 15:27:56,362 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:27:56,368 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-06-04 15:27:56,374 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-06-04 15:27:56,380 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-06-04 15:27:56,386 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-06-04 15:27:56,387 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-06-04 15:27:56,393 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-06-04 15:27:56,399 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-06-04 15:27:56,405 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-06-04 15:27:56,405 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-06-04 15:27:56,635 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-06-04 15:27:56,938 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-06-04 15:27:57,370 INFO  [enrich.enrich_USFS    ]  Save Result...\n",
      "2025-06-04 15:27:57,371 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-06-04 15:27:57,371 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\USFS_1950_2025.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:28:00,692 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n",
      "2025-06-04 15:28:28,384 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\USFS_1950_2025.gdb USFS_Region05_enriched_20250604\n"
     ]
    }
   ],
   "source": [
    "output_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\USFS_{}_{}.gdb\".format(start_year, end_year)\n",
    "if __name__ == '__main__':\n",
    "    from enrich.enrich_USFS import enrich_USFS\n",
    "    #from utils.mp_df import MyDataFrame, ObjProxy\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    region_ids = [\"05\"]#[\"04\", \"05\", \"06\"]\n",
    "    for region_id in region_ids:    \n",
    "        usfs_input_gdb_path = r'D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\FACTS_V2.0\\Actv_CommonAttribute_PL_Region{}.gdb'.format(region_id)\n",
    "        usfs_input_layer_name = \"Actv_CommonAttribute_PL\"\n",
    "        output_layer_name = f\"USFS_Region{region_id}_enriched_{datetime.today().strftime('%Y%m%d')}\"\n",
    "        # init multiprocessing manager in main module for Windows fork\n",
    "\n",
    "        \n",
    "        enrich_USFS(usfs_input_gdb_path,\n",
    "                    usfs_input_layer_name,\n",
    "                    a_reference_gdb_path,\n",
    "                    start_year,\n",
    "                    end_year,\n",
    "                    output_gdb_path,\n",
    "                    output_layer_name,\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df008fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 16:03:50,899 INFO  [enrich.enrich_USFS    ]  Loading the USFS data into GeoDataFrames: Actv_CommonAttribute_PL_Region04.gdb : Actv_CommonAttribute_PL\n",
      "2025-06-04 16:03:50,900 INFO  [enrich.enrich_USFS    ]     Loading USFS data from source and cache the data\n",
      "2025-06-04 16:04:19,996 INFO  [enrich.enrich_USFS    ]        records: 337783\n",
      "2025-06-04 16:04:19,996 INFO  [enrich.enrich_USFS    ]        time for loading USFS: 29.09639286994934\n",
      "2025-06-04 16:04:19,997 INFO  [enrich.enrich_USFS    ]     all required columns are present.\n",
      "2025-06-04 16:04:25,004 INFO  [enrich.enrich_USFS    ]  Performing Standardization...\n",
      "2025-06-04 16:04:25,138 INFO  [enrich.enrich_USFS    ]     found 137057 rows with empty geometry\n",
      "2025-06-04 16:04:25,139 INFO  [enrich.enrich_USFS    ]     drop 137057 rows with empty geometry\n",
      "2025-06-04 16:04:26,229 INFO  [enrich.enrich_USFS    ]     records in California: 979\n",
      "2025-06-04 16:04:26,230 INFO  [enrich.enrich_USFS    ]     step 1/8 Selecting Features...\n",
      "2025-06-04 16:04:26,245 INFO  [enrich.enrich_USFS    ]        selected Activities have 760 records\n",
      "2025-06-04 16:04:26,245 INFO  [enrich.enrich_USFS    ]     step 2/8 Repairing Geometry...\n",
      "2025-06-04 16:04:26,337 INFO  [enrich.enrich_USFS    ]     step 3/8 Adding Fields...\n",
      "2025-06-04 16:04:26,367 INFO  [enrich.enrich_USFS    ]     step 4/8 Transfering Attributes...\n",
      "2025-06-04 16:04:26,369 INFO  [enrich.enrich_USFS    ]     step 5/8 Calculating End Date...\n",
      "2025-06-04 16:04:26,370 INFO  [enrich.enrich_USFS    ]     step 6/8 Calculating Status...\n",
      "2025-06-04 16:04:26,379 INFO  [enrich.enrich_USFS    ]     step 7/8 Activity Quantity...\n",
      "2025-06-04 16:04:26,379 INFO  [enrich.enrich_USFS    ]     step 8/8 Enter Field Values...\n",
      "2025-06-04 16:04:26,381 INFO  [enrich.enrich_USFS    ]  Remove Unnecessary Columns...\n",
      "2025-06-04 16:04:26,385 INFO  [enrich.enrich_USFS    ]  Select records between 1950 and 2025...\n",
      "2025-06-04 16:04:26,388 INFO  [enrich.enrich_USFS    ]  Enriching Dataset...\n",
      "2025-06-04 16:04:26,388 INFO  [utils.enrich_polygons ]        Executing Polygon Enrichments...\n",
      "2025-06-04 16:04:26,389 INFO  [utils.enrich_polygons ]           Calculating Broad Vegetation Type...\n",
      "2025-06-04 16:04:26,389 INFO  [utils.enrich_polygons ]              enrich step 1/32 summarize veg within polygons\n",
      "2025-06-04 16:04:32,149 INFO  [utils.enrich_polygons ]                 Loaded Broad_Vegetation_Types from cache\n",
      "2025-06-04 16:04:32,150 INFO  [utils.enrich_polygons ]                    time for loading Broad_Vegetation_Types: 5.759950876235962\n",
      "2025-06-04 16:04:32,155 INFO  [utils.enrich_polygons ]              create numerical intermediate columns before multiprocessing\n",
      "2025-06-04 16:04:32,158 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 16:04:32,354 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 16:04:32,355 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 135255 \n",
      "2025-06-04 16:04:32,355 INFO  [utils.enrich_polygons ]                 records for summary: 760\n",
      "2025-06-04 16:04:32,356 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 16:04:32,356 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 16:04:33,540 INFO  [utils.enrich_polygons ]                 joined records: 5425\n",
      "2025-06-04 16:04:33,541 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 16:04:33,541 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 16:05:27,280 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 16:05:27,281 INFO  [utils.enrich_polygons ]                 time for summarizing veg types: 55.13131666183472\n",
      "2025-06-04 16:05:27,288 INFO  [utils.enrich_polygons ]              enrich step 7/32 select records where BROAD_VEGETATION_TYPE is not null\n",
      "2025-06-04 16:05:27,288 INFO  [utils.enrich_polygons ]              enrich step 8/32 set BVT_USERD of the selected records to YES\n",
      "2025-06-04 16:05:27,289 INFO  [utils.enrich_polygons ]              enrich step 9/32 select records where BROAD_VEGETATION_TYPE is null\n",
      "2025-06-04 16:05:27,289 INFO  [utils.enrich_polygons ]              enrich step 11/32 set BVT_USERD of the selected records to NO\n",
      "2025-06-04 16:05:27,292 INFO  [utils.enrich_polygons ]              enrich step 12/32 keeping only the necessary columns\n",
      "2025-06-04 16:05:29,481 INFO  [utils.enrich_polygons ]           Calculating WUI...\n",
      "2025-06-04 16:05:29,676 INFO  [utils.enrich_polygons ]              Loaded WUI from cache\n",
      "2025-06-04 16:05:29,677 INFO  [utils.enrich_polygons ]                 time for loading WUI: 0.19523978233337402\n",
      "2025-06-04 16:05:29,677 INFO  [utils.enrich_polygons ]              enrich step 13/32 select records with null WUI\n",
      "2025-06-04 16:05:29,682 INFO  [utils.enrich_polygons ]              enrich step 14/32 select by WUI location\n",
      "2025-06-04 16:05:29,730 INFO  [utils.enrich_polygons ]              enrich step 15/32 calculate WUI yes\n",
      "2025-06-04 16:05:29,731 INFO  [utils.enrich_polygons ]              enrich step 16/32 select remaining null records\n",
      "2025-06-04 16:05:29,735 INFO  [utils.enrich_polygons ]              enrich step 17/32 calculate WUI no\n",
      "2025-06-04 16:05:29,736 INFO  [utils.enrich_polygons ]              enrich step 18/32 feature to point\n",
      "2025-06-04 16:05:29,740 INFO  [utils.enrich_polygons ]              enrich step 19/32 setup ORIG_FID\n",
      "2025-06-04 16:05:29,741 INFO  [utils.enrich_polygons ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-06-04 16:05:30,211 INFO  [utils.enrich_polygons ]              Loaded CALFIRE_Ownership_Update from cache\n",
      "2025-06-04 16:05:30,211 INFO  [utils.enrich_polygons ]                 time for loading CALFIRE_Ownership_Update: 0.47026753425598145\n",
      "2025-06-04 16:05:30,222 INFO  [utils.enrich_polygons ]              Loaded WFRTF_Regions from cache\n",
      "2025-06-04 16:05:30,223 INFO  [utils.enrich_polygons ]                 time for loading WFRTF_Regions: 0.011296987533569336\n",
      "2025-06-04 16:05:30,223 INFO  [utils.enrich_polygons ]              enrich step 20/32 spatial join ownership\n",
      "2025-06-04 16:05:30,504 INFO  [utils.enrich_polygons ]              enrich step 21/32 spatial join with regions layer\n",
      "2025-06-04 16:05:30,554 INFO  [utils.enrich_polygons ]              enrich step 22/32 add ownership and region\n",
      "2025-06-04 16:05:30,560 INFO  [utils.enrich_polygons ]              enrich step 23/32 calculate ownership field\n",
      "2025-06-04 16:05:30,560 INFO  [utils.enrich_polygons ]              enrich step 24/32 calculate county field\n",
      "2025-06-04 16:05:30,561 INFO  [utils.enrich_polygons ]              enrich step 25/32 calculate region field\n",
      "2025-06-04 16:05:30,561 INFO  [utils.enrich_polygons ]              enrich step 26/32 set TRMT_GEOM\n",
      "2025-06-04 16:05:30,561 INFO  [utils.enrich_polygons ]              enrich step 27/32 calculating years...\n",
      "2025-06-04 16:05:30,565 INFO  [utils.enrich_polygons ]              enrich step 28/32 Initiating Crosswalk...\n",
      "2025-06-04 16:05:30,565 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-06-04 16:05:30,565 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-06-04 16:05:30,597 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-06-04 16:05:30,601 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-06-04 16:05:30,602 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-06-04 16:05:30,603 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-06-04 16:05:30,603 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "2025-06-04 16:05:30,605 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-06-04 16:05:30,613 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-06-04 16:05:30,634 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 16:05:30,635 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-06-04 16:05:30,635 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-06-04 16:05:30,635 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-06-04 16:05:30,636 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-06-04 16:05:30,637 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-06-04 16:05:30,637 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-06-04 16:05:30,638 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-06-04 16:05:30,638 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-06-04 16:05:30,639 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Org is 'USFS' and Status is 'Active'\n",
      "2025-06-04 16:05:30,642 INFO  [utils.enrich_polygons ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-06-04 16:05:30,643 INFO  [utils.enrich_polygons ]              enrich step 29/32 Calculating Latitude and Longitude...\n",
      "2025-06-04 16:05:30,647 INFO  [utils.enrich_polygons ]              enrich step 30/32 calculate treatment acres\n",
      "2025-06-04 16:05:30,648 INFO  [utils.enrich_polygons ]              enrich step 31/32 removing unnecessary fields\n",
      "2025-06-04 16:05:30,658 INFO  [utils.enrich_polygons ]              enrich step 32/32 delete if County is Null\n",
      "2025-06-04 16:05:30,847 INFO  [enrich.enrich_USFS    ]  Assign Domains...\n",
      "2025-06-04 16:05:30,921 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-06-04 16:05:30,928 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-06-04 16:05:30,936 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-06-04 16:05:30,941 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-06-04 16:05:30,948 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-06-04 16:05:30,954 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-06-04 16:05:30,959 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-06-04 16:05:30,965 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-06-04 16:05:30,971 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-06-04 16:05:30,976 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-06-04 16:05:30,982 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-06-04 16:05:30,987 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-06-04 16:05:30,993 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-06-04 16:05:30,999 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-06-04 16:05:31,005 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-06-04 16:05:31,010 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-06-04 16:05:31,011 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-06-04 16:05:31,016 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-06-04 16:05:31,022 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-06-04 16:05:31,027 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-06-04 16:05:31,028 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-06-04 16:05:31,037 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-06-04 16:05:31,046 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-06-04 16:05:31,062 INFO  [enrich.enrich_USFS    ]  Save Result...\n",
      "2025-06-04 16:05:31,062 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-06-04 16:05:31,062 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-06-04 16:05:31,068 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n",
      "2025-06-04 16:05:31,164 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\USFS_1950_2025.gdb USFS_Region04_enriched_20250604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\USFS_1950_2025.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 16:05:31,401 INFO  [enrich.enrich_USFS    ]  Loading the USFS data into GeoDataFrames: Actv_CommonAttribute_PL_Region06.gdb : Actv_CommonAttribute_PL\n",
      "2025-06-04 16:05:31,402 INFO  [enrich.enrich_USFS    ]     Loading USFS data from source and cache the data\n",
      "2025-06-04 16:07:14,442 INFO  [enrich.enrich_USFS    ]        records: 1213138\n",
      "2025-06-04 16:07:14,442 INFO  [enrich.enrich_USFS    ]        time for loading USFS: 103.04078197479248\n",
      "2025-06-04 16:07:14,443 INFO  [enrich.enrich_USFS    ]     all required columns are present.\n",
      "2025-06-04 16:07:39,281 INFO  [enrich.enrich_USFS    ]  Performing Standardization...\n",
      "2025-06-04 16:07:39,523 INFO  [enrich.enrich_USFS    ]     found 181936 rows with empty geometry\n",
      "2025-06-04 16:07:39,524 INFO  [enrich.enrich_USFS    ]     drop 181936 rows with empty geometry\n",
      "2025-06-04 16:07:44,763 INFO  [enrich.enrich_USFS    ]     records in California: 1205\n",
      "2025-06-04 16:07:44,764 INFO  [enrich.enrich_USFS    ]     step 1/8 Selecting Features...\n",
      "2025-06-04 16:07:44,780 INFO  [enrich.enrich_USFS    ]        selected Activities have 681 records\n",
      "2025-06-04 16:07:44,781 INFO  [enrich.enrich_USFS    ]     step 2/8 Repairing Geometry...\n",
      "2025-06-04 16:07:45,210 INFO  [enrich.enrich_USFS    ]     step 3/8 Adding Fields...\n",
      "2025-06-04 16:07:45,238 INFO  [enrich.enrich_USFS    ]     step 4/8 Transfering Attributes...\n",
      "2025-06-04 16:07:45,240 INFO  [enrich.enrich_USFS    ]     step 5/8 Calculating End Date...\n",
      "2025-06-04 16:07:45,242 INFO  [enrich.enrich_USFS    ]     step 6/8 Calculating Status...\n",
      "2025-06-04 16:07:45,250 INFO  [enrich.enrich_USFS    ]     step 7/8 Activity Quantity...\n",
      "2025-06-04 16:07:45,251 INFO  [enrich.enrich_USFS    ]     step 8/8 Enter Field Values...\n",
      "2025-06-04 16:07:45,252 INFO  [enrich.enrich_USFS    ]  Remove Unnecessary Columns...\n",
      "2025-06-04 16:07:45,255 INFO  [enrich.enrich_USFS    ]  Select records between 1950 and 2025...\n",
      "2025-06-04 16:07:45,257 INFO  [enrich.enrich_USFS    ]  Enriching Dataset...\n",
      "2025-06-04 16:07:45,258 INFO  [utils.enrich_polygons ]        Executing Polygon Enrichments...\n",
      "2025-06-04 16:07:45,258 INFO  [utils.enrich_polygons ]           Calculating Broad Vegetation Type...\n",
      "2025-06-04 16:07:45,258 INFO  [utils.enrich_polygons ]              enrich step 1/32 summarize veg within polygons\n",
      "2025-06-04 16:07:50,613 INFO  [utils.enrich_polygons ]                 Loaded Broad_Vegetation_Types from cache\n",
      "2025-06-04 16:07:50,614 INFO  [utils.enrich_polygons ]                    time for loading Broad_Vegetation_Types: 5.355029821395874\n",
      "2025-06-04 16:07:50,618 INFO  [utils.enrich_polygons ]              create numerical intermediate columns before multiprocessing\n",
      "2025-06-04 16:07:50,621 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-06-04 16:07:50,799 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-06-04 16:07:50,800 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3656 \n",
      "2025-06-04 16:07:50,800 INFO  [utils.enrich_polygons ]                 records for summary: 681\n",
      "2025-06-04 16:07:50,801 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-06-04 16:07:50,801 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-06-04 16:07:53,941 INFO  [utils.enrich_polygons ]                 joined records: 3277\n",
      "2025-06-04 16:07:53,942 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-06-04 16:07:53,942 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-06-04 16:08:45,208 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-06-04 16:08:45,210 INFO  [utils.enrich_polygons ]                 time for summarizing veg types: 54.59548211097717\n",
      "2025-06-04 16:08:45,216 INFO  [utils.enrich_polygons ]              enrich step 7/32 select records where BROAD_VEGETATION_TYPE is not null\n",
      "2025-06-04 16:08:45,216 INFO  [utils.enrich_polygons ]              enrich step 8/32 set BVT_USERD of the selected records to YES\n",
      "2025-06-04 16:08:45,217 INFO  [utils.enrich_polygons ]              enrich step 9/32 select records where BROAD_VEGETATION_TYPE is null\n",
      "2025-06-04 16:08:45,218 INFO  [utils.enrich_polygons ]              enrich step 11/32 set BVT_USERD of the selected records to NO\n",
      "2025-06-04 16:08:45,220 INFO  [utils.enrich_polygons ]              enrich step 12/32 keeping only the necessary columns\n",
      "2025-06-04 16:08:47,984 INFO  [utils.enrich_polygons ]           Calculating WUI...\n",
      "2025-06-04 16:08:48,187 INFO  [utils.enrich_polygons ]              Loaded WUI from cache\n",
      "2025-06-04 16:08:48,188 INFO  [utils.enrich_polygons ]                 time for loading WUI: 0.20336318016052246\n",
      "2025-06-04 16:08:48,188 INFO  [utils.enrich_polygons ]              enrich step 13/32 select records with null WUI\n",
      "2025-06-04 16:08:48,192 INFO  [utils.enrich_polygons ]              enrich step 14/32 select by WUI location\n",
      "2025-06-04 16:08:48,230 INFO  [utils.enrich_polygons ]              enrich step 15/32 calculate WUI yes\n",
      "2025-06-04 16:08:48,230 INFO  [utils.enrich_polygons ]              enrich step 16/32 select remaining null records\n",
      "2025-06-04 16:08:48,234 INFO  [utils.enrich_polygons ]              enrich step 17/32 calculate WUI no\n",
      "2025-06-04 16:08:48,235 INFO  [utils.enrich_polygons ]              enrich step 18/32 feature to point\n",
      "2025-06-04 16:08:48,238 INFO  [utils.enrich_polygons ]              enrich step 19/32 setup ORIG_FID\n",
      "2025-06-04 16:08:48,239 INFO  [utils.enrich_polygons ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-06-04 16:08:48,746 INFO  [utils.enrich_polygons ]              Loaded CALFIRE_Ownership_Update from cache\n",
      "2025-06-04 16:08:48,746 INFO  [utils.enrich_polygons ]                 time for loading CALFIRE_Ownership_Update: 0.507314920425415\n",
      "2025-06-04 16:08:48,768 INFO  [utils.enrich_polygons ]              Loaded WFRTF_Regions from cache\n",
      "2025-06-04 16:08:48,768 INFO  [utils.enrich_polygons ]                 time for loading WFRTF_Regions: 0.02144765853881836\n",
      "2025-06-04 16:08:48,768 INFO  [utils.enrich_polygons ]              enrich step 20/32 spatial join ownership\n",
      "2025-06-04 16:08:49,170 INFO  [utils.enrich_polygons ]              enrich step 21/32 spatial join with regions layer\n",
      "2025-06-04 16:08:49,273 INFO  [utils.enrich_polygons ]              enrich step 22/32 add ownership and region\n",
      "2025-06-04 16:08:49,279 INFO  [utils.enrich_polygons ]              enrich step 23/32 calculate ownership field\n",
      "2025-06-04 16:08:49,279 INFO  [utils.enrich_polygons ]              enrich step 24/32 calculate county field\n",
      "2025-06-04 16:08:49,280 INFO  [utils.enrich_polygons ]              enrich step 25/32 calculate region field\n",
      "2025-06-04 16:08:49,280 INFO  [utils.enrich_polygons ]              enrich step 26/32 set TRMT_GEOM\n",
      "2025-06-04 16:08:49,280 INFO  [utils.enrich_polygons ]              enrich step 27/32 calculating years...\n",
      "2025-06-04 16:08:49,284 INFO  [utils.enrich_polygons ]              enrich step 28/32 Initiating Crosswalk...\n",
      "2025-06-04 16:08:49,284 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-06-04 16:08:49,284 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-06-04 16:08:49,326 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-06-04 16:08:49,330 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-06-04 16:08:49,331 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-06-04 16:08:49,332 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-06-04 16:08:49,332 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "2025-06-04 16:08:49,335 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-06-04 16:08:49,341 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-06-04 16:08:49,362 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 16:08:49,362 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-06-04 16:08:49,362 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-06-04 16:08:49,363 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-06-04 16:08:49,364 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-06-04 16:08:49,364 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-06-04 16:08:49,364 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-06-04 16:08:49,365 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-06-04 16:08:49,365 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-06-04 16:08:49,366 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Org is 'USFS' and Status is 'Active'\n",
      "2025-06-04 16:08:49,369 INFO  [utils.enrich_polygons ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-06-04 16:08:49,369 INFO  [utils.enrich_polygons ]              enrich step 29/32 Calculating Latitude and Longitude...\n",
      "2025-06-04 16:08:49,375 INFO  [utils.enrich_polygons ]              enrich step 30/32 calculate treatment acres\n",
      "2025-06-04 16:08:49,376 INFO  [utils.enrich_polygons ]              enrich step 31/32 removing unnecessary fields\n",
      "2025-06-04 16:08:49,378 INFO  [utils.enrich_polygons ]              enrich step 32/32 delete if County is Null\n",
      "2025-06-04 16:08:49,577 INFO  [enrich.enrich_USFS    ]  Assign Domains...\n",
      "2025-06-04 16:08:49,652 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-06-04 16:08:49,658 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-06-04 16:08:49,665 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-06-04 16:08:49,670 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-06-04 16:08:49,678 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-06-04 16:08:49,720 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-06-04 16:08:49,726 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-06-04 16:08:49,732 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-06-04 16:08:49,737 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-06-04 16:08:49,743 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-06-04 16:08:49,749 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-06-04 16:08:49,754 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-06-04 16:08:49,760 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-06-04 16:08:49,766 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-06-04 16:08:49,773 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-06-04 16:08:49,778 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-06-04 16:08:49,779 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-06-04 16:08:49,785 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-06-04 16:08:49,790 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-06-04 16:08:49,797 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-06-04 16:08:49,797 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-06-04 16:08:49,807 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-06-04 16:08:49,818 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-06-04 16:08:49,835 INFO  [enrich.enrich_USFS    ]  Save Result...\n",
      "2025-06-04 16:08:49,836 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-06-04 16:08:49,836 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-06-04 16:08:49,842 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n",
      "2025-06-04 16:08:49,946 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\USFS_1950_2025.gdb USFS_Region06_enriched_20250604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\USFS_1950_2025.gdb\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    region_ids = [\"04\", \"06\"]\n",
    "    for region_id in region_ids:    \n",
    "        usfs_input_gdb_path = r'D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\FACTS_V2.0\\Actv_CommonAttribute_PL_Region{}.gdb'.format(region_id)\n",
    "        usfs_input_layer_name = \"Actv_CommonAttribute_PL\"\n",
    "        output_layer_name = f\"USFS_Region{region_id}_enriched_{datetime.today().strftime('%Y%m%d')}\"\n",
    "        # init multiprocessing manager in main module for Windows fork\n",
    "\n",
    "        \n",
    "        enrich_USFS(usfs_input_gdb_path,\n",
    "                    usfs_input_layer_name,\n",
    "                    a_reference_gdb_path,\n",
    "                    start_year,\n",
    "                    end_year,\n",
    "                    output_gdb_path,\n",
    "                    output_layer_name,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cdea36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrich.enrich_Timber_Nonspatial import enrich_Timber_Nonspatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb45224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tn_input_excel_path = r'D:\\WORK\\wildfire\\Interagency-Tracking-System\\2023\\Industry_nonspatial_2023\\Timber_Industry_Acres_{}.xlsx'\n",
    "output_gdb_path =  r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\tmp\\Timber_Nonspatial_{}_{}.gdb\".format(start_year, end_year)\n",
    "output_layer_name = f\"Timber_Nonspatial_{datetime.today().strftime('%Y%m%d')}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2ce6895",
   "metadata": {},
   "source": [
    "# concat all timber nonspatial xlsx files\n",
    "tn21_df = pd.read_excel(tn_input_excel_path.format(2021))\n",
    "tn22_df = pd.read_excel(tn_input_excel_path.format(2022))\n",
    "tn23_df = pd.read_excel(tn_input_excel_path.format(2023))\n",
    "tn_df = pd.concat([tn21_df, tn22_df, tn23_df])\n",
    "tn_df.to_excel(tn_input_excel_path.format('concat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "510e50f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tn_input_excel_path = r'D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\Industry_nonspatial_V2.0\\Timber_Industry_Acres_concat.xlsx'\n",
    "output_gdb_path =  r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\Timber_Nonspatial_{}_{}.gdb\".format(start_year, end_year)\n",
    "output_layer_name = f\"Timber_Nonspatial_{datetime.today().strftime('%Y%m%d')}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33e7c393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 16:46:59,535 INFO  [enrich.Timber_NSpatial]  Load the Timeber Industry Nonspatial data into a DataFrame\n",
      "2025-08-14 16:46:59,720 INFO  [enrich.Timber_NSpatial]     time for loading D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\Industry_nonspatial_V2.0\\Timber_Industry_Acres_concat.xlsx: 0.18476390838623047\n",
      "2025-08-14 16:46:59,720 INFO  [enrich.Timber_NSpatial]  Performing Standardization\n",
      "2025-08-14 16:46:59,720 INFO  [enrich.Timber_NSpatial]     step 1/10 convert Excel sheet to table\n",
      "2025-08-14 16:46:59,738 INFO  [enrich.Timber_NSpatial]     all required columns are present.\n",
      "2025-08-14 16:46:59,739 INFO  [enrich.Timber_NSpatial]     step 2/10 rename and add fields\n",
      "2025-08-14 16:46:59,739 INFO  [enrich.Timber_NSpatial]     step 3/10 adding common columns...\n",
      "2025-08-14 16:46:59,760 INFO  [enrich.Timber_NSpatial]     step 4/10 calculate fields\n",
      "2025-08-14 16:46:59,763 INFO  [enrich.Timber_NSpatial]     step 5/10 converting Table to Geodataframe\n",
      "2025-08-14 16:46:59,797 INFO  [enrich.Timber_NSpatial]     step 6/10 Remove Unnecessary Columns...\n",
      "2025-08-14 16:46:59,799 INFO  [enrich.Timber_NSpatial]     step 7/10 Enrich Points\n",
      "2025-08-14 16:46:59,799 INFO  [utils.enrich_points   ]        Executing Point Enrichments...\n",
      "2025-08-14 16:46:59,800 INFO  [utils.enrich_points   ]           Calculating WUI...\n",
      "2025-08-14 16:46:59,800 INFO  [utils.enrich_points   ]              enrich step 1/16 loading WUI from cache\n",
      "2025-08-14 16:46:59,980 INFO  [utils.enrich_points   ]                 time for loading WUI: 0.1799030303955078\n",
      "2025-08-14 16:46:59,981 INFO  [utils.enrich_points   ]              enrich step 2/16 select records with null WUI\n",
      "2025-08-14 16:46:59,983 INFO  [utils.enrich_points   ]              enrich step 3/16 select by WUI location\n",
      "2025-08-14 16:47:00,015 INFO  [utils.enrich_points   ]              enrich step 4/16 calculate WUI yes\n",
      "2025-08-14 16:47:00,016 INFO  [utils.enrich_points   ]              enrich step 5/16 select remaining null records\n",
      "2025-08-14 16:47:00,017 INFO  [utils.enrich_points   ]              enrich step 6/16 calculate WUI no\n",
      "2025-08-14 16:47:00,018 INFO  [utils.enrich_points   ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-08-14 16:47:00,018 INFO  [utils.enrich_points   ]              enrich step 7/16 loading CALFIRE_Ownership_Update from cache\n",
      "2025-08-14 16:47:00,457 INFO  [utils.enrich_points   ]                 time for loading CALFIRE_Ownership_Update: 0.4391801357269287\n",
      "2025-08-14 16:47:00,458 INFO  [utils.enrich_points   ]              enrich step 8/16 spatial join ownership\n",
      "2025-08-14 16:47:00,860 INFO  [utils.enrich_points   ]              enrich step 9/16 loading WFRTF_Regions from cache\n",
      "2025-08-14 16:47:00,887 INFO  [utils.enrich_points   ]                 time for loading WFRTF_Regions: 0.02682042121887207\n",
      "2025-08-14 16:47:00,888 INFO  [utils.enrich_points   ]              enrich step 10/16 spatial join regions\n",
      "2025-08-14 16:47:01,016 INFO  [utils.enrich_points   ]              enrich step 11/16 loading Broad_Vegetation_Types from cache\n",
      "2025-08-14 16:47:05,149 INFO  [utils.enrich_points   ]                 time for loading Broad_Vegetation_Types: 4.2887842655181885\n",
      "2025-08-14 16:47:05,150 INFO  [utils.enrich_points   ]              enrich step 12/16 spatial join veg and calculations\n",
      "2025-08-14 16:47:06,405 INFO  [utils.enrich_points   ]              enrich step 13/16 Initiating Crosswalk\n",
      "2025-08-14 16:47:06,405 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-08-14 16:47:06,406 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-08-14 16:47:06,444 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-08-14 16:47:06,448 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-08-14 16:47:06,449 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-08-14 16:47:06,449 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-08-14 16:47:06,450 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "2025-08-14 16:47:06,463 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-08-14 16:47:06,466 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-08-14 16:47:06,472 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-08-14 16:47:06,472 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-08-14 16:47:06,472 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-08-14 16:47:06,473 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-08-14 16:47:06,474 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-08-14 16:47:06,475 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-08-14 16:47:06,476 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-08-14 16:47:06,476 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-08-14 16:47:06,477 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-08-14 16:47:06,477 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Status is 'Active' unless Agency is 'CNRA' \n",
      "2025-08-14 16:47:06,479 INFO  [utils.enrich_points   ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-08-14 16:47:06,480 INFO  [utils.enrich_points   ]              enrich step 14/16 calculating Years\n",
      "2025-08-14 16:47:06,482 INFO  [utils.enrich_points   ]              enrich step 15/16 calculating Latitude and Longitude\n",
      "2025-08-14 16:47:06,483 INFO  [utils.enrich_points   ]              enrich step 16/16 removing unnecessary fields\n",
      "2025-08-14 16:47:06,485 INFO  [utils.enrich_points   ]           Enrich Points Complete...\n",
      "2025-08-14 16:47:06,678 INFO  [enrich.Timber_NSpatial]     step 8/10 Fix board veg types and others\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "Alternative Prescription\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "Alternative Prescription\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "Alternative Prescription\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "Alternative Prescription\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "Landing Treated\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "Landing Treated\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "Landing Treated\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "Landing Treated\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "Removal of Hazard Trees and Snags - Area\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "Roadway Clearance\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "Roadway Clearance\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "Roadway Clearance\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "Roadway Clearance\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 16:47:06,681 INFO  [enrich.Timber_NSpatial]     step 9/10 Assign Domains...\n",
      "2025-08-14 16:47:06,762 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-08-14 16:47:06,767 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-08-14 16:47:06,774 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-08-14 16:47:06,780 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-08-14 16:47:06,787 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-08-14 16:47:06,793 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-08-14 16:47:06,799 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-08-14 16:47:06,805 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-08-14 16:47:06,811 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-08-14 16:47:06,816 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-08-14 16:47:06,822 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-08-14 16:47:06,829 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-08-14 16:47:06,835 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-08-14 16:47:06,842 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-08-14 16:47:06,848 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-08-14 16:47:06,854 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-08-14 16:47:06,854 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-08-14 16:47:06,860 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-08-14 16:47:06,866 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-08-14 16:47:06,871 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-08-14 16:47:06,872 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-08-14 16:47:06,876 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-08-14 16:47:06,881 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-08-14 16:47:06,889 INFO  [enrich.Timber_NSpatial]     step 10/10 Save Result...\n",
      "2025-08-14 16:47:06,889 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-08-14 16:47:06,890 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-08-14 16:47:06,890 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n",
      "2025-08-14 16:47:06,968 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\Timber_Nonspatial_1950_2025.gdb Timber_Nonspatial_20250814\n",
      "2025-08-14 16:47:06,969 INFO  [its_logging.logger_config]  Memory usage: 4059.27 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\Timber_Nonspatial_1950_2025.gdb\n"
     ]
    }
   ],
   "source": [
    "enrich_Timber_Nonspatial(tn_input_excel_path.format('concat'),\n",
    "                         a_reference_gdb_path,\n",
    "                         start_year,\n",
    "                         end_year,\n",
    "                         output_gdb_path,\n",
    "                         output_layer_name)\n",
    "\n",
    "# Get memory usage in bytes, convert to MB\n",
    "memory_usage = process.memory_info().rss / 1024 / 1024\n",
    "logger.info(f\"Memory usage: {memory_usage:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0e711e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrich.enrich_NPS import enrich_NPS_from_gdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0aa83f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nps_gdb_path = r'D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\NPS_V2.0\\NPS_V2.0\\NPS_V2_0_20250331.shp'\n",
    "nps_layer_name = None\n",
    "output_gdb_path =  r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\NPS_{}_{}.gdb\".format(start_year, end_year)\n",
    "output_layer_name = f\"NPS_enriched_{datetime.today().strftime('%Y%m%d')}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d86e3a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 16:53:06,560 INFO  [enrich.enrich_NPS     ]  Load the NPS data into a GeoDataFrame\n",
      "2025-08-14 16:53:06,968 INFO  [enrich.enrich_NPS     ]     time for loading None: 0.4070427417755127\n",
      "2025-08-14 16:53:06,968 INFO  [enrich.enrich_NPS     ]     all required columns are present.\n",
      "2025-08-14 16:53:07,374 INFO  [enrich.enrich_NPS     ]  Performing Standardization...\n",
      "2025-08-14 16:53:07,374 INFO  [enrich.enrich_NPS     ]     step 1/11 select after 1995\n",
      "2025-08-14 16:53:07,387 INFO  [enrich.enrich_NPS     ]     step 2/11 repairing geometry\n",
      "2025-08-14 16:53:10,270 INFO  [enrich.enrich_NPS     ]     step 3/11 clip features by CA\n",
      "2025-08-14 16:53:20,144 INFO  [enrich.enrich_NPS     ]     step 4/11 dissolve to implement multipart polygons\n",
      "2025-08-14 16:53:20,661 INFO  [enrich.enrich_NPS     ]     step 5/11 rename and add fields\n",
      "2025-08-14 16:53:20,685 INFO  [enrich.enrich_NPS     ]     step 6/11 import attributes\n",
      "2025-08-14 16:53:20,705 INFO  [enrich.enrich_NPS     ]     step 7/11 Remove Unnecessary Columns...\n",
      "2025-08-14 16:53:20,708 INFO  [enrich.enrich_NPS     ]     step 8/11 Enriching Polygons...\n",
      "2025-08-14 16:53:20,708 INFO  [utils.enrich_polygons ]        Executing Polygon Enrichments...\n",
      "2025-08-14 16:53:20,708 INFO  [utils.enrich_polygons ]           Calculating Broad Vegetation Type...\n",
      "2025-08-14 16:53:20,708 INFO  [utils.enrich_polygons ]              enrich step 1/32 summarize veg within polygons\n",
      "2025-08-14 16:53:25,446 INFO  [utils.enrich_polygons ]                 Loaded Broad_Vegetation_Types from cache\n",
      "2025-08-14 16:53:25,447 INFO  [utils.enrich_polygons ]                    time for loading Broad_Vegetation_Types: 4.737661361694336\n",
      "2025-08-14 16:53:25,451 INFO  [utils.enrich_polygons ]              create numerical intermediate columns before multiprocessing\n",
      "2025-08-14 16:53:25,454 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-08-14 16:53:26,040 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-08-14 16:53:26,040 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3499647 \n",
      "2025-08-14 16:53:26,040 INFO  [utils.enrich_polygons ]                 records for summary: 831\n",
      "2025-08-14 16:53:26,041 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-08-14 16:53:26,041 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-08-14 16:53:49,087 INFO  [utils.enrich_polygons ]                 joined records: 20391\n",
      "2025-08-14 16:53:49,088 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-08-14 16:53:49,088 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-08-14 16:54:51,952 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-08-14 16:54:51,953 INFO  [utils.enrich_polygons ]                 time for summarizing veg types: 86.50605940818787\n",
      "2025-08-14 16:54:51,959 INFO  [utils.enrich_polygons ]              enrich step 7/32 select records where BROAD_VEGETATION_TYPE is not null\n",
      "2025-08-14 16:54:51,959 INFO  [utils.enrich_polygons ]              enrich step 8/32 set BVT_USERD of the selected records to YES\n",
      "2025-08-14 16:54:51,960 INFO  [utils.enrich_polygons ]              enrich step 9/32 select records where BROAD_VEGETATION_TYPE is null\n",
      "2025-08-14 16:54:51,960 INFO  [utils.enrich_polygons ]              enrich step 11/32 set BVT_USERD of the selected records to NO\n",
      "2025-08-14 16:54:51,962 INFO  [utils.enrich_polygons ]              enrich step 12/32 keeping only the necessary columns\n",
      "2025-08-14 16:54:52,095 INFO  [utils.enrich_polygons ]           Calculating WUI...\n",
      "2025-08-14 16:54:52,250 INFO  [utils.enrich_polygons ]              Loaded WUI from cache\n",
      "2025-08-14 16:54:52,250 INFO  [utils.enrich_polygons ]                 time for loading WUI: 0.15490412712097168\n",
      "2025-08-14 16:54:52,251 INFO  [utils.enrich_polygons ]              enrich step 13/32 select records with null WUI\n",
      "2025-08-14 16:54:52,255 INFO  [utils.enrich_polygons ]              enrich step 14/32 select by WUI location\n",
      "2025-08-14 16:54:54,094 INFO  [utils.enrich_polygons ]              enrich step 15/32 calculate WUI yes\n",
      "2025-08-14 16:54:54,095 INFO  [utils.enrich_polygons ]              enrich step 16/32 select remaining null records\n",
      "2025-08-14 16:54:54,099 INFO  [utils.enrich_polygons ]              enrich step 17/32 calculate WUI no\n",
      "2025-08-14 16:54:54,100 INFO  [utils.enrich_polygons ]              enrich step 18/32 feature to point\n",
      "2025-08-14 16:54:54,106 INFO  [utils.enrich_polygons ]              enrich step 19/32 setup ORIG_FID\n",
      "2025-08-14 16:54:54,106 INFO  [utils.enrich_polygons ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-08-14 16:54:54,499 INFO  [utils.enrich_polygons ]              Loaded CALFIRE_Ownership_Update from cache\n",
      "2025-08-14 16:54:54,500 INFO  [utils.enrich_polygons ]                 time for loading CALFIRE_Ownership_Update: 0.39324951171875\n",
      "2025-08-14 16:54:54,520 INFO  [utils.enrich_polygons ]              Loaded WFRTF_Regions from cache\n",
      "2025-08-14 16:54:54,521 INFO  [utils.enrich_polygons ]                 time for loading WFRTF_Regions: 0.020560264587402344\n",
      "2025-08-14 16:54:54,521 INFO  [utils.enrich_polygons ]              enrich step 20/32 spatial join ownership\n",
      "2025-08-14 16:54:55,085 INFO  [utils.enrich_polygons ]              enrich step 21/32 spatial join with regions layer\n",
      "2025-08-14 16:54:55,504 INFO  [utils.enrich_polygons ]              enrich step 22/32 add ownership and region\n",
      "2025-08-14 16:54:55,509 INFO  [utils.enrich_polygons ]              enrich step 23/32 calculate ownership field\n",
      "2025-08-14 16:54:55,510 INFO  [utils.enrich_polygons ]              enrich step 24/32 calculate county field\n",
      "2025-08-14 16:54:55,510 INFO  [utils.enrich_polygons ]              enrich step 25/32 calculate region field\n",
      "2025-08-14 16:54:55,510 INFO  [utils.enrich_polygons ]              enrich step 26/32 set TRMT_GEOM\n",
      "2025-08-14 16:54:55,511 INFO  [utils.enrich_polygons ]              enrich step 27/32 calculating years...\n",
      "2025-08-14 16:54:55,514 INFO  [utils.enrich_polygons ]              enrich step 28/32 Initiating Crosswalk...\n",
      "2025-08-14 16:54:55,515 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-08-14 16:54:55,515 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-08-14 16:54:55,545 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-08-14 16:54:55,549 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-08-14 16:54:55,550 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-08-14 16:54:55,551 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-08-14 16:54:55,551 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "2025-08-14 16:54:55,555 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-08-14 16:54:55,564 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-08-14 16:54:55,587 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-08-14 16:54:55,587 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 16:54:55,587 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-08-14 16:54:55,587 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-08-14 16:54:55,588 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-08-14 16:54:55,589 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-08-14 16:54:55,589 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-08-14 16:54:55,590 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-08-14 16:54:55,590 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-08-14 16:54:55,591 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Status is 'Active' unless Agency is 'CNRA' \n",
      "2025-08-14 16:54:55,594 INFO  [utils.enrich_polygons ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-08-14 16:54:55,594 INFO  [utils.enrich_polygons ]              enrich step 29/32 Calculating Latitude and Longitude...\n",
      "2025-08-14 16:54:55,602 INFO  [utils.enrich_polygons ]              enrich step 30/32 calculate treatment acres\n",
      "2025-08-14 16:54:55,604 INFO  [utils.enrich_polygons ]              enrich step 31/32 removing unnecessary fields\n",
      "2025-08-14 16:54:55,606 INFO  [utils.enrich_polygons ]              enrich step 32/32 delete if County is Null\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "NOT_DEFINED\n",
      "NOT_DEFINED\n",
      "NOT_DEFINED\n",
      "NOT_DEFINED\n",
      "NOT_DEFINED\n",
      "NOT_DEFINED\n",
      "NOT_DEFINED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 16:54:55,789 INFO  [enrich.enrich_NPS     ]     step 9/11 adding treatment ID\n",
      "2025-08-14 16:54:55,799 INFO  [enrich.enrich_NPS     ]     step 10/11 Assign Domains...\n",
      "2025-08-14 16:54:55,867 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-08-14 16:54:55,874 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-08-14 16:54:55,880 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-08-14 16:54:55,886 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-08-14 16:54:55,893 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-08-14 16:54:55,898 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-08-14 16:54:55,904 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-08-14 16:54:55,910 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-08-14 16:54:55,915 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-08-14 16:54:55,921 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-08-14 16:54:55,926 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-08-14 16:54:55,931 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-08-14 16:54:55,937 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-08-14 16:54:55,943 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-08-14 16:54:55,949 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-08-14 16:54:55,954 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-08-14 16:54:55,955 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-08-14 16:54:55,960 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-08-14 16:54:55,966 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-08-14 16:54:55,971 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-08-14 16:54:55,971 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-08-14 16:54:55,976 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-08-14 16:54:55,984 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-08-14 16:54:55,995 INFO  [enrich.enrich_NPS     ]     step 11/11 Save Result...\n",
      "2025-08-14 16:54:55,995 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-08-14 16:54:55,995 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-08-14 16:54:56,001 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n",
      "2025-08-14 16:54:56,142 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\NPS_1950_2025.gdb NPS_enriched_20250814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\NPS_1950_2025.gdb\n"
     ]
    }
   ],
   "source": [
    "enrich_NPS_from_gdb(nps_gdb_path,\n",
    "                    nps_layer_name,\n",
    "                    a_reference_gdb_path,\n",
    "                    start_year,\n",
    "                    end_year,\n",
    "                    output_gdb_path,\n",
    "                    output_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "230b4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nps_gdf = gpd.read_file(output_gdb_path, driver='OpenFileGDB', layer=output_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49b25c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTIVITY_DESCRIPTION</th>\n",
       "      <th>PRIMARY_OBJECTIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NOT_DEFINED</td>\n",
       "      <td>OTHER_FUELS_REDUCTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NOT_DEFINED</td>\n",
       "      <td>OTHER_FUELS_REDUCTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>NOT_DEFINED</td>\n",
       "      <td>OTHER_FUELS_REDUCTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>NOT_DEFINED</td>\n",
       "      <td>NOT_DEFINED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>NOT_DEFINED</td>\n",
       "      <td>NOT_DEFINED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>NOT_DEFINED</td>\n",
       "      <td>NOT_DEFINED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>NOT_DEFINED</td>\n",
       "      <td>NOT_DEFINED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ACTIVITY_DESCRIPTION      PRIMARY_OBJECTIVE\n",
       "6            NOT_DEFINED  OTHER_FUELS_REDUCTION\n",
       "13           NOT_DEFINED  OTHER_FUELS_REDUCTION\n",
       "298          NOT_DEFINED  OTHER_FUELS_REDUCTION\n",
       "721          NOT_DEFINED            NOT_DEFINED\n",
       "762          NOT_DEFINED            NOT_DEFINED\n",
       "763          NOT_DEFINED            NOT_DEFINED\n",
       "764          NOT_DEFINED            NOT_DEFINED"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nps_gdf[nps_gdf.ACTIVITY_CAT == 'NOT_DEFINED'][['ACTIVITY_DESCRIPTION', 'PRIMARY_OBJECTIVE']]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "27b674a3",
   "metadata": {},
   "source": [
    "NPS_gpd = enrich_NPS_from_gdb(nps_gdb_path,\n",
    "                    nps_layer_name,\n",
    "                    a_reference_gdb_path,\n",
    "                    start_year,\n",
    "                    end_year,\n",
    "                    output_gdb_path,\n",
    "                    output_layer_name)\n",
    "\n",
    "# Get memory usage in bytes, convert to MB\n",
    "memory_usage = process.memory_info().rss / 1024 / 1024\n",
    "logger.info(f\"Memory usage: {memory_usage:.2f} MB\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bbe37fd4",
   "metadata": {},
   "source": [
    "NPS_reference = gpd.read_file(r'D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\Interagency Tracking System.gdb', driver='openFileGDB', layer='nps_flat_fuels_enriched2023_20240925')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38b9d376",
   "metadata": {},
   "source": [
    "NPS_reference[['ACTIVITY_QUANTITY', 'ADMINISTERING_ORG', 'COUNTS_TO_MAS', 'PRIMARY_OBJECTIVE', \"Year_txt\"]].groupby(['ADMINISTERING_ORG', 'COUNTS_TO_MAS', 'PRIMARY_OBJECTIVE', \"Year_txt\"]).sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "554ccf80",
   "metadata": {},
   "source": [
    "NPS_output = gpd.read_file(output_gdb_path, driver='openFileGDB', layer=output_layer_name)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea0e15cd",
   "metadata": {},
   "source": [
    "NPS_output[['ACTIVITY_QUANTITY', 'ADMINISTERING_ORG', 'COUNTS_TO_MAS', 'PRIMARY_OBJECTIVE', \"Year_txt\"]].groupby(['ADMINISTERING_ORG', 'COUNTS_TO_MAS', 'PRIMARY_OBJECTIVE', \"Year_txt\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d79da30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrich.enrich_BLM import enrich_BLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86909eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "blm_input_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\BLM_V2.0\\BLM_V2.0\\BLM_V2_0_20250331.shp\"\n",
    "blm_input_layer_name = None\n",
    "output_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\BLM_{}_{}.gdb\".format(start_year, end_year)\n",
    "output_layer_name = f\"BLM_enriched_20250710\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f169405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:01:57,279 INFO  [enrich.enrich_BLM     ]  Load the BLM data into a GeoDataFrame\n",
      "2025-08-14 17:01:57,365 INFO  [enrich.enrich_BLM     ]     time for loading None: 0.08496308326721191\n",
      "2025-08-14 17:01:57,366 INFO  [enrich.enrich_BLM     ]     all required columns are present.\n",
      "2025-08-14 17:01:57,366 INFO  [enrich.enrich_BLM     ]  Performing Standardization...\n",
      "2025-08-14 17:01:57,366 INFO  [enrich.enrich_BLM     ]     step 1/15 Clip Features to California...\n",
      "2025-08-14 17:02:11,757 INFO  [enrich.enrich_BLM     ]     step 2/15 Repairing Geometry...\n",
      "2025-08-14 17:02:12,211 INFO  [enrich.enrich_BLM     ]     step 3/15 Adding Common Columns...\n",
      "2025-08-14 17:02:12,235 INFO  [enrich.enrich_BLM     ]     step 4/15 Transfering Values...\n",
      "2025-08-14 17:02:12,236 INFO  [enrich.enrich_BLM     ]     step 5/15 Calculating Start and End Date...\n",
      "2025-08-14 17:02:12,249 INFO  [enrich.enrich_BLM     ]     step 6/15 Calculating Status...\n",
      "2025-08-14 17:02:12,249 INFO  [enrich.enrich_BLM     ]     step 7/15 Activity Quantity...\n",
      "2025-08-14 17:02:12,259 INFO  [enrich.enrich_BLM     ]     step 8/15 Enter Column Values...\n",
      "2025-08-14 17:02:12,260 INFO  [enrich.enrich_BLM     ]     step 9/15 Adding Original Activity Description to Crosswalk Column...\n",
      "2025-08-14 17:02:12,296 INFO  [enrich.enrich_BLM     ]     step 10/15 Select by Years...\n",
      "2025-08-14 17:02:12,300 INFO  [enrich.enrich_BLM     ]     step 10/15 Create New GeoDataframe Using the Template...\n",
      "2025-08-14 17:02:12,329 INFO  [enrich.enrich_BLM     ]     step 10/15 Append to Template...\n",
      "2025-08-14 17:02:12,338 INFO  [enrich.enrich_BLM     ]     step 10/15 Calculate Treatment Geometry...\n",
      "2025-08-14 17:02:12,339 INFO  [enrich.enrich_BLM     ]     step 11/15 Remove Unnecessary Columns...\n",
      "2025-08-14 17:02:12,341 INFO  [enrich.enrich_BLM     ]     step 12/15 Enriching Polygons...\n",
      "2025-08-14 17:02:12,341 INFO  [utils.enrich_polygons ]        Executing Polygon Enrichments...\n",
      "2025-08-14 17:02:12,342 INFO  [utils.enrich_polygons ]           Calculating Broad Vegetation Type...\n",
      "2025-08-14 17:02:12,342 INFO  [utils.enrich_polygons ]              enrich step 1/32 summarize veg within polygons\n",
      "2025-08-14 17:02:16,578 INFO  [utils.enrich_polygons ]                 Loaded Broad_Vegetation_Types from cache\n",
      "2025-08-14 17:02:16,579 INFO  [utils.enrich_polygons ]                    time for loading Broad_Vegetation_Types: 4.236515283584595\n",
      "2025-08-14 17:02:16,585 INFO  [utils.enrich_polygons ]              create numerical intermediate columns before multiprocessing\n",
      "2025-08-14 17:02:16,588 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-08-14 17:02:17,325 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-08-14 17:02:17,325 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3677656 \n",
      "2025-08-14 17:02:17,325 INFO  [utils.enrich_polygons ]                 records for summary: 1220\n",
      "2025-08-14 17:02:17,326 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-08-14 17:02:17,326 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-08-14 17:03:05,320 INFO  [utils.enrich_polygons ]                 joined records: 30068\n",
      "2025-08-14 17:03:05,321 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-08-14 17:03:05,321 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-08-14 17:04:55,555 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-08-14 17:04:55,557 INFO  [utils.enrich_polygons ]                 time for summarizing veg types: 158.97728514671326\n",
      "2025-08-14 17:04:55,590 INFO  [utils.enrich_polygons ]              enrich step 7/32 select records where BROAD_VEGETATION_TYPE is not null\n",
      "2025-08-14 17:04:55,590 INFO  [utils.enrich_polygons ]              enrich step 8/32 set BVT_USERD of the selected records to YES\n",
      "2025-08-14 17:04:55,591 INFO  [utils.enrich_polygons ]              enrich step 9/32 select records where BROAD_VEGETATION_TYPE is null\n",
      "2025-08-14 17:04:55,592 INFO  [utils.enrich_polygons ]              enrich step 11/32 set BVT_USERD of the selected records to NO\n",
      "2025-08-14 17:04:55,593 INFO  [utils.enrich_polygons ]              enrich step 12/32 keeping only the necessary columns\n",
      "2025-08-14 17:04:55,653 INFO  [utils.enrich_polygons ]           Calculating WUI...\n",
      "2025-08-14 17:04:55,809 INFO  [utils.enrich_polygons ]              Loaded WUI from cache\n",
      "2025-08-14 17:04:55,809 INFO  [utils.enrich_polygons ]                 time for loading WUI: 0.1560077667236328\n",
      "2025-08-14 17:04:55,810 INFO  [utils.enrich_polygons ]              enrich step 13/32 select records with null WUI\n",
      "2025-08-14 17:04:55,814 INFO  [utils.enrich_polygons ]              enrich step 14/32 select by WUI location\n",
      "2025-08-14 17:05:00,157 INFO  [utils.enrich_polygons ]              enrich step 15/32 calculate WUI yes\n",
      "2025-08-14 17:05:00,158 INFO  [utils.enrich_polygons ]              enrich step 16/32 select remaining null records\n",
      "2025-08-14 17:05:00,161 INFO  [utils.enrich_polygons ]              enrich step 17/32 calculate WUI no\n",
      "2025-08-14 17:05:00,162 INFO  [utils.enrich_polygons ]              enrich step 18/32 feature to point\n",
      "2025-08-14 17:05:00,169 INFO  [utils.enrich_polygons ]              enrich step 19/32 setup ORIG_FID\n",
      "2025-08-14 17:05:00,169 INFO  [utils.enrich_polygons ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-08-14 17:05:00,560 INFO  [utils.enrich_polygons ]              Loaded CALFIRE_Ownership_Update from cache\n",
      "2025-08-14 17:05:00,561 INFO  [utils.enrich_polygons ]                 time for loading CALFIRE_Ownership_Update: 0.39107680320739746\n",
      "2025-08-14 17:05:00,583 INFO  [utils.enrich_polygons ]              Loaded WFRTF_Regions from cache\n",
      "2025-08-14 17:05:00,583 INFO  [utils.enrich_polygons ]                 time for loading WFRTF_Regions: 0.02205348014831543\n",
      "2025-08-14 17:05:00,583 INFO  [utils.enrich_polygons ]              enrich step 20/32 spatial join ownership\n",
      "2025-08-14 17:05:01,275 INFO  [utils.enrich_polygons ]              enrich step 21/32 spatial join with regions layer\n",
      "2025-08-14 17:05:01,634 INFO  [utils.enrich_polygons ]              enrich step 22/32 add ownership and region\n",
      "2025-08-14 17:05:01,637 INFO  [utils.enrich_polygons ]              enrich step 23/32 calculate ownership field\n",
      "2025-08-14 17:05:01,638 INFO  [utils.enrich_polygons ]              enrich step 24/32 calculate county field\n",
      "2025-08-14 17:05:01,638 INFO  [utils.enrich_polygons ]              enrich step 25/32 calculate region field\n",
      "2025-08-14 17:05:01,639 INFO  [utils.enrich_polygons ]              enrich step 26/32 set TRMT_GEOM\n",
      "2025-08-14 17:05:01,639 INFO  [utils.enrich_polygons ]              enrich step 27/32 calculating years...\n",
      "2025-08-14 17:05:01,644 INFO  [utils.enrich_polygons ]              enrich step 28/32 Initiating Crosswalk...\n",
      "2025-08-14 17:05:01,644 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-08-14 17:05:01,644 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-08-14 17:05:01,675 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-08-14 17:05:01,678 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-08-14 17:05:01,679 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-08-14 17:05:01,679 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-08-14 17:05:01,680 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "2025-08-14 17:05:01,684 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:05:01,706 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-08-14 17:05:01,739 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-08-14 17:05:01,739 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-08-14 17:05:01,739 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-08-14 17:05:01,740 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-08-14 17:05:01,741 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-08-14 17:05:01,742 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-08-14 17:05:01,742 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-08-14 17:05:01,742 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-08-14 17:05:01,743 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-08-14 17:05:01,744 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Status is 'Active' unless Agency is 'CNRA' \n",
      "2025-08-14 17:05:01,747 INFO  [utils.enrich_polygons ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-08-14 17:05:01,747 INFO  [utils.enrich_polygons ]              enrich step 29/32 Calculating Latitude and Longitude...\n",
      "2025-08-14 17:05:01,759 INFO  [utils.enrich_polygons ]              enrich step 30/32 calculate treatment acres\n",
      "2025-08-14 17:05:01,762 INFO  [utils.enrich_polygons ]              enrich step 31/32 removing unnecessary fields\n",
      "2025-08-14 17:05:01,764 INFO  [utils.enrich_polygons ]              enrich step 32/32 delete if County is Null\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBD\n",
      "TBD\n",
      "NOT_DEFINED\n",
      "NOT_DEFINED\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:05:01,944 INFO  [enrich.enrich_BLM     ]     step 13/15 Calculate Treatment ID...\n",
      "2025-08-14 17:05:01,947 INFO  [enrich.enrich_BLM     ]     step 14/15 Assign Domains...\n",
      "2025-08-14 17:05:02,016 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-08-14 17:05:02,022 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-08-14 17:05:02,029 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-08-14 17:05:02,035 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-08-14 17:05:02,042 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-08-14 17:05:02,048 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-08-14 17:05:02,054 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-08-14 17:05:02,059 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-08-14 17:05:02,065 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-08-14 17:05:02,071 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-08-14 17:05:02,077 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-08-14 17:05:02,083 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-08-14 17:05:02,089 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-08-14 17:05:02,095 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-08-14 17:05:02,101 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-08-14 17:05:02,107 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-08-14 17:05:02,107 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-08-14 17:05:02,113 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-08-14 17:05:02,119 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-08-14 17:05:02,125 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-08-14 17:05:02,125 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-08-14 17:05:02,131 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-08-14 17:05:02,137 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-08-14 17:05:02,149 INFO  [enrich.enrich_BLM     ]     step 15/15 Save Result...\n",
      "2025-08-14 17:05:02,149 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-08-14 17:05:02,149 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-08-14 17:05:02,158 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\BLM_1950_2025.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:05:02,369 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\BLM_1950_2025.gdb BLM_enriched_20250710\n",
      "2025-08-14 17:05:02,377 INFO  [its_logging.logger_config]  Memory usage: 8206.05 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "enrich_BLM(blm_input_gdb_path,\n",
    "               blm_input_layer_name,\n",
    "               a_reference_gdb_path,\n",
    "               start_year,\n",
    "               end_year,\n",
    "               output_gdb_path,\n",
    "               output_layer_name)\n",
    "\n",
    "# Get memory usage in bytes, convert to MB\n",
    "memory_usage = process.memory_info().rss / 1024 / 1024\n",
    "logger.info(f\"Memory usage: {memory_usage:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3002c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrich.enrich_CNRA import enrich_CNRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3aa5794b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>geometry_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TREATMENT_POINT</td>\n",
       "      <td>Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TREATMENT_LINE</td>\n",
       "      <td>MultiLineString</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TREATMENT_POLY</td>\n",
       "      <td>MultiPolygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PROJECT_POLY</td>\n",
       "      <td>MultiPolygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACTIVITIES</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name    geometry_type\n",
       "0  TREATMENT_POINT            Point\n",
       "1   TREATMENT_LINE  MultiLineString\n",
       "2   TREATMENT_POLY     MultiPolygon\n",
       "3     PROJECT_POLY     MultiPolygon\n",
       "4       ACTIVITIES             None"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpd.list_layers(r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\CNRA_V2.0\\CNRA_TRMT_DATA_Pv6c_20250620.gdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0146dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnra_input_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\CNRA_V2.0\\CNRA_TRMT_DATA_Pv6c_20250620.gdb\"\n",
    "cnra_polygon_layer_name = \"TREATMENT_POLY\"\n",
    "cnra_line_layer_name = \"TREATMENT_LINE\"\n",
    "cnra_point_layer_name = \"TREATMENT_POINT\"\n",
    "cnra_project_polygon_layer_name = \"PROJECT_POLY\"\n",
    "cnra_activity_layer_name = \"ACTIVITIES\"\n",
    "output_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\CNRA_{}_{}.gdb\".format(start_year, end_year)\n",
    "output_layer_name = f\"CNRA_enriched_{datetime.today().strftime('%Y%m%d')}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "710825bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:05:02,407 INFO  [enrich.enrich_CNRA    ]  Load the CNRA polygon layer into a GeoDataFrame\n",
      "2025-08-14 17:05:02,975 INFO  [enrich.enrich_CNRA    ]     all required columns are present.\n",
      "2025-08-14 17:05:03,847 INFO  [enrich.enrich_CNRA    ]  Load the CNRA line layer into a GeoDataFrame\n",
      "2025-08-14 17:05:03,860 INFO  [enrich.enrich_CNRA    ]     all required columns are present.\n",
      "2025-08-14 17:05:03,865 INFO  [enrich.enrich_CNRA    ]  Load the CNRA point layer into a GeoDataFrame\n",
      "2025-08-14 17:05:03,882 INFO  [enrich.enrich_CNRA    ]     all required columns are present.\n",
      "2025-08-14 17:05:03,883 INFO  [enrich.enrich_CNRA    ]  Load the CNRA project polygon layer into a GeoDataFrame\n",
      "2025-08-14 17:05:04,135 INFO  [enrich.enrich_CNRA    ]     all required columns are present.\n",
      "2025-08-14 17:05:04,683 INFO  [enrich.enrich_CNRA    ]  Load the CNRA activity layer into a DataFrame\n",
      "2025-08-14 17:05:05,584 INFO  [enrich.enrich_CNRA    ]     all required columns are present.\n",
      "2025-08-14 17:05:05,624 INFO  [enrich.enrich_CNRA    ]  Enrich the CNRA polygons...\n",
      "2025-08-14 17:05:05,624 INFO  [enrich.enrich_CNRA    ]     Part 1 Prepare Features\n",
      "2025-08-14 17:05:05,631 INFO  [enrich.enrich_CNRA    ]     Part 2 Prepare Activity Table\n",
      "2025-08-14 17:05:05,901 INFO  [enrich.enrich_CNRA    ]        step 2/17 remove milliseconds from dates\n",
      "2025-08-14 17:05:05,919 INFO  [enrich.enrich_CNRA    ]        step 3/17 create standardized activity table\n",
      "2025-08-14 17:05:05,924 INFO  [enrich.enrich_CNRA    ]        step 4/17 import activities into standardized table\n",
      "2025-08-14 17:05:05,954 INFO  [enrich.enrich_CNRA    ]     Part 3 - Combine CNRA Features and Activity Table\n",
      "2025-08-14 17:05:05,955 INFO  [enrich.enrich_CNRA    ]        step 6/17 join polygon table and activity table\n",
      "2025-08-14 17:05:06,029 INFO  [enrich.enrich_CNRA    ]           calculate unique Treatment ID with postfix '-CNRA'\n",
      "2025-08-14 17:05:09,899 INFO  [enrich.enrich_CNRA    ]     Part 4 Prepare Project Table\n",
      "2025-08-14 17:05:09,901 INFO  [enrich.enrich_CNRA    ]        step 7/17 calculate unique Project ID if null\n",
      "2025-08-14 17:05:09,905 INFO  [enrich.enrich_CNRA    ]     Part 5 Join Project Table to Features/Activities\n",
      "2025-08-14 17:05:10,035 INFO  [enrich.enrich_CNRA    ]        step 8/17 copy features\n",
      "2025-08-14 17:05:10,088 INFO  [enrich.enrich_CNRA    ]        step 9/17 create Features\n",
      "2025-08-14 17:05:10,118 INFO  [enrich.enrich_CNRA    ]        step 10/17 append\n",
      "2025-08-14 17:05:10,138 INFO  [enrich.enrich_CNRA    ]        standardized has 34831 records\n",
      "2025-08-14 17:05:10,138 INFO  [enrich.enrich_CNRA    ]     Part 6 Standardize and Enrich\n",
      "2025-08-14 17:05:10,138 INFO  [enrich.enrich_CNRA    ]        step 11/17 calculate crosswalk\n",
      "2025-08-14 17:05:10,139 INFO  [enrich.enrich_CNRA    ]        step 12/17 calculate source\n",
      "2025-08-14 17:05:10,140 INFO  [enrich.enrich_CNRA    ]        step 13/17 calculate admin\n",
      "2025-08-14 17:05:10,147 INFO  [enrich.enrich_CNRA    ]        step 14/17 update status\n",
      "2025-08-14 17:05:10,152 INFO  [enrich.enrich_CNRA    ]        step 15/17 update activity end date\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!\n",
      "13092\n",
      "2702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:05:10,453 INFO  [enrich.enrich_CNRA    ]     Part 7 Calculate Board Vegetation Types, Ownership and Others ... \n",
      "2025-08-14 17:05:10,489 INFO  [utils.enrich_polygons ]        Executing Polygon Enrichments...\n",
      "2025-08-14 17:05:10,489 INFO  [utils.enrich_polygons ]           Calculating Broad Vegetation Type...\n",
      "2025-08-14 17:05:10,489 INFO  [utils.enrich_polygons ]              enrich step 1/32 summarize veg within polygons\n",
      "2025-08-14 17:05:15,262 INFO  [utils.enrich_polygons ]                 Loaded Broad_Vegetation_Types from cache\n",
      "2025-08-14 17:05:15,264 INFO  [utils.enrich_polygons ]                    time for loading Broad_Vegetation_Types: 4.773627758026123\n",
      "2025-08-14 17:05:15,317 INFO  [utils.enrich_polygons ]              create numerical intermediate columns before multiprocessing\n",
      "2025-08-14 17:05:15,320 INFO  [utils.enrich_polygons ]              enrich step 2/32 filter broad veg types using the bounding box\n",
      "2025-08-14 17:05:16,067 INFO  [utils.enrich_polygons ]                 original broad veg type records: 3736147 \n",
      "2025-08-14 17:05:16,068 INFO  [utils.enrich_polygons ]                 filtered broad veg type records: 3409950 \n",
      "2025-08-14 17:05:16,068 INFO  [utils.enrich_polygons ]                 records for summary: 319\n",
      "2025-08-14 17:05:16,069 INFO  [utils.enrich_polygons ]              enrich step 3/32 determining broad veg types\n",
      "2025-08-14 17:05:16,069 INFO  [utils.enrich_polygons ]              enrich step 4/32 joining with broad veg types\n",
      "2025-08-14 17:05:25,559 INFO  [utils.enrich_polygons ]                 joined records: 6504\n",
      "2025-08-14 17:05:25,560 INFO  [utils.enrich_polygons ]              enrich step 5/32 concurrent calculate veg type for each polygon\n",
      "2025-08-14 17:05:25,560 INFO  [utils.enrich_polygons ]              enrich step 5/32 MULTIPROCESSING DISABLED\n",
      "2025-08-14 17:05:50,586 INFO  [utils.enrich_polygons ]                 assigning vegetation types is completed\n",
      "2025-08-14 17:05:50,587 INFO  [utils.enrich_polygons ]                 time for summarizing veg types: 35.322731018066406\n",
      "2025-08-14 17:05:50,673 INFO  [utils.enrich_polygons ]              enrich step 7/32 select records where BROAD_VEGETATION_TYPE is not null\n",
      "2025-08-14 17:05:50,676 INFO  [utils.enrich_polygons ]              enrich step 8/32 set BVT_USERD of the selected records to YES\n",
      "2025-08-14 17:05:50,678 INFO  [utils.enrich_polygons ]              enrich step 9/32 select records where BROAD_VEGETATION_TYPE is null\n",
      "2025-08-14 17:05:50,680 INFO  [utils.enrich_polygons ]              enrich step 11/32 set BVT_USERD of the selected records to NO\n",
      "2025-08-14 17:05:50,684 INFO  [utils.enrich_polygons ]              enrich step 12/32 keeping only the necessary columns\n",
      "2025-08-14 17:05:50,889 INFO  [utils.enrich_polygons ]           Calculating WUI...\n",
      "2025-08-14 17:05:51,045 INFO  [utils.enrich_polygons ]              Loaded WUI from cache\n",
      "2025-08-14 17:05:51,046 INFO  [utils.enrich_polygons ]                 time for loading WUI: 0.15671610832214355\n",
      "2025-08-14 17:05:51,046 INFO  [utils.enrich_polygons ]              enrich step 13/32 select records with null WUI\n",
      "2025-08-14 17:05:51,052 INFO  [utils.enrich_polygons ]              enrich step 14/32 select by WUI location\n",
      "2025-08-14 17:05:51,423 INFO  [utils.enrich_polygons ]              enrich step 15/32 calculate WUI yes\n",
      "2025-08-14 17:05:51,424 INFO  [utils.enrich_polygons ]              enrich step 16/32 select remaining null records\n",
      "2025-08-14 17:05:51,428 INFO  [utils.enrich_polygons ]              enrich step 17/32 calculate WUI no\n",
      "2025-08-14 17:05:51,429 INFO  [utils.enrich_polygons ]              enrich step 18/32 feature to point\n",
      "2025-08-14 17:05:51,659 INFO  [utils.enrich_polygons ]              enrich step 19/32 setup ORIG_FID\n",
      "2025-08-14 17:05:51,660 INFO  [utils.enrich_polygons ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-08-14 17:05:52,081 INFO  [utils.enrich_polygons ]              Loaded CALFIRE_Ownership_Update from cache\n",
      "2025-08-14 17:05:52,081 INFO  [utils.enrich_polygons ]                 time for loading CALFIRE_Ownership_Update: 0.4208338260650635\n",
      "2025-08-14 17:05:52,103 INFO  [utils.enrich_polygons ]              Loaded WFRTF_Regions from cache\n",
      "2025-08-14 17:05:52,104 INFO  [utils.enrich_polygons ]                 time for loading WFRTF_Regions: 0.022084712982177734\n",
      "2025-08-14 17:05:52,104 INFO  [utils.enrich_polygons ]              enrich step 20/32 spatial join ownership\n",
      "2025-08-14 17:06:12,893 INFO  [utils.enrich_polygons ]              enrich step 21/32 spatial join with regions layer\n",
      "2025-08-14 17:06:26,201 INFO  [utils.enrich_polygons ]              enrich step 22/32 add ownership and region\n",
      "2025-08-14 17:06:26,285 INFO  [utils.enrich_polygons ]              enrich step 23/32 calculate ownership field\n",
      "2025-08-14 17:06:26,285 INFO  [utils.enrich_polygons ]              enrich step 24/32 calculate county field\n",
      "2025-08-14 17:06:26,286 INFO  [utils.enrich_polygons ]              enrich step 25/32 calculate region field\n",
      "2025-08-14 17:06:26,287 INFO  [utils.enrich_polygons ]              enrich step 26/32 set TRMT_GEOM\n",
      "2025-08-14 17:06:26,288 INFO  [utils.enrich_polygons ]              enrich step 27/32 calculating years...\n",
      "2025-08-14 17:06:26,382 INFO  [utils.enrich_polygons ]              enrich step 28/32 Initiating Crosswalk...\n",
      "2025-08-14 17:06:26,383 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-08-14 17:06:26,383 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-08-14 17:06:26,414 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-08-14 17:06:26,490 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-08-14 17:06:26,494 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-08-14 17:06:26,497 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-08-14 17:06:26,501 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "2025-08-14 17:06:26,594 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "FIRE_PREVENTION\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "FIRE_PREVENTION\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "PRESCRB_FIRE\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "ROADWAY_CLEARANCE\n",
      "NOT_DEFINED\n",
      "INV_SPECIES_CNTRL\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "FUEL_BREAK\n",
      "NOT_DEFINED\n",
      "RIPARIAN_RESTOR\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:06:26,914 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "INV_SPECIES_CNTRL\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "FIRE_PREVENTION\n",
      "TBD\n",
      "HABITAT_RESTOR\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "ROADWAY_CLEARANCE\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "REFORESTATION\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "RIPARIAN_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "RIPARIAN_RESTOR\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "RIPARIAN_RESTOR\n",
      "TBD\n",
      "RIPARIAN_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "PRESCRB_FIRE\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "MTN_MEADOW_RESTOR\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "REFORESTATION\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "ROADWAY_CLEARANCE\n",
      "TBD\n",
      "FOREST_PEST_CNTRL\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "BURNED_AREA_RESTOR\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "BURNED_AREA_RESTOR\n",
      "TBD\n",
      "FOREST_STEWARDSHIP\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "ECO_RESTOR\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "INV_SPECIES_CNTRL\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "REFORESTATION\n",
      "TBD\n",
      "REFORESTATION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:06:27,799 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-08-14 17:06:27,799 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-08-14 17:06:27,800 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-08-14 17:06:27,800 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-08-14 17:06:27,806 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-08-14 17:06:27,807 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-08-14 17:06:27,811 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-08-14 17:06:27,816 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-08-14 17:06:27,817 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-08-14 17:06:27,831 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Status is 'Active' unless Agency is 'CNRA' \n",
      "2025-08-14 17:06:27,901 INFO  [utils.enrich_polygons ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-08-14 17:06:27,901 INFO  [utils.enrich_polygons ]              enrich step 29/32 Calculating Latitude and Longitude...\n",
      "2025-08-14 17:06:28,316 INFO  [utils.enrich_polygons ]              enrich step 30/32 calculate treatment acres\n",
      "2025-08-14 17:06:28,367 INFO  [utils.enrich_polygons ]              enrich step 31/32 removing unnecessary fields\n",
      "2025-08-14 17:06:28,399 INFO  [utils.enrich_polygons ]              enrich step 32/32 delete if County is Null\n",
      "2025-08-14 17:06:28,756 INFO  [enrich.enrich_CNRA    ]     Part 8 Assign Domains...\n",
      "2025-08-14 17:06:28,825 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-08-14 17:06:28,831 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-08-14 17:06:28,838 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-08-14 17:06:28,845 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-08-14 17:06:28,852 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-08-14 17:06:28,857 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-08-14 17:06:28,863 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-08-14 17:06:28,869 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-08-14 17:06:28,875 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-08-14 17:06:28,880 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-08-14 17:06:28,886 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-08-14 17:06:28,892 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-08-14 17:06:28,897 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-08-14 17:06:28,903 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-08-14 17:06:28,909 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-08-14 17:06:28,915 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-08-14 17:06:28,915 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-08-14 17:06:28,921 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-08-14 17:06:28,926 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-08-14 17:06:28,932 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-08-14 17:06:28,932 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-08-14 17:06:28,976 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-08-14 17:06:29,036 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-08-14 17:06:29,123 INFO  [enrich.enrich_CNRA    ]     Part 9 Save Result...\n",
      "2025-08-14 17:06:29,123 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-08-14 17:06:29,123 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-08-14 17:06:29,128 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\CNRA_1950_2025.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:06:37,790 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\CNRA_1950_2025.gdb CNRA_enriched_20250814_polygon\n",
      "2025-08-14 17:06:37,847 INFO  [enrich.enrich_CNRA    ]  Enrich the CNRA lines...\n",
      "2025-08-14 17:06:37,848 INFO  [enrich.enrich_CNRA    ]     Part 1 Prepare Features\n",
      "2025-08-14 17:06:37,849 INFO  [enrich.enrich_CNRA    ]     Part 2 Prepare Activity Table\n",
      "2025-08-14 17:06:38,131 INFO  [enrich.enrich_CNRA    ]        step 2/17 remove milliseconds from dates\n",
      "2025-08-14 17:06:38,152 INFO  [enrich.enrich_CNRA    ]        step 3/17 create standardized activity table\n",
      "2025-08-14 17:06:38,156 INFO  [enrich.enrich_CNRA    ]        step 4/17 import activities into standardized table\n",
      "2025-08-14 17:06:38,194 INFO  [enrich.enrich_CNRA    ]     Part 3 - Combine CNRA Features and Activity Table\n",
      "2025-08-14 17:06:38,195 INFO  [enrich.enrich_CNRA    ]        step 6/17 join polygon table and activity table\n",
      "2025-08-14 17:06:38,203 INFO  [enrich.enrich_CNRA    ]           calculate unique Treatment ID with postfix '-CNRA'\n",
      "2025-08-14 17:06:38,213 INFO  [enrich.enrich_CNRA    ]     Part 4 Prepare Project Table\n",
      "2025-08-14 17:06:38,216 INFO  [enrich.enrich_CNRA    ]        step 7/17 calculate unique Project ID if null\n",
      "2025-08-14 17:06:38,219 INFO  [enrich.enrich_CNRA    ]     Part 5 Join Project Table to Features/Activities\n",
      "2025-08-14 17:06:38,224 INFO  [enrich.enrich_CNRA    ]        step 8/17 copy features\n",
      "2025-08-14 17:06:38,225 INFO  [enrich.enrich_CNRA    ]        step 9/17 create Features\n",
      "2025-08-14 17:06:38,257 INFO  [enrich.enrich_CNRA    ]        step 10/17 append\n",
      "2025-08-14 17:06:38,259 INFO  [enrich.enrich_CNRA    ]        standardized has 359 records\n",
      "2025-08-14 17:06:38,259 INFO  [enrich.enrich_CNRA    ]     Part 6 Standardize and Enrich\n",
      "2025-08-14 17:06:38,259 INFO  [enrich.enrich_CNRA    ]        step 11/17 calculate crosswalk\n",
      "2025-08-14 17:06:38,260 INFO  [enrich.enrich_CNRA    ]        step 12/17 calculate source\n",
      "2025-08-14 17:06:38,260 INFO  [enrich.enrich_CNRA    ]        step 13/17 calculate admin\n",
      "2025-08-14 17:06:38,261 INFO  [enrich.enrich_CNRA    ]        step 14/17 update status\n",
      "2025-08-14 17:06:38,262 INFO  [enrich.enrich_CNRA    ]        step 15/17 update activity end date\n",
      "2025-08-14 17:06:38,271 INFO  [enrich.enrich_CNRA    ]     Part 7 Calculate Board Vegetation Types, Ownership and Others ... \n",
      "2025-08-14 17:06:38,273 INFO  [utils.enrich_lines    ]        Executing Line Enrichments...\n",
      "2025-08-14 17:06:38,303 INFO  [utils.enrich_lines    ]           enrich line step 1/4 convert to points\n",
      "2025-08-14 17:06:38,305 INFO  [utils.enrich_lines    ]           enrich line step 2/4 execute enrich_points...\n",
      "2025-08-14 17:06:38,305 INFO  [utils.enrich_points   ]        Executing Point Enrichments...\n",
      "2025-08-14 17:06:38,306 INFO  [utils.enrich_points   ]           Calculating WUI...\n",
      "2025-08-14 17:06:38,307 INFO  [utils.enrich_points   ]              enrich step 1/16 loading WUI from cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!\n",
      "113\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:06:38,469 INFO  [utils.enrich_points   ]                 time for loading WUI: 0.1619415283203125\n",
      "2025-08-14 17:06:38,469 INFO  [utils.enrich_points   ]              enrich step 2/16 select records with null WUI\n",
      "2025-08-14 17:06:38,471 INFO  [utils.enrich_points   ]              enrich step 3/16 select by WUI location\n",
      "2025-08-14 17:06:38,512 INFO  [utils.enrich_points   ]              enrich step 4/16 calculate WUI yes\n",
      "2025-08-14 17:06:38,512 INFO  [utils.enrich_points   ]              enrich step 5/16 select remaining null records\n",
      "2025-08-14 17:06:38,514 INFO  [utils.enrich_points   ]              enrich step 6/16 calculate WUI no\n",
      "2025-08-14 17:06:38,514 INFO  [utils.enrich_points   ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-08-14 17:06:38,515 INFO  [utils.enrich_points   ]              enrich step 7/16 loading CALFIRE_Ownership_Update from cache\n",
      "2025-08-14 17:06:38,924 INFO  [utils.enrich_points   ]                 time for loading CALFIRE_Ownership_Update: 0.40958619117736816\n",
      "2025-08-14 17:06:38,925 INFO  [utils.enrich_points   ]              enrich step 8/16 spatial join ownership\n",
      "2025-08-14 17:06:41,079 INFO  [utils.enrich_points   ]              enrich step 9/16 loading WFRTF_Regions from cache\n",
      "2025-08-14 17:06:41,100 INFO  [utils.enrich_points   ]                 time for loading WFRTF_Regions: 0.02097177505493164\n",
      "2025-08-14 17:06:41,100 INFO  [utils.enrich_points   ]              enrich step 10/16 spatial join regions\n",
      "2025-08-14 17:06:41,696 INFO  [utils.enrich_points   ]              enrich step 11/16 loading Broad_Vegetation_Types from cache\n",
      "2025-08-14 17:06:48,046 INFO  [utils.enrich_points   ]                 time for loading Broad_Vegetation_Types: 6.967418909072876\n",
      "2025-08-14 17:06:48,047 INFO  [utils.enrich_points   ]              enrich step 12/16 spatial join veg and calculations\n",
      "2025-08-14 17:06:50,932 INFO  [utils.enrich_points   ]              enrich step 13/16 Initiating Crosswalk\n",
      "2025-08-14 17:06:50,933 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-08-14 17:06:50,933 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-08-14 17:06:50,970 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-08-14 17:06:50,974 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-08-14 17:06:50,975 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-08-14 17:06:50,976 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-08-14 17:06:50,976 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "2025-08-14 17:06:50,979 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-08-14 17:06:50,986 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-08-14 17:06:50,998 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-08-14 17:06:50,998 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-08-14 17:06:50,999 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-08-14 17:06:51,000 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-08-14 17:06:51,000 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-08-14 17:06:51,001 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-08-14 17:06:51,002 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-08-14 17:06:51,002 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-08-14 17:06:51,003 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-08-14 17:06:51,004 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Status is 'Active' unless Agency is 'CNRA' \n",
      "2025-08-14 17:06:51,008 INFO  [utils.enrich_points   ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-08-14 17:06:51,008 INFO  [utils.enrich_points   ]              enrich step 14/16 calculating Years\n",
      "2025-08-14 17:06:51,011 INFO  [utils.enrich_points   ]              enrich step 15/16 calculating Latitude and Longitude\n",
      "2025-08-14 17:06:51,012 INFO  [utils.enrich_points   ]              enrich step 16/16 removing unnecessary fields\n",
      "2025-08-14 17:06:51,014 INFO  [utils.enrich_points   ]           Enrich Points Complete...\n",
      "2025-08-14 17:06:51,315 INFO  [utils.enrich_lines    ]           enrich line step 3/4 importing attributes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "ROADWAY_CLEARANCE\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "FUEL_BREAK\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:06:51,349 INFO  [utils.enrich_lines    ]           enrich line step 4/4 align to template\n",
      "2025-08-14 17:06:51,355 INFO  [enrich.enrich_CNRA    ]     Part 8 Assign Domains...\n",
      "2025-08-14 17:06:51,735 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-08-14 17:06:51,742 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-08-14 17:06:51,749 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-08-14 17:06:51,755 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-08-14 17:06:51,762 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-08-14 17:06:51,768 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-08-14 17:06:51,774 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-08-14 17:06:51,780 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-08-14 17:06:51,787 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-08-14 17:06:51,793 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-08-14 17:06:51,799 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-08-14 17:06:51,805 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-08-14 17:06:51,811 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-08-14 17:06:51,818 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-08-14 17:06:51,824 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-08-14 17:06:51,830 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-08-14 17:06:51,831 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-08-14 17:06:51,837 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-08-14 17:06:51,843 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-08-14 17:06:51,849 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-08-14 17:06:51,849 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-08-14 17:06:51,855 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-08-14 17:06:51,861 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-08-14 17:06:51,871 INFO  [enrich.enrich_CNRA    ]     Part 9 Save Result...\n",
      "2025-08-14 17:06:51,872 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-08-14 17:06:51,873 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-08-14 17:06:51,874 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n",
      "2025-08-14 17:06:51,950 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\CNRA_1950_2025.gdb CNRA_enriched_20250814_line\n",
      "2025-08-14 17:06:51,967 INFO  [enrich.enrich_CNRA    ]  Enrich the CNRA points...\n",
      "2025-08-14 17:06:51,968 INFO  [enrich.enrich_CNRA    ]     Part 1 Prepare Features\n",
      "2025-08-14 17:06:51,970 INFO  [enrich.enrich_CNRA    ]     Part 2 Prepare Activity Table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\CNRA_1950_2025.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:06:52,261 INFO  [enrich.enrich_CNRA    ]        step 2/17 remove milliseconds from dates\n",
      "2025-08-14 17:06:52,284 INFO  [enrich.enrich_CNRA    ]        step 3/17 create standardized activity table\n",
      "2025-08-14 17:06:52,288 INFO  [enrich.enrich_CNRA    ]        step 4/17 import activities into standardized table\n",
      "2025-08-14 17:06:52,331 INFO  [enrich.enrich_CNRA    ]     Part 3 - Combine CNRA Features and Activity Table\n",
      "2025-08-14 17:06:52,332 INFO  [enrich.enrich_CNRA    ]        step 6/17 join polygon table and activity table\n",
      "2025-08-14 17:06:52,345 INFO  [enrich.enrich_CNRA    ]           calculate unique Treatment ID with postfix '-CNRA'\n",
      "2025-08-14 17:06:52,360 INFO  [enrich.enrich_CNRA    ]     Part 4 Prepare Project Table\n",
      "2025-08-14 17:06:52,362 INFO  [enrich.enrich_CNRA    ]        step 7/17 calculate unique Project ID if null\n",
      "2025-08-14 17:06:52,367 INFO  [enrich.enrich_CNRA    ]     Part 5 Join Project Table to Features/Activities\n",
      "2025-08-14 17:06:52,377 INFO  [enrich.enrich_CNRA    ]        step 8/17 copy features\n",
      "2025-08-14 17:06:52,382 INFO  [enrich.enrich_CNRA    ]        step 9/17 create Features\n",
      "2025-08-14 17:06:52,418 INFO  [enrich.enrich_CNRA    ]        step 10/17 append\n",
      "2025-08-14 17:06:52,422 INFO  [enrich.enrich_CNRA    ]        standardized has 2066 records\n",
      "2025-08-14 17:06:52,422 INFO  [enrich.enrich_CNRA    ]     Part 6 Standardize and Enrich\n",
      "2025-08-14 17:06:52,422 INFO  [enrich.enrich_CNRA    ]        step 11/17 calculate crosswalk\n",
      "2025-08-14 17:06:52,424 INFO  [enrich.enrich_CNRA    ]        step 12/17 calculate source\n",
      "2025-08-14 17:06:52,424 INFO  [enrich.enrich_CNRA    ]        step 13/17 calculate admin\n",
      "2025-08-14 17:06:52,426 INFO  [enrich.enrich_CNRA    ]        step 14/17 update status\n",
      "2025-08-14 17:06:52,427 INFO  [enrich.enrich_CNRA    ]        step 15/17 update activity end date\n",
      "2025-08-14 17:06:52,455 INFO  [enrich.enrich_CNRA    ]     Part 7 Calculate Board Vegetation Types, Ownership and Others ... \n",
      "2025-08-14 17:06:52,459 INFO  [utils.enrich_points   ]        Executing Point Enrichments...\n",
      "2025-08-14 17:06:52,461 INFO  [utils.enrich_points   ]           Calculating WUI...\n",
      "2025-08-14 17:06:52,462 INFO  [utils.enrich_points   ]              enrich step 1/16 loading WUI from cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!\n",
      "361\n",
      "225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:06:52,625 INFO  [utils.enrich_points   ]                 time for loading WUI: 0.16290593147277832\n",
      "2025-08-14 17:06:52,626 INFO  [utils.enrich_points   ]              enrich step 2/16 select records with null WUI\n",
      "2025-08-14 17:06:52,627 INFO  [utils.enrich_points   ]              enrich step 3/16 select by WUI location\n",
      "2025-08-14 17:06:52,666 INFO  [utils.enrich_points   ]              enrich step 4/16 calculate WUI yes\n",
      "2025-08-14 17:06:52,667 INFO  [utils.enrich_points   ]              enrich step 5/16 select remaining null records\n",
      "2025-08-14 17:06:52,668 INFO  [utils.enrich_points   ]              enrich step 6/16 calculate WUI no\n",
      "2025-08-14 17:06:52,668 INFO  [utils.enrich_points   ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-08-14 17:06:52,669 INFO  [utils.enrich_points   ]              enrich step 7/16 loading CALFIRE_Ownership_Update from cache\n",
      "2025-08-14 17:06:53,105 INFO  [utils.enrich_points   ]                 time for loading CALFIRE_Ownership_Update: 0.43583154678344727\n",
      "2025-08-14 17:06:53,105 INFO  [utils.enrich_points   ]              enrich step 8/16 spatial join ownership\n",
      "2025-08-14 17:07:14,010 INFO  [utils.enrich_points   ]              enrich step 9/16 loading WFRTF_Regions from cache\n",
      "2025-08-14 17:07:14,032 INFO  [utils.enrich_points   ]                 time for loading WFRTF_Regions: 0.022215604782104492\n",
      "2025-08-14 17:07:14,033 INFO  [utils.enrich_points   ]              enrich step 10/16 spatial join regions\n",
      "2025-08-14 17:07:17,843 INFO  [utils.enrich_points   ]              enrich step 11/16 loading Broad_Vegetation_Types from cache\n",
      "2025-08-14 17:07:24,323 INFO  [utils.enrich_points   ]                 time for loading Broad_Vegetation_Types: 10.31368613243103\n",
      "2025-08-14 17:07:24,325 INFO  [utils.enrich_points   ]              enrich step 12/16 spatial join veg and calculations\n",
      "2025-08-14 17:07:35,343 INFO  [utils.enrich_points   ]              enrich step 13/16 Initiating Crosswalk\n",
      "2025-08-14 17:07:35,343 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-08-14 17:07:35,344 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-08-14 17:07:35,382 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-08-14 17:07:35,390 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-08-14 17:07:35,392 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-08-14 17:07:35,393 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-08-14 17:07:35,394 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "2025-08-14 17:07:35,402 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-08-14 17:07:35,423 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-08-14 17:07:35,480 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-08-14 17:07:35,480 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-08-14 17:07:35,481 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-08-14 17:07:35,482 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-08-14 17:07:35,483 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-08-14 17:07:35,484 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-08-14 17:07:35,484 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-08-14 17:07:35,485 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-08-14 17:07:35,485 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-08-14 17:07:35,488 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Status is 'Active' unless Agency is 'CNRA' \n",
      "2025-08-14 17:07:35,496 INFO  [utils.enrich_points   ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-08-14 17:07:35,496 INFO  [utils.enrich_points   ]              enrich step 14/16 calculating Years\n",
      "2025-08-14 17:07:35,505 INFO  [utils.enrich_points   ]              enrich step 15/16 calculating Latitude and Longitude\n",
      "2025-08-14 17:07:35,506 INFO  [utils.enrich_points   ]              enrich step 16/16 removing unnecessary fields\n",
      "2025-08-14 17:07:35,512 INFO  [utils.enrich_points   ]           Enrich Points Complete...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "NOT_DEFINED\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "NOT_DEFINED\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "OTHER_FUELS_REDUCTION\n",
      "TBD\n",
      "FOREST_STEWARDSHIP\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "TBD\n",
      "OTHER_FOREST_MGMT\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n",
      "FOUND TBD ACTIVITY DESCRIPTION:\n",
      "TBD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:07:35,825 INFO  [enrich.enrich_CNRA    ]     Part 8 Assign Domains...\n",
      "2025-08-14 17:07:35,897 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-08-14 17:07:35,904 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-08-14 17:07:35,912 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-08-14 17:07:35,918 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-08-14 17:07:35,926 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-08-14 17:07:35,932 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-08-14 17:07:35,939 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-08-14 17:07:35,946 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-08-14 17:07:35,953 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-08-14 17:07:35,960 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-08-14 17:07:35,966 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-08-14 17:07:35,972 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-08-14 17:07:35,978 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-08-14 17:07:35,985 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-08-14 17:07:35,992 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-08-14 17:07:35,998 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-08-14 17:07:35,998 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-08-14 17:07:36,005 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-08-14 17:07:36,011 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-08-14 17:07:36,018 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-08-14 17:07:36,018 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-08-14 17:07:36,026 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-08-14 17:07:36,034 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-08-14 17:07:36,048 INFO  [enrich.enrich_CNRA    ]     Part 9 Save Result...\n",
      "2025-08-14 17:07:36,049 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-08-14 17:07:36,049 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-08-14 17:07:36,051 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n",
      "2025-08-14 17:07:36,221 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\CNRA_1950_2025.gdb CNRA_enriched_20250814_point\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\CNRA_1950_2025.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:07:36,745 INFO  [its_logging.logger_config]  Memory usage: 8903.18 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "enrich_CNRA(cnra_input_gdb_path,\n",
    "            cnra_polygon_layer_name,\n",
    "            cnra_line_layer_name,\n",
    "            cnra_point_layer_name,\n",
    "            cnra_project_polygon_layer_name,\n",
    "            cnra_activity_layer_name,\n",
    "            a_reference_gdb_path,\n",
    "            start_year,\n",
    "            end_year,\n",
    "            output_gdb_path,\n",
    "            output_layer_name)\n",
    "\n",
    "# Get memory usage in bytes, convert to MB\n",
    "memory_usage = process.memory_info().rss / 1024 / 1024\n",
    "logger.info(f\"Memory usage: {memory_usage:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d5ff40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrich.enrich_CalTrans import enrich_Caltrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bcf37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb66681f-509c-403c-9379-b13e10b2113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp file path\n",
    "caltrans_input_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\2023\\CALTRANS_2023\\Caltrans_Vegetation_Management_20_23.gdb\"\n",
    "tree_activity_layer_name = \"Caltrans_Vegetation_Management_Trees_ActivitiesTable_20_23\"\n",
    "tree_treatment_layer_name = \"Caltrans_Vegetation_Management_Trees_Treatments_20_23\"\n",
    "road_activity_layer_name = \"Caltrans_Vegetation_Management_RoadsideLandscape_ActivitiesTable_20_23\"\n",
    "road_treatment_layer_name = \"Caltrans_Vegetation_Management_RoadsideLandscape_Treatments_20_23\"\n",
    "start_year = 1950\n",
    "end_year = 2025\n",
    "output_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\tmp\\CalTRANS_{}_{}.gdb\".format(start_year, end_year)\n",
    "output_layer_name = f\"CalTRANS_enriched_{datetime.today().strftime('%Y%m%d')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8dc4b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:14:02,039 INFO  [enrich.enrich_CalTrans]  Load Caltrans road activity layer into a DataFrame\n",
      "2025-08-14 17:14:04,760 INFO  [enrich.enrich_CalTrans]     all required columns are present.\n",
      "2025-08-14 17:14:04,760 INFO  [enrich.enrich_CalTrans]  Load Caltrans road treatment layer into a GeoDataFrame\n",
      "2025-08-14 17:14:04,895 INFO  [enrich.enrich_CalTrans]     all required columns are present.\n",
      "2025-08-14 17:14:05,169 INFO  [enrich.enrich_CalTrans]  Performing Standardization\n",
      "2025-08-14 17:14:05,170 INFO  [enrich.enrich_CalTrans]     step 1/10 merge treatments and activities\n",
      "2025-08-14 17:14:05,320 INFO  [enrich.enrich_CalTrans]        merged_data has 103426 records\n",
      "2025-08-14 17:14:05,321 INFO  [enrich.enrich_CalTrans]     step 2/10 repair geometries\n",
      "2025-08-14 17:14:05,746 INFO  [enrich.enrich_CalTrans]     step 3/10 add standard columns\n",
      "2025-08-14 17:14:06,346 INFO  [enrich.enrich_CalTrans]     step 4/10 calculate column values\n",
      "2025-08-14 17:14:08,418 INFO  [enrich.enrich_CalTrans]     step 5/10 keep standard columns only\n",
      "2025-08-14 17:14:08,565 INFO  [enrich.enrich_CalTrans]     step 6/10 calculate broad veg table, region and etc\n",
      "2025-08-14 17:14:08,566 INFO  [utils.enrich_lines    ]        Executing Line Enrichments...\n",
      "2025-08-14 17:14:08,733 INFO  [utils.enrich_lines    ]           enrich line step 1/4 convert to points\n",
      "2025-08-14 17:14:09,555 INFO  [utils.enrich_lines    ]           enrich line step 2/4 execute enrich_points...\n",
      "2025-08-14 17:14:09,556 INFO  [utils.enrich_points   ]        Executing Point Enrichments...\n",
      "2025-08-14 17:14:09,648 INFO  [utils.enrich_points   ]           Calculating WUI...\n",
      "2025-08-14 17:14:09,649 INFO  [utils.enrich_points   ]              enrich step 1/16 loading WUI from cache\n",
      "2025-08-14 17:14:09,803 INFO  [utils.enrich_points   ]                 time for loading WUI: 0.1548154354095459\n",
      "2025-08-14 17:14:09,804 INFO  [utils.enrich_points   ]              enrich step 2/16 select records with null WUI\n",
      "2025-08-14 17:14:10,003 INFO  [utils.enrich_points   ]              enrich step 3/16 select by WUI location\n",
      "2025-08-14 17:14:23,491 INFO  [utils.enrich_points   ]              enrich step 4/16 calculate WUI yes\n",
      "2025-08-14 17:14:23,498 INFO  [utils.enrich_points   ]              enrich step 5/16 select remaining null records\n",
      "2025-08-14 17:14:23,674 INFO  [utils.enrich_points   ]              enrich step 6/16 calculate WUI no\n",
      "2025-08-14 17:14:23,683 INFO  [utils.enrich_points   ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-08-14 17:14:23,683 INFO  [utils.enrich_points   ]              enrich step 7/16 loading CALFIRE_Ownership_Update from cache\n",
      "2025-08-14 17:14:24,116 INFO  [utils.enrich_points   ]                 time for loading CALFIRE_Ownership_Update: 0.4327433109283447\n",
      "2025-08-14 17:14:24,117 INFO  [utils.enrich_points   ]              enrich step 8/16 spatial join ownership\n",
      "2025-08-14 17:15:48,956 INFO  [utils.enrich_points   ]              enrich step 9/16 loading WFRTF_Regions from cache\n",
      "2025-08-14 17:15:48,979 INFO  [utils.enrich_points   ]                 time for loading WFRTF_Regions: 0.023031234741210938\n",
      "2025-08-14 17:15:48,979 INFO  [utils.enrich_points   ]              enrich step 10/16 spatial join regions\n",
      "2025-08-14 17:18:31,984 INFO  [utils.enrich_points   ]              enrich step 11/16 loading Broad_Vegetation_Types from cache\n",
      "2025-08-14 17:18:39,793 INFO  [utils.enrich_points   ]                 time for loading Broad_Vegetation_Types: 170.83750224113464\n",
      "2025-08-14 17:18:39,794 INFO  [utils.enrich_points   ]              enrich step 12/16 spatial join veg and calculations\n",
      "2025-08-14 17:21:23,413 INFO  [utils.enrich_points   ]              enrich step 13/16 Initiating Crosswalk\n",
      "2025-08-14 17:21:23,414 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-08-14 17:21:23,415 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-08-14 17:21:23,456 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-08-14 17:21:23,742 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-08-14 17:21:23,755 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-08-14 17:21:23,762 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-08-14 17:21:23,767 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "2025-08-14 17:21:24,067 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-08-14 17:21:24,873 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-08-14 17:21:27,427 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-08-14 17:21:27,428 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-08-14 17:21:27,428 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-08-14 17:21:27,429 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-08-14 17:21:27,438 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-08-14 17:21:27,441 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-08-14 17:21:27,444 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-08-14 17:21:27,447 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-08-14 17:21:27,450 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-08-14 17:21:27,491 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Status is 'Active' unless Agency is 'CNRA' \n",
      "2025-08-14 17:21:27,633 INFO  [utils.enrich_points   ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-08-14 17:21:27,634 INFO  [utils.enrich_points   ]              enrich step 14/16 calculating Years\n",
      "2025-08-14 17:21:27,901 INFO  [utils.enrich_points   ]              enrich step 15/16 calculating Latitude and Longitude\n",
      "2025-08-14 17:21:27,925 INFO  [utils.enrich_points   ]              enrich step 16/16 removing unnecessary fields\n",
      "2025-08-14 17:21:28,018 INFO  [utils.enrich_points   ]           Enrich Points Complete...\n",
      "2025-08-14 17:21:28,958 INFO  [utils.enrich_lines    ]           enrich line step 3/4 importing attributes\n",
      "2025-08-14 17:21:32,816 INFO  [utils.enrich_lines    ]           enrich line step 4/4 align to template\n",
      "2025-08-14 17:21:33,196 INFO  [enrich.enrich_CalTrans]        enriched data has 103426 records\n",
      "2025-08-14 17:21:33,197 INFO  [enrich.enrich_CalTrans]     step 7/10 calculate PRIMARY_OWNERSHIP_GROUP and TRMTID_USER\n",
      "2025-08-14 17:21:34,118 INFO  [enrich.enrich_CalTrans]     step 8/10 Remove Unnecessary Columns...\n",
      "2025-08-14 17:21:34,238 INFO  [enrich.enrich_CalTrans]     step 9/10 Assign Domains...\n",
      "2025-08-14 17:21:34,311 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-08-14 17:21:34,318 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-08-14 17:21:34,326 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-08-14 17:21:34,333 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:21:34,341 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-08-14 17:21:34,347 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-08-14 17:21:34,354 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-08-14 17:21:34,361 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-08-14 17:21:34,367 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-08-14 17:21:34,374 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-08-14 17:21:34,381 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-08-14 17:21:34,387 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-08-14 17:21:34,394 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-08-14 17:21:34,401 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-08-14 17:21:34,408 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-08-14 17:21:34,415 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-08-14 17:21:34,416 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-08-14 17:21:34,422 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-08-14 17:21:34,429 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-08-14 17:21:34,435 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-08-14 17:21:34,436 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-08-14 17:21:34,538 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-08-14 17:21:34,666 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-08-14 17:21:34,880 INFO  [enrich.enrich_CalTrans]     step 10/10 Save Result...\n",
      "2025-08-14 17:21:34,881 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-08-14 17:21:34,881 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-08-14 17:21:34,891 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\tmp\\CalTRANS_1950_2025.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:22:02,301 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\tmp\\CalTRANS_1950_2025.gdb CalTRANS_enriched_20250814\n",
      "2025-08-14 17:22:02,474 INFO  [its_logging.logger_config]  Memory usage: 4506.52 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "enrich_Caltrans(caltrans_input_gdb_path,\n",
    "                tree_activity_layer_name,\n",
    "                tree_treatment_layer_name,\n",
    "                road_activity_layer_name,\n",
    "                road_treatment_layer_name,\n",
    "                a_reference_gdb_path,\n",
    "                start_year,\n",
    "                end_year,\n",
    "                output_gdb_path,\n",
    "                output_layer_name)\n",
    "\n",
    "# Get memory usage in bytes, convert to MB\n",
    "memory_usage = process.memory_info().rss / 1024 / 1024\n",
    "logger.info(f\"Memory usage: {memory_usage:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "781b49f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp file path\n",
    "caltrans_input_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\CALTRANS_V2.0\\Caltrans_Vegetation_Management_Treatments_2024.gdb\"\n",
    "tree_activity_layer_name = \"Caltrans_Vegetation_Management_Trees_ActivitiesTable_2024\"\n",
    "tree_treatment_layer_name = \"Caltrans_Vegetation_Management_Tree_Treatments_2024\"\n",
    "road_activity_layer_name = \"Caltrans_Vegetation_Management_RoadsideLandscape_ActivitiesTable_2024\"\n",
    "road_treatment_layer_name = \"Caltrans_Vegetation_Management_RoadsideLandscape_Treatments_2024\"\n",
    "start_year = 1950\n",
    "end_year = 2025\n",
    "output_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\CalTRANS_{}_{}.gdb\".format(start_year, end_year)\n",
    "output_layer_name = f\"CalTRANS_enriched_{datetime.today().strftime('%Y%m%d')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e49232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:22:02,489 INFO  [enrich.enrich_CalTrans]  Load Caltrans road activity layer into a DataFrame\n",
      "2025-08-14 17:22:03,308 INFO  [enrich.enrich_CalTrans]     all required columns are present.\n",
      "2025-08-14 17:22:03,309 INFO  [enrich.enrich_CalTrans]  Load Caltrans road treatment layer into a GeoDataFrame\n",
      "2025-08-14 17:22:03,367 INFO  [enrich.enrich_CalTrans]     all required columns are present.\n",
      "2025-08-14 17:22:03,442 INFO  [enrich.enrich_CalTrans]  Performing Standardization\n",
      "2025-08-14 17:22:03,443 INFO  [enrich.enrich_CalTrans]     step 1/10 merge treatments and activities\n",
      "2025-08-14 17:22:03,520 INFO  [enrich.enrich_CalTrans]        merged_data has 27843 records\n",
      "2025-08-14 17:22:03,520 INFO  [enrich.enrich_CalTrans]     step 2/10 repair geometries\n",
      "2025-08-14 17:22:03,636 INFO  [enrich.enrich_CalTrans]     step 3/10 add standard columns\n",
      "2025-08-14 17:22:03,892 INFO  [enrich.enrich_CalTrans]     step 4/10 calculate column values\n",
      "2025-08-14 17:22:04,948 INFO  [enrich.enrich_CalTrans]     step 5/10 keep standard columns only\n",
      "2025-08-14 17:22:05,006 INFO  [enrich.enrich_CalTrans]     step 6/10 calculate broad veg table, region and etc\n",
      "2025-08-14 17:22:05,007 INFO  [utils.enrich_lines    ]        Executing Line Enrichments...\n",
      "2025-08-14 17:22:05,096 INFO  [utils.enrich_lines    ]           enrich line step 1/4 convert to points\n",
      "2025-08-14 17:22:05,323 INFO  [utils.enrich_lines    ]           enrich line step 2/4 execute enrich_points...\n",
      "2025-08-14 17:22:05,323 INFO  [utils.enrich_points   ]        Executing Point Enrichments...\n",
      "2025-08-14 17:22:05,357 INFO  [utils.enrich_points   ]           Calculating WUI...\n",
      "2025-08-14 17:22:05,358 INFO  [utils.enrich_points   ]              enrich step 1/16 loading WUI from cache\n",
      "2025-08-14 17:22:05,557 INFO  [utils.enrich_points   ]                 time for loading WUI: 0.19864225387573242\n",
      "2025-08-14 17:22:05,558 INFO  [utils.enrich_points   ]              enrich step 2/16 select records with null WUI\n",
      "2025-08-14 17:22:05,633 INFO  [utils.enrich_points   ]              enrich step 3/16 select by WUI location\n",
      "2025-08-14 17:22:09,245 INFO  [utils.enrich_points   ]              enrich step 4/16 calculate WUI yes\n",
      "2025-08-14 17:22:09,249 INFO  [utils.enrich_points   ]              enrich step 5/16 select remaining null records\n",
      "2025-08-14 17:22:09,312 INFO  [utils.enrich_points   ]              enrich step 6/16 calculate WUI no\n",
      "2025-08-14 17:22:09,317 INFO  [utils.enrich_points   ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-08-14 17:22:09,318 INFO  [utils.enrich_points   ]              enrich step 7/16 loading CALFIRE_Ownership_Update from cache\n",
      "2025-08-14 17:22:09,806 INFO  [utils.enrich_points   ]                 time for loading CALFIRE_Ownership_Update: 0.487945556640625\n",
      "2025-08-14 17:22:09,807 INFO  [utils.enrich_points   ]              enrich step 8/16 spatial join ownership\n",
      "2025-08-14 17:22:43,913 INFO  [utils.enrich_points   ]              enrich step 9/16 loading WFRTF_Regions from cache\n",
      "2025-08-14 17:22:43,951 INFO  [utils.enrich_points   ]                 time for loading WFRTF_Regions: 0.0388028621673584\n",
      "2025-08-14 17:22:43,952 INFO  [utils.enrich_points   ]              enrich step 10/16 spatial join regions\n",
      "2025-08-14 17:23:27,410 INFO  [utils.enrich_points   ]              enrich step 11/16 loading Broad_Vegetation_Types from cache\n",
      "2025-08-14 17:23:34,814 INFO  [utils.enrich_points   ]                 time for loading Broad_Vegetation_Types: 50.901034116744995\n",
      "2025-08-14 17:23:34,816 INFO  [utils.enrich_points   ]              enrich step 12/16 spatial join veg and calculations\n",
      "2025-08-14 17:25:15,530 INFO  [utils.enrich_points   ]              enrich step 13/16 Initiating Crosswalk\n",
      "2025-08-14 17:25:15,531 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-08-14 17:25:15,532 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-08-14 17:25:15,581 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-08-14 17:25:15,686 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-08-14 17:25:15,694 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-08-14 17:25:15,701 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-08-14 17:25:15,704 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "2025-08-14 17:25:15,809 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-08-14 17:25:16,066 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-08-14 17:25:16,886 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-08-14 17:25:16,887 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-08-14 17:25:16,888 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-08-14 17:25:16,890 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-08-14 17:25:16,906 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-08-14 17:25:16,907 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-08-14 17:25:16,909 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-08-14 17:25:16,911 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-08-14 17:25:16,913 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-08-14 17:25:16,929 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Status is 'Active' unless Agency is 'CNRA' \n",
      "2025-08-14 17:25:17,012 INFO  [utils.enrich_points   ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-08-14 17:25:17,013 INFO  [utils.enrich_points   ]              enrich step 14/16 calculating Years\n",
      "2025-08-14 17:25:17,109 INFO  [utils.enrich_points   ]              enrich step 15/16 calculating Latitude and Longitude\n",
      "2025-08-14 17:25:17,122 INFO  [utils.enrich_points   ]              enrich step 16/16 removing unnecessary fields\n",
      "2025-08-14 17:25:17,177 INFO  [utils.enrich_points   ]           Enrich Points Complete...\n",
      "2025-08-14 17:25:17,819 INFO  [utils.enrich_lines    ]           enrich line step 3/4 importing attributes\n",
      "2025-08-14 17:25:19,268 INFO  [utils.enrich_lines    ]           enrich line step 4/4 align to template\n",
      "2025-08-14 17:25:19,420 INFO  [enrich.enrich_CalTrans]        enriched data has 27843 records\n",
      "2025-08-14 17:25:19,422 INFO  [enrich.enrich_CalTrans]     step 7/10 calculate PRIMARY_OWNERSHIP_GROUP and TRMTID_USER\n",
      "2025-08-14 17:25:19,703 INFO  [enrich.enrich_CalTrans]     step 8/10 Remove Unnecessary Columns...\n",
      "2025-08-14 17:25:19,748 INFO  [enrich.enrich_CalTrans]     step 9/10 Assign Domains...\n",
      "2025-08-14 17:25:19,826 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-08-14 17:25:19,833 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-08-14 17:25:19,842 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-08-14 17:25:19,849 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:25:19,859 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-08-14 17:25:19,866 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-08-14 17:25:19,873 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-08-14 17:25:19,881 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-08-14 17:25:19,888 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-08-14 17:25:19,896 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-08-14 17:25:19,903 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-08-14 17:25:19,911 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-08-14 17:25:19,918 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-08-14 17:25:19,926 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-08-14 17:25:19,934 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-08-14 17:25:19,941 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-08-14 17:25:19,941 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-08-14 17:25:19,950 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-08-14 17:25:19,958 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-08-14 17:25:19,965 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n",
      "2025-08-14 17:25:19,966 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-08-14 17:25:20,020 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-08-14 17:25:20,084 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-08-14 17:25:20,193 INFO  [enrich.enrich_CalTrans]     step 10/10 Save Result...\n",
      "2025-08-14 17:25:20,195 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-08-14 17:25:20,196 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-08-14 17:25:20,205 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\CalTRANS_1950_2025.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 17:25:28,095 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\CalTRANS_1950_2025.gdb CalTRANS_enriched_20250814\n",
      "2025-08-14 17:25:28,214 INFO  [its_logging.logger_config]  Memory usage: 6720.24 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "enrich_Caltrans(caltrans_input_gdb_path,\n",
    "                tree_activity_layer_name,\n",
    "                tree_treatment_layer_name,\n",
    "                road_activity_layer_name,\n",
    "                road_treatment_layer_name,\n",
    "                a_reference_gdb_path,\n",
    "                start_year,\n",
    "                end_year,\n",
    "                output_gdb_path,\n",
    "                output_layer_name)\n",
    "\n",
    "# Get memory usage in bytes, convert to MB\n",
    "memory_usage = process.memory_info().rss / 1024 / 1024\n",
    "logger.info(f\"Memory usage: {memory_usage:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b8326b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "caltrans_2023 = gpd.read_file(r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\tmp\\CalTRANS_{}_{}.gdb\".format(start_year, end_year),\n",
    "                              driver='OpenFileGDB',\n",
    "                              layer=output_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c8afb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "caltrans_2024 = gpd.read_file(r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\CalTRANS_{}_{}.gdb\".format(start_year, end_year),\n",
    "                              driver='OpenFileGDB',\n",
    "                              layer=output_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b87d2e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "caltrans_out = pd.concat([caltrans_2023, caltrans_2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c65b2315",
   "metadata": {},
   "outputs": [],
   "source": [
    "caltrans_out.to_file(r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0.1\\CalTRANS_{}_{}.gdb\".format(start_year, end_year),\n",
    "                      driver='OpenFileGDB',\n",
    "                      layer=output_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1425304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\tmp\\reports.gdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad738bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>geometry_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>footprint2021</td>\n",
       "      <td>MultiPolygon Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>footprint2022</td>\n",
       "      <td>MultiPolygon Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>footprint2023</td>\n",
       "      <td>MultiPolygon Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name   geometry_type\n",
       "0  footprint2021  MultiPolygon Z\n",
       "1  footprint2022  MultiPolygon Z\n",
       "2  footprint2023  MultiPolygon Z"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpd.list_layers(report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51e647d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\pyogrio\\raw.py:198: RuntimeWarning: driver OpenFileGDB does not support open option DRIVER\n",
      "  return ogr_read(\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\pyogrio\\raw.py:198: RuntimeWarning: organizePolygons() received a polygon with more than 100 parts. The processing may be really slow.  You can skip the processing by setting METHOD=SKIP, or only make it analyze counter-clock wise parts by setting METHOD=ONLY_CCW if you can assume that the outline of holes is counter-clock wise defined\n",
      "  return ogr_read(\n"
     ]
    }
   ],
   "source": [
    "footprint2023 = gpd.read_file(report_path,driver='OpenFileGDB',layer='footprint2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8fcc8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_OWNERSHIP_GROUP\n",
       "FEDERAL                 260083.279806\n",
       "LOCAL                     4945.251612\n",
       "NGO                       2446.897781\n",
       "PRIVATE_INDUSTRY        224994.549016\n",
       "PRIVATE_NON-INDUSTRY     59268.893918\n",
       "STATE                   137141.116163\n",
       "TRIBAL                    3599.720000\n",
       "Name: ACTIVITY_QUANTITY, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "footprint2023.groupby(['PRIMARY_OWNERSHIP_GROUP']).ACTIVITY_QUANTITY.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af52b779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRMTID_USER</th>\n",
       "      <th>ACTIVITY_QUANTITY</th>\n",
       "      <th>AGENCY</th>\n",
       "      <th>PRIMARY_OWNERSHIP_GROUP</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>BROAD_VEGETATION_TYPE</th>\n",
       "      <th>REGION</th>\n",
       "      <th>WUI</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-DN-101-DN-NOR-NON</td>\n",
       "      <td>32.400000</td>\n",
       "      <td>CALSTA</td>\n",
       "      <td>STATE</td>\n",
       "      <td>DN</td>\n",
       "      <td>Forest</td>\n",
       "      <td>North Coast</td>\n",
       "      <td>Non-WUI</td>\n",
       "      <td>MULTIPOLYGON (((-342583.596 406960.852, -34258...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-DN-101-DN-NOR-WUI</td>\n",
       "      <td>32.400000</td>\n",
       "      <td>CALSTA</td>\n",
       "      <td>STATE</td>\n",
       "      <td>DN</td>\n",
       "      <td>Forest</td>\n",
       "      <td>North Coast</td>\n",
       "      <td>Non-WUI</td>\n",
       "      <td>MULTIPOLYGON (((-342583.596 406960.852, -34258...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-DN-169-DN-NOR-NON</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>CALSTA</td>\n",
       "      <td>STATE</td>\n",
       "      <td>DN</td>\n",
       "      <td>Urban</td>\n",
       "      <td>North Coast</td>\n",
       "      <td>WUI</td>\n",
       "      <td>MULTIPOLYGON (((-337005.425 396726.106, -33698...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-DN-169-DN-NOR-WUI</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>CALSTA</td>\n",
       "      <td>STATE</td>\n",
       "      <td>DN</td>\n",
       "      <td>Urban</td>\n",
       "      <td>North Coast</td>\n",
       "      <td>WUI</td>\n",
       "      <td>MULTIPOLYGON (((-337005.425 396726.106, -33698...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-DN-197-DN-NOR-WUI</td>\n",
       "      <td>5.860000</td>\n",
       "      <td>CALSTA</td>\n",
       "      <td>STATE</td>\n",
       "      <td>DN</td>\n",
       "      <td>Forest</td>\n",
       "      <td>North Coast</td>\n",
       "      <td>WUI</td>\n",
       "      <td>MULTIPOLYGON (((-339603.722 428203.383, -33960...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>TI-55</td>\n",
       "      <td>12200.547236</td>\n",
       "      <td>TIMBER</td>\n",
       "      <td>PRIVATE_INDUSTRY</td>\n",
       "      <td>None</td>\n",
       "      <td>FOREST</td>\n",
       "      <td>None</td>\n",
       "      <td>Non-WUI</td>\n",
       "      <td>MULTIPOLYGON (((-308845.263 -48952.018, -30886...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>TI-58</td>\n",
       "      <td>1525.818568</td>\n",
       "      <td>TIMBER</td>\n",
       "      <td>PRIVATE_INDUSTRY</td>\n",
       "      <td>None</td>\n",
       "      <td>FOREST</td>\n",
       "      <td>None</td>\n",
       "      <td>Non-WUI</td>\n",
       "      <td>MULTIPOLYGON (((-291682.027 -45293.631, -29168...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>TI-61</td>\n",
       "      <td>30646.452164</td>\n",
       "      <td>TIMBER</td>\n",
       "      <td>PRIVATE_INDUSTRY</td>\n",
       "      <td>None</td>\n",
       "      <td>FOREST</td>\n",
       "      <td>None</td>\n",
       "      <td>Non-WUI</td>\n",
       "      <td>MULTIPOLYGON (((-286089.472 -38332.964, -28611...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>TI-64</td>\n",
       "      <td>2298.548819</td>\n",
       "      <td>TIMBER</td>\n",
       "      <td>PRIVATE_INDUSTRY</td>\n",
       "      <td>None</td>\n",
       "      <td>FOREST</td>\n",
       "      <td>None</td>\n",
       "      <td>Non-WUI</td>\n",
       "      <td>MULTIPOLYGON (((-295831.21 -46396.505, -295839...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>TI-70</td>\n",
       "      <td>34337.536889</td>\n",
       "      <td>TIMBER</td>\n",
       "      <td>PRIVATE_INDUSTRY</td>\n",
       "      <td>None</td>\n",
       "      <td>FOREST</td>\n",
       "      <td>None</td>\n",
       "      <td>Non-WUI</td>\n",
       "      <td>MULTIPOLYGON (((-286502.251 -48482.165, -28653...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5110 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               TRMTID_USER  ACTIVITY_QUANTITY  AGENCY PRIMARY_OWNERSHIP_GROUP  \\\n",
       "0     01-DN-101-DN-NOR-NON          32.400000  CALSTA                   STATE   \n",
       "1     01-DN-101-DN-NOR-WUI          32.400000  CALSTA                   STATE   \n",
       "2     01-DN-169-DN-NOR-NON           8.500000  CALSTA                   STATE   \n",
       "3     01-DN-169-DN-NOR-WUI           8.500000  CALSTA                   STATE   \n",
       "4     01-DN-197-DN-NOR-WUI           5.860000  CALSTA                   STATE   \n",
       "...                    ...                ...     ...                     ...   \n",
       "5105                 TI-55       12200.547236  TIMBER        PRIVATE_INDUSTRY   \n",
       "5106                 TI-58        1525.818568  TIMBER        PRIVATE_INDUSTRY   \n",
       "5107                 TI-61       30646.452164  TIMBER        PRIVATE_INDUSTRY   \n",
       "5108                 TI-64        2298.548819  TIMBER        PRIVATE_INDUSTRY   \n",
       "5109                 TI-70       34337.536889  TIMBER        PRIVATE_INDUSTRY   \n",
       "\n",
       "     COUNTY BROAD_VEGETATION_TYPE       REGION      WUI  \\\n",
       "0        DN                Forest  North Coast  Non-WUI   \n",
       "1        DN                Forest  North Coast  Non-WUI   \n",
       "2        DN                 Urban  North Coast      WUI   \n",
       "3        DN                 Urban  North Coast      WUI   \n",
       "4        DN                Forest  North Coast      WUI   \n",
       "...     ...                   ...          ...      ...   \n",
       "5105   None                FOREST         None  Non-WUI   \n",
       "5106   None                FOREST         None  Non-WUI   \n",
       "5107   None                FOREST         None  Non-WUI   \n",
       "5108   None                FOREST         None  Non-WUI   \n",
       "5109   None                FOREST         None  Non-WUI   \n",
       "\n",
       "                                               geometry  \n",
       "0     MULTIPOLYGON (((-342583.596 406960.852, -34258...  \n",
       "1     MULTIPOLYGON (((-342583.596 406960.852, -34258...  \n",
       "2     MULTIPOLYGON (((-337005.425 396726.106, -33698...  \n",
       "3     MULTIPOLYGON (((-337005.425 396726.106, -33698...  \n",
       "4     MULTIPOLYGON (((-339603.722 428203.383, -33960...  \n",
       "...                                                 ...  \n",
       "5105  MULTIPOLYGON (((-308845.263 -48952.018, -30886...  \n",
       "5106  MULTIPOLYGON (((-291682.027 -45293.631, -29168...  \n",
       "5107  MULTIPOLYGON (((-286089.472 -38332.964, -28611...  \n",
       "5108  MULTIPOLYGON (((-295831.21 -46396.505, -295839...  \n",
       "5109  MULTIPOLYGON (((-286502.251 -48482.165, -28653...  \n",
       "\n",
       "[5110 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "footprint2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd55fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
