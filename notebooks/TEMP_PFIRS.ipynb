{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cf7ae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b2324b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9b4ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from its_logging.logger_config import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ec2cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfirs_gdb_path = r'D:\\WORK\\wildfire\\Interagency-Tracking-System\\V2.0\\PFIRS_V2.0\\PFIRS2024.gdb'\n",
    "pfirs_layer_name = 'PFIRS2024'\n",
    "lookup_table_path = r'D:\\WORK\\wildfire\\Interagency-Tracking-System\\2023\\PFIRS_2023\\pfirs_agency_2022_2023_AT.xlsx'\n",
    "a_reference_gdb_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\Interagency Tracking System.gdb\"\n",
    "start_year, end_year = 1950, 2025\n",
    "\n",
    "output_gdb_path =  r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\PFIRS_{}_{}.gdb\".format(start_year, end_year)\n",
    "output_layer_name = f\"PFIRS_{datetime.today().strftime('%Y%m%d')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3c757e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\pyogrio\\raw.py:198: RuntimeWarning: driver OpenFileGDB does not support open option DRIVER\n",
      "  return ogr_read(\n",
      "C:\\Users\\sky\\.conda\\envs\\its_recode\\Lib\\site-packages\\pyogrio\\raw.py:198: RuntimeWarning: organizePolygons() received a polygon with more than 100 parts. The processing may be really slow.  You can skip the processing by setting METHOD=SKIP, or only make it analyze counter-clock wise parts by setting METHOD=ONLY_CCW if you can assume that the outline of holes is counter-clock wise defined\n",
      "  return ogr_read(\n"
     ]
    }
   ],
   "source": [
    "append_path = r\"D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\appended.gdb\"\n",
    "enriched_polygons = gpd.read_file(append_path, driver='OpenFileGDB', layer='appended_poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f723932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrich.enrich_PFIRS import enrich_PFIRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6bd654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 12:34:37,576 INFO  [enrich.enrich_PFIRS   ]  Load the PFIRS data into a GeoDataFrame\n",
      "2025-05-23 12:34:37,847 INFO  [enrich.enrich_PFIRS   ]     time for loading PFIRS2024: 0.27043581008911133\n",
      "2025-05-23 12:34:37,848 INFO  [enrich.enrich_PFIRS   ]     all required columns are present.\n",
      "2025-05-23 12:34:37,872 INFO  [enrich.enrich_PFIRS   ]  Performing Standardization\n",
      "2025-05-23 12:34:37,873 INFO  [enrich.enrich_PFIRS   ]     step 1/8 remove some agencies\n",
      "2025-05-23 12:34:37,878 INFO  [enrich.enrich_PFIRS   ]     step 2/8 rename fields\n",
      "2025-05-23 12:34:37,880 INFO  [enrich.enrich_PFIRS   ]     step 3/8 adding common columns...\n",
      "2025-05-23 12:34:37,916 INFO  [enrich.enrich_PFIRS   ]     step 4/8 import attributes\n",
      "2025-05-23 12:34:37,931 INFO  [enrich.enrich_PFIRS   ]        standardized has 3675 records\n",
      "2025-05-23 12:34:37,932 INFO  [enrich.enrich_PFIRS   ]     step 5/8 remove points that intersect burn polygons\n",
      "2025-05-23 12:34:37,932 INFO  [enrich.enrich_PFIRS   ]     step 6/8 Remove Unnecessary Columns...\n",
      "2025-05-23 12:34:37,938 INFO  [enrich.enrich_PFIRS   ]  Performing Enrichments\n",
      "2025-05-23 12:34:37,939 INFO  [utils.enrich_points   ]        Executing Point Enrichments...\n",
      "2025-05-23 12:34:37,944 INFO  [utils.enrich_points   ]           Calculating WUI...\n",
      "2025-05-23 12:34:37,945 INFO  [utils.enrich_points   ]              enrich step 1/16 loading WUI from cache\n",
      "2025-05-23 12:34:38,127 INFO  [utils.enrich_points   ]                 time for loading WUI: 0.18199586868286133\n",
      "2025-05-23 12:34:38,127 INFO  [utils.enrich_points   ]              enrich step 2/16 select records with null WUI\n",
      "2025-05-23 12:34:38,137 INFO  [utils.enrich_points   ]              enrich step 3/16 select by WUI location\n",
      "2025-05-23 12:34:38,520 INFO  [utils.enrich_points   ]              enrich step 4/16 calculate WUI yes\n",
      "2025-05-23 12:34:38,521 INFO  [utils.enrich_points   ]              enrich step 5/16 select remaining null records\n",
      "2025-05-23 12:34:38,526 INFO  [utils.enrich_points   ]              enrich step 6/16 calculate WUI no\n",
      "2025-05-23 12:34:38,526 INFO  [utils.enrich_points   ]           Calculating Ownership, Counties, and Regions...\n",
      "2025-05-23 12:34:38,527 INFO  [utils.enrich_points   ]              enrich step 7/16 loading CALFIRE_Ownership_Update from cache\n",
      "2025-05-23 12:34:38,955 INFO  [utils.enrich_points   ]                 time for loading CALFIRE_Ownership_Update: 0.4287087917327881\n",
      "2025-05-23 12:34:38,956 INFO  [utils.enrich_points   ]              enrich step 8/16 spatial join ownership\n",
      "2025-05-23 12:35:09,537 INFO  [utils.enrich_points   ]              enrich step 9/16 loading WFRTF_Regions from cache\n",
      "2025-05-23 12:35:09,547 INFO  [utils.enrich_points   ]                 time for loading WFRTF_Regions: 0.009617328643798828\n",
      "2025-05-23 12:35:09,548 INFO  [utils.enrich_points   ]              enrich step 10/16 spatial join regions\n",
      "2025-05-23 12:35:12,458 INFO  [utils.enrich_points   ]              enrich step 11/16 loading Broad_Vegetation_Types from cache\n",
      "2025-05-23 12:35:17,184 INFO  [utils.enrich_points   ]                 time for loading Broad_Vegetation_Types: 7.646814584732056\n",
      "2025-05-23 12:35:17,185 INFO  [utils.enrich_points   ]              enrich step 12/16 spatial join veg and calculations\n",
      "2025-05-23 12:35:30,105 INFO  [utils.enrich_points   ]              enrich step 13/16 Initiating Crosswalk\n",
      "2025-05-23 12:35:30,105 INFO  [utils.crosswalk       ]           Calculating Crosswalking Activites...\n",
      "2025-05-23 12:35:30,106 INFO  [utils.crosswalk       ]              Load Crosswalk table...\n",
      "2025-05-23 12:35:30,135 INFO  [utils.crosswalk       ]              cross step 1/8 add join\n",
      "2025-05-23 12:35:30,147 INFO  [utils.crosswalk       ]              cross step 2/8 calculate activities\n",
      "2025-05-23 12:35:30,149 INFO  [utils.crosswalk       ]              cross step 3/8 calculate residue fate field\n",
      "2025-05-23 12:35:30,150 INFO  [utils.crosswalk       ]              cross step 4/8 select attribute by layer\n",
      "2025-05-23 12:35:30,150 INFO  [utils.crosswalk       ]              cross step 5/8 calculating objective...\n",
      "2025-05-23 12:35:30,156 INFO  [utils.crosswalk       ]              cross step 6/8 calculate category\n",
      "2025-05-23 12:35:30,184 INFO  [utils.crosswalk       ]              cross step 7/8 standardize domains\n",
      "2025-05-23 12:35:30,273 INFO  [utils.crosswalk       ]              cross step 8/8 counts towards MAS\n",
      "2025-05-23 12:35:30,274 INFO  [utils.counts_to_mas   ]           Calculating Counts to MAS\n",
      "2025-05-23 12:35:30,274 INFO  [utils.counts_to_mas   ]              counts step 1/8: set to 'NO'\n",
      "2025-05-23 12:35:30,275 INFO  [utils.counts_to_mas   ]              counts step 2/8: select by bounding years (1950-2025)\n",
      "2025-05-23 12:35:30,278 INFO  [utils.counts_to_mas   ]              counts step 3/8: set to 'YES' if activity description is in the list\n",
      "2025-05-23 12:35:30,278 INFO  [utils.counts_to_mas   ]              counts step 4/8: set to 'NO' if not 'Acres'\n",
      "2025-05-23 12:35:30,279 INFO  [utils.counts_to_mas   ]              counts step 5/8: set to 'NO' if status is 'Canceled', 'Planned', 'Outyear', or 'Proposed'\n",
      "2025-05-23 12:35:30,280 INFO  [utils.counts_to_mas   ]              counts step 6/8: set to 'NO' if Activity Category is 'Watershed Improvement'\n",
      "2025-05-23 12:35:30,281 INFO  [utils.counts_to_mas   ]              counts step 7/8: set to 'NO' if Agency is 'Other' and Admin is 'CARB'\n",
      "2025-05-23 12:35:30,283 INFO  [utils.counts_to_mas   ]              counts step 8/8: set to 'NO' if Org is 'USFS' and Status is 'Active'\n",
      "2025-05-23 12:35:30,290 INFO  [utils.enrich_points   ]           Crosswalk Complete. Continuing Enrichment...\n",
      "2025-05-23 12:35:30,290 INFO  [utils.enrich_points   ]              enrich step 14/16 calculating Years\n",
      "2025-05-23 12:35:30,302 INFO  [utils.enrich_points   ]              enrich step 15/16 calculating Latitude and Longitude\n",
      "2025-05-23 12:35:30,304 INFO  [utils.enrich_points   ]              enrich step 16/16 removing unnecessary fields\n",
      "2025-05-23 12:35:30,309 INFO  [utils.enrich_points   ]           Enrich Points Complete...\n",
      "2025-05-23 12:35:30,519 INFO  [enrich.enrich_PFIRS   ]     step 7/8 Assign Domains...\n",
      "2025-05-23 12:35:30,589 INFO  [utils.assign_domains  ]        Created domain 'D_OBJECTIVE' with 27 values\n",
      "2025-05-23 12:35:30,596 INFO  [utils.assign_domains  ]        Created domain 'D_STATUS' with 6 values\n",
      "2025-05-23 12:35:30,603 INFO  [utils.assign_domains  ]        Created domain 'D_CNTY' with 59 values\n",
      "2025-05-23 12:35:30,609 INFO  [utils.assign_domains  ]        Created domain 'D_IN_WUI' with 4 values\n",
      "2025-05-23 12:35:30,615 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVDSCRP' with 61 values\n",
      "2025-05-23 12:35:30,621 INFO  [utils.assign_domains  ]        Created domain 'D_ACTVCAT' with 8 values\n",
      "2025-05-23 12:35:30,627 INFO  [utils.assign_domains  ]        Created domain 'D_USERDEFINED' with 2 values\n",
      "2025-05-23 12:35:30,633 INFO  [utils.assign_domains  ]        Created domain 'D_BVT' with 8 values\n",
      "2025-05-23 12:35:30,639 INFO  [utils.assign_domains  ]        Created domain 'D_RESIDUEFATE' with 15 values\n",
      "2025-05-23 12:35:30,645 INFO  [utils.assign_domains  ]        Created domain 'D_UOM' with 6 values\n",
      "2025-05-23 12:35:30,651 INFO  [utils.assign_domains  ]        Created domain 'D_TASKFORCE' with 5 values\n",
      "2025-05-23 12:35:30,656 INFO  [utils.assign_domains  ]        Created domain 'D_PR_OWN_GR' with 7 values\n",
      "2025-05-23 12:35:30,662 INFO  [utils.assign_domains  ]        Created domain 'D_FNDSRC' with 11 values\n",
      "2025-05-23 12:35:30,667 INFO  [utils.assign_domains  ]        Created domain 'D_AGENCY' with 9 values\n",
      "2025-05-23 12:35:30,674 INFO  [utils.assign_domains  ]        Created domain 'D_ORGANIZATION' with 32 values\n",
      "2025-05-23 12:35:30,679 INFO  [utils.assign_domains  ]        Warning: 1 rows with NULL values were dropped from 'D_DATASTATUS'\n",
      "2025-05-23 12:35:30,679 INFO  [utils.assign_domains  ]        Created domain 'D_DATASTATUS' with 2 values\n",
      "2025-05-23 12:35:30,685 INFO  [utils.assign_domains  ]        Created domain 'D_DATAMSG' with 3 values\n",
      "2025-05-23 12:35:30,691 INFO  [utils.assign_domains  ]        Created domain 'D_VERFIEDMSG' with 2 values\n",
      "2025-05-23 12:35:30,696 INFO  [utils.assign_domains  ]        Created domain 'D_TRMT_GEOM' with 4 values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 12:35:30,696 INFO  [utils.assign_domains  ]        Assign domains to project-related columns\n",
      "2025-05-23 12:35:30,703 INFO  [utils.assign_domains  ]        Assign domains to treatment-related columns\n",
      "2025-05-23 12:35:30,711 INFO  [utils.assign_domains  ]        Assign domains to activity-related columns\n",
      "2025-05-23 12:35:30,867 INFO  [enrich.enrich_PFIRS   ]     step 8/8 Save Result...\n",
      "2025-05-23 12:35:30,868 INFO  [utils.save_gdf_to_gdb ]        Windows machine detected\n",
      "2025-05-23 12:35:30,868 INFO  [utils.save_gdf_to_gdb ]        Check geodataframe geometry object and cast to Multi-x type if both exist\n",
      "2025-05-23 12:35:30,869 INFO  [utils.save_gdf_to_gdb ]        Running GDAL OpenFileGDB to save to file\n",
      "2025-05-23 12:35:31,066 INFO  [utils.save_gdf_to_gdb ]        File saved to D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\PFIRS_1950_2025.gdb PFIRS_20250523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WORK\\wildfire\\Interagency-Tracking-System\\its\\ITSGDB_backup\\V2.0\\PFIRS_1950_2025.gdb\n"
     ]
    }
   ],
   "source": [
    "gdf = enrich_PFIRS(pfirs_gdb_path,\n",
    "                 pfirs_layer_name,\n",
    "                 enriched_polygons,\n",
    "                 a_reference_gdb_path,\n",
    "                 lookup_table_path,\n",
    "                 start_year,\n",
    "                 end_year,\n",
    "                 output_gdb_path,\n",
    "                 output_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884911a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
